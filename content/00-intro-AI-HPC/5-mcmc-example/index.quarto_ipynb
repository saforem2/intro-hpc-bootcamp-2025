{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: 'Computing $\\pi$ in Parallel with Markov Chain Monte Carlo (MCMC) and MPI'\n",
        "description: 'Simple example of parallel computing using MPI to estimate the value of $\\pi$ with the Monte Carlo method.'\n",
        "categories:\n",
        "  - ai4science\n",
        "  - hpc\n",
        "  - llm\n",
        "  - mcmc\n",
        "toc: true\n",
        "date: 2025-07-15\n",
        "date-modified: last-modified\n",
        "---\n",
        "\n",
        "> **Parallel computing** refers to the process of breaking down larger problems\n",
        "> into smaller, independent, often similar parts that can be executed\n",
        "> simultaneously by multiple processors communicating via network or shared\n",
        "> memory, the results of which are combined upon completion as part of an\n",
        "> overall algorithm.\n",
        "\n",
        "## Example: Estimate $\\pi$\n",
        "\n",
        "We can calculate the value of $\\pi$ using a MPI parallelized version of the\n",
        "Monte Carlo method.\n",
        "The basic idea is to estimate $\\pi$ by randomly sampling points within a square\n",
        "and determining how many fall inside a quarter circle inscribed within that\n",
        "square.\n",
        "\n",
        "![$\\pi$](https://www.101computing.net/wp/wp-content/uploads/estimating-pi-monte-carlo-method.png)\n",
        "\n",
        "The ratio between the area of the circle and the square is\n",
        "\n",
        "$\\frac{N_\\text{in}}{N_\\text{total}} = \\frac{\\pi r^2}{4r^2} = \\frac{\\pi}{4}$\n",
        "\n",
        "Therefore, we can calculate $\\pi$ using \n",
        "$\\pi = \\frac{4N_\\text{in}}{N_\\text{total}} $\n"
      ],
      "id": "7931b9ba"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import ambivalent\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.style.use(ambivalent.STYLES['ambivalent'])\n",
        "sns.set_context(\"notebook\")\n",
        "plt.rcParams[\"figure.figsize\"] = [6.4, 4.8]\n",
        "\n",
        "from IPython.display import display, clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "fig, ax = plt.subplots()\n",
        "#ax = fig.add_subplot(111)\n",
        "circle = plt.Circle(( 0. , 0. ), 0.5 )\n",
        "plt.xlim(-0.5, 0.5)\n",
        "plt.ylim(-0.5, 0.5)\n",
        "ax.add_patch(circle)\n",
        "ax.set_aspect('equal')\n",
        "N = 500\n",
        "Nin = 0\n",
        "t0 = time.time()\n",
        "for i in range(1, N+1):\n",
        "    x = random.uniform(-0.5, 0.5)\n",
        "    y = random.uniform(-0.5, 0.5)\n",
        "    if (np.sqrt(x*x + y*y) < 0.5):\n",
        "        Nin += 1\n",
        "        plt.plot([x], [y], 'o', color='r', markersize=3)\n",
        "    else:\n",
        "        plt.plot([x], [y], 'o', color='b', markersize=3)\n",
        "    display(fig)\n",
        "    plt.xlabel(\"$\\pi$ = %3.4f \\n N_in / N_total = %5d/%5d\" %(Nin*4.0/i, Nin, i))\n",
        "    clear_output(wait=True)\n",
        "\n",
        "res = np.array(Nin, dtype='d')\n",
        "t1 = time.time()\n",
        "print(f\"Pi = {res/float(N/4.0)}\")\n",
        "print(\"Time: %s\" %(t1 - t0))"
      ],
      "id": "d31a9165",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MPI example\n",
        "```python\n",
        "from mpi4py import MPI\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "comm = MPI.COMM_WORLD\n",
        "\n",
        "N = 5000000\n",
        "Nin = 0\n",
        "t0 = time.time()\n",
        "for i in range(comm.rank, N, comm.size):\n",
        "    x = random.uniform(-0.5, 0.5)\n",
        "    y = random.uniform(-0.5, 0.5)\n",
        "    if (np.sqrt(x*x + y*y) < 0.5):\n",
        "        Nin += 1\n",
        "res = np.array(Nin, dtype='d')\n",
        "res_tot = np.array(Nin, dtype='d')\n",
        "comm.Allreduce(res, res_tot, op=MPI.SUM)\n",
        "t1 = time.time()\n",
        "if comm.rank==0:\n",
        "    print(res_tot/float(N/4.0))\n",
        "    print(\"Time: %s\" %(t1 - t0))\n",
        "```\n",
        "\n",
        "### Running $\\pi$ example on Google Colab\n",
        "* Go to https://colab.research.google.com/, sign in or sign up\n",
        "* \"File\"-> \"open notebook\"\n",
        "* choose ```01_intro_AI_on_Supercomputer/00_mpi.ipynb``` from the list\n",
        "![Google Colab](../figures/colab.png)"
      ],
      "id": "8b2fb792"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "! wget https://raw.githubusercontent.com/argonne-lcf/ai-science-training-series/main/01_intro_AI_on_Supercomputer/mpi_pi.py\n",
        "! pip install mpi4py"
      ],
      "id": "636fd0e2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "! mpirun -np 1 --allow-run-as-root python mpi_pi.py"
      ],
      "id": "dfc6d811",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "! mpirun -np 2 --allow-run-as-root --oversubscribe python mpi_pi.py"
      ],
      "id": "c4ffb327",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "! mpirun -np 4 --allow-run-as-root --oversubscribe python mpi_pi.py"
      ],
      "id": "5a0b72f0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Running $\\pi$ on Polaris\n",
        "```bash\n",
        "ssh <username>@polaris.alcf.anl.gov\n",
        "qsub -A ALCFAITP -l select=1 -q ALCFAITP -l walltime=0:30:00 -l filesystems=home:eagle\n",
        "# choose debug queue outside of the class\n",
        "# qsub -A ALCFAITP -l select=1 -q debug -l walltime=0:30:00 -l filesystems=home:eagle\n",
        "\n",
        "module load conda/2023-10-04\n",
        "conda activate /soft/datascience/ALCFAITP/2023-10-04\n",
        "git clone git@github.com:argonne-lcf/ai-science-training-series.git\n",
        "cd ai-science-training-series/01_intro_AI_on_Supercomputer/\n",
        "mpirun -np 1 python mpi_pi.py   # 3.141988,   8.029037714004517  s\n",
        "mpirun -np 2 python mpi_pi.py   # 3.1415096   4.212774038314819  s\n",
        "mpirun -np 4 python mpi_pi.py   # 3.1425632   2.093632459640503  s\n",
        "mpirun -np 8 python mpi_pi.py   # 3.1411632   1.0610620975494385 s\n",
        "```\n",
        "\n",
        "**Attention: Please use ```debug``` queue outside of lecture time instead of ```ALCFAITP```.** \n",
        "\n",
        "## Parallel computing in AI\n",
        "The parallel computing in AI is usually called distributed training. Distributed training is the process of training I models across multiple GPUs or other accelerators, with the goal of speeding up the training process and enabling the training of larger models on larger datasets.\n",
        "\n",
        "There are two ways of parallelization in distributed training. \n",
        "* **Data parallelism**: \n",
        "    * Each worker (GPU) has a complete set of model\n",
        "    * different workers work on different subsets of data. \n",
        "* **Model parallelism** \n",
        "    * The model is splitted into different parts and stored on different workers\n",
        "    * Different workers work on computation involved in different parts of the model\n",
        "![PI](../figures/parallel_computing.png)\n",
        "\n",
        "![3D LLM](../figures/3DLLM.png)\n"
      ],
      "id": "6b8d01d9"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}