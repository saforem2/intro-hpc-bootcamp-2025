<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.17">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Sam Foreman">
<meta name="dcterms.date" content="2025-07-22">

<title>Introduction To Sequential Data Modeling – Intro to HPC Bootcamp 2025</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-1ba5600575b524666f3a728b03aeaa80.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-0434ab73b344d2590fb99d65eafd6ba5.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-d390ef2c999da7b376b2b53b4e33de94.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../../site_libs/bootstrap/bootstrap-dark-ad57ad1ea03c766bc722c08932ed62e2.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../../../../site_libs/quarto-contrib/iconify-3.0.0/iconify-icon.min.js"></script>
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "?",
    "H"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css" integrity="sha384-5TcZemv2l/9On385z///+d7MSYlvIEw9FuZTIdZ14vJLqWphw7e7ZPuOiCHJcFCP" crossorigin="anonymous">

<!-- The loading of KaTeX is deferred to speed up page rendering -->
<script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.js" integrity="sha384-cMkvdD8LoxVzGF/RPUKAcvmm49FQ0oxwDF3BGKtDXcEc+T1b2N+teh/OJfpU0jr6" crossorigin="anonymous"></script>

<!-- To automatically render math in text elements, include the auto-render extension: -->
<script defer="" src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/auto-render.min.js" integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&amp;family=IBM+Plex+Sans+Condensed:ital,wght@0,400;0,500;0,600;0,700&amp;family=IBM+Plex+Mono:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700&amp;display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=IBM+Plex+Sans&amp;family=IBM+Plex+Sans+Condensed&amp;family=IBM+Plex+Mono&amp;display=swap" rel="stylesheet">
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-TC329HJ');</script>
<!-- End Google Tag Manager -->
<link rel="preconnect" href="https://fonts.googleapis.com">

  <script defer="" src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../../static/fonts/MIosevkaQp/MIosevkaQp.css">
<link rel="stylesheet" href="../../../../static/fonts/MIosevkaterm/MIosevkaTerm.css">
<meta property="og:title" content="Introduction To Sequential Data Modeling – Intro to HPC Bootcamp 2025">
<meta property="og:description" content="An introduction to High Performance Computing (HPC) and Artificial Intelligence (AI) for scientific applications, with a focus on practical skills and hands-on experience.">
<meta property="og:image" content="https://saforem2.github.io/hpc-bootcamp-2025/content/02-llms/0-intro-to-llms/OLD/Figures/CIFAR-10.png">
<meta property="og:site_name" content="Intro to HPC Bootcamp 2025">
<meta property="og:image:height" content="894">
<meta property="og:image:width" content="1176">
<meta name="twitter:title" content="Introduction To Sequential Data Modeling – Intro to HPC Bootcamp 2025">
<meta name="twitter:description" content="An introduction to High Performance Computing (HPC) and Artificial Intelligence (AI) for scientific applications, with a focus on practical skills and hands-on experience.">
<meta name="twitter:image" content="https://saforem2.github.io/hpc-bootcamp-2025/content/02-llms/0-intro-to-llms/OLD/Figures/CIFAR-10.png">
<meta name="twitter:site" content="saforem2">
<meta name="twitter:image-height" content="894">
<meta name="twitter:image-width" content="1176">
<meta name="twitter:card" content="summary_large_image">
<meta name="citation_title" content="Introduction To Sequential Data Modeling">
<meta name="citation_author" content="Sam Foreman">
<meta name="citation_publication_date" content="2025-07-22">
<meta name="citation_cover_date" content="2025-07-22">
<meta name="citation_year" content="2025">
<meta name="citation_online_date" content="2025-07-22">
<meta name="citation_fulltext_html_url" content="https://saforem2.github.io/hpc-bootcamp-2025/content/02-llms/0-intro-to-llms/OLD/Sequential_Data_Models.html">
<meta name="citation_language" content="en">
<meta name="citation_reference" content="citation_title=HiPerRAG: High-performance retrieval augmented generation for scientific insights;,citation_author=Ozan Gokdemir;,citation_author=Carlo Siebenschuh;,citation_author=Alexander Brace;,citation_author=Azton Wells;,citation_author=Brian Hsu;,citation_author=Kyle Hippe;,citation_author=Priyanka V. Setty;,citation_author=Aswathy Ajith;,citation_author=J. Gregory Pauloski;,citation_author=Varuni Sastry;,citation_author=Sam Foreman;,citation_author=Huihuo Zheng;,citation_author=Heng Ma;,citation_author=Bharat Kale;,citation_author=Nicholas Chia;,citation_author=Thomas Gibbs;,citation_author=Michael E. Papka;,citation_author=Thomas Brettin;,citation_author=Francis J. Alexander;,citation_author=Anima Anandkumar;,citation_author=Ian Foster;,citation_author=Rick Stevens;,citation_author=Venkatram Vishwanath;,citation_author=Arvind Ramanathan;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_fulltext_html_url=https://arxiv.org/abs/2505.04846;">
<meta name="citation_reference" content="citation_title=MOFA: Discovering materials for carbon capture with a GenAI- and simulation-based workflow;,citation_author=Xiaoli Yan;,citation_author=Nathaniel Hudson;,citation_author=Hyun Park;,citation_author=Daniel Grzenda;,citation_author=J. Gregory Pauloski;,citation_author=Marcus Schwarting;,citation_author=Haochen Pan;,citation_author=Hassan Harb;,citation_author=Samuel Foreman;,citation_author=Chris Knight;,citation_author=Tom Gibbs;,citation_author=Kyle Chard;,citation_author=Santanu Chaudhuri;,citation_author=Emad Tajkhorshid;,citation_author=Ian Foster;,citation_author=Mohamad Moosavi;,citation_author=Logan Ward;,citation_author=E. A. Huerta;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_fulltext_html_url=https://arxiv.org/abs/2501.10651;">
<meta name="citation_reference" content="citation_title=MProt-DPO: Breaking the ExaFLOPS barrier for multimodal protein design workflows with direct preference optimization;,citation_abstract=We present a scalable, end-to-end workflow for protein design. By augmenting protein sequences with natural language descriptions of their biochemical properties, we train generative models that can be preferentially aligned with protein fitness landscapes. Through complex experimental- and simulation-based observations, we integrate these measures as preferred parameters for generating new protein variants and demonstrate our workflow on five diverse supercomputers. We achieve &amp;amp;amp;gt;1 ExaFLOPS sustained performance in mixed precision on each supercomputer and a maximum sustained performance of 4.11 ExaFLOPS and peak performance of 5.57 ExaFLOPS. We establish the scientific performance of our model on two tasks: (1) across a predetermined benchmark dataset of deep mutational scanning experiments to optimize the fitness-determining mutations in the yeast protein HIS7, and (2) in optimizing the design of the enzyme malate dehydrogenase to achieve lower activation barriers (and therefore increased catalytic rates) using simulation data. Our implementation thus sets high watermarks for multimodal protein design workflows.;,citation_author=Gautham Dharuman;,citation_author=Kyle Hippe;,citation_author=Alexander Brace;,citation_author=Sam Foreman;,citation_author=Väinö Hatanpää;,citation_author=Varuni K. Sastry;,citation_author=Huihuo Zheng;,citation_author=Logan Ward;,citation_author=Servesh Muralidharan;,citation_author=Archit Vasan;,citation_author=Bharat Kale;,citation_author=Carla M. Mann;,citation_author=Heng Ma;,citation_author=Yun-Hsuan Cheng;,citation_author=Yuliana Zamora;,citation_author=Shengchao Liu;,citation_author=Chaowei Xiao;,citation_author=Murali Emani;,citation_author=Tom Gibbs;,citation_author=Mahidhar Tatineni;,citation_author=Deepak Canchi;,citation_author=Jerome Mitchell;,citation_author=Koichi Yamada;,citation_author=Maria Garzaran;,citation_author=Michael E. Papka;,citation_author=Ian Foster;,citation_author=Rick Stevens;,citation_author=Anima Anandkumar;,citation_author=Venkatram Vishwanath;,citation_author=Arvind Ramanathan;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://doi.org/10.1109/SC41406.2024.00013;,citation_doi=10.1109/SC41406.2024.00013;,citation_isbn=9798350352917;,citation_conference_title=Proceedings of the international conference for high performance computing, networking, storage, and analysis;,citation_conference=IEEE Press;,citation_series_title=SC ’24;">
<meta name="citation_reference" content="citation_title=Quality measures for dynamic graph generative models;,citation_author=Ryien Hosseini;,citation_author=Filippo Simini;,citation_author=Venkatram Vishwanath;,citation_author=Rebecca Willett;,citation_author=Henry Hoffmann;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_fulltext_html_url=https://openreview.net/forum?id=8bjspmAMBk;,citation_conference_title=The thirteenth international conference on learning representations;">
<meta name="citation_reference" content="citation_title=Superconductivity of in and sn samples;,citation_author=George Deamont;,citation_author=Sam Foreman;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=RG-inspired machine learning for lattice field theory;,citation_author=Sam Foreman;,citation_author=Joel Giedt;,citation_author=Yannick Meurice;,citation_author=Judah Unmuth-Yockey;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_volume=175;,citation_conference_title=EPJ web of conferences;,citation_conference=EDP Sciences;">
<meta name="citation_reference" content="citation_title=Large energy density in three-plate nanocapacitors due to coulomb blockade;,citation_author=A Hubler;,citation_author=S Foreman;,citation_author=J Liu;,citation_author=L Wortsmann;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=10;,citation_volume=123;,citation_journal_title=Journal of Applied Physics;,citation_publisher=AIP Publishing;">
<meta name="citation_reference" content="citation_title=Examples of renormalization group transformations for image sets;,citation_author=Samuel Foreman;,citation_author=Joel Giedt;,citation_author=Yannick Meurice;,citation_author=Judah Unmuth-Yockey;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=5;,citation_volume=98;,citation_journal_title=Physical Review E;,citation_publisher=American Physical Society;">
<meta name="citation_reference" content="citation_title=Machine learning inspired analysis of the Ising model transition;,citation_author=Samuel Foreman;,citation_author=Joel Giedt;,citation_author=Yannick Meurice;,citation_author=Judah Unmuth-Yockey;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_doi=10.22323/1.334.0245;,citation_volume=LATTICE2018;,citation_journal_title=PoS;">
<meta name="citation_reference" content="citation_title=Machine learning inspired analysis of the ising model transition;,citation_author=Samuel Foreman;,citation_author=Joel Giedt;,citation_author=Yannick Meurice;,citation_author=Judah Unmuth-Yockey;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_conference_title=Lattice 2018;">
<meta name="citation_reference" content="citation_title=Learning better physics: A machine learning approach to lattice gauge theory;,citation_author=Samuel Alfred Foreman;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_dissertation_institution=University of Iowa;">
<meta name="citation_reference" content="citation_title=Machine learning and neural networks for field theory;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;">
<meta name="citation_reference" content="citation_title=HMC with normalizing flows;,citation_author=Sam Foreman;,citation_author=Taku Izubuchi;,citation_author=Luchang Jin;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_author=Akio Tomiya;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01586;,citation_journal_title=arXiv preprint arXiv:2112.01586;">
<meta name="citation_reference" content="citation_title=LeapfrogLayers: A trainable framework for effective topological sampling;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01582;,citation_journal_title=arXiv preprint arXiv:2112.01582;">
<meta name="citation_reference" content="citation_title=Energy storage in quantum resonators;,citation_author=Jiaqi Liu;,citation_author=Alfred W Hubler;,citation_author=Samuel Alfred Foreman;,citation_author=Katharina Ott;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=Applications of machine learning to lattice quantum field theory;,citation_author=Denis Boyda;,citation_author=Salvatore Calı̀;,citation_author=Sam Foreman;,citation_author=Lena Funcke;,citation_author=Daniel C Hackett;,citation_author=Yin Lin;,citation_author=Gert Aarts;,citation_author=Andrei Alexandru;,citation_author=Xiao-Yong Jin;,citation_author=Biagio Lucini;,citation_author=others;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2202.05838;,citation_journal_title=arXiv preprint arXiv:2202.05838;">
<meta name="citation_reference" content="citation_title=Lattice QCD and particle physics;,citation_author=Andreas S Kronfeld;,citation_author=Tanmoy Bhattacharya;,citation_author=Thomas Blum;,citation_author=Norman H Christ;,citation_author=Carleton DeTar;,citation_author=William Detmold;,citation_author=Robert Edwards;,citation_author=Anna Hasenfratz;,citation_author=Huey-Wen Lin;,citation_author=Swagato Mukherjee;,citation_author=others;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2207.07641;,citation_journal_title=arXiv preprint arXiv:2207.07641;">
<meta name="citation_reference" content="citation_title=GenSLMs: Genome-scale language models reveal SARS-CoV-2 evolutionary dynamics;,citation_author=Maxim Zvyagin;,citation_author=Alexander Brace;,citation_author=Kyle Hippe;,citation_author=Yuntian Deng;,citation_author=Bin Zhang;,citation_author=Cindy Orozco Bohorquez;,citation_author=Austin Clyde;,citation_author=Bharat Kale;,citation_author=Danilo Perez-Rivera;,citation_author=Heng Ma;,citation_author=others;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_issue=6;,citation_volume=37;,citation_journal_title=The International Journal of High Performance Computing Applications;,citation_publisher=SAGE Publications Sage UK: London, England;">
<meta name="citation_reference" content="citation_title=MLMC: Machine learning monte carlo;,citation_author=Sam Foreman;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_conference_title=The international symposium on lattice field theory;">
<meta name="citation_reference" content="citation_title=Superconductivity of in and sn samples;,citation_author=George Deamont;,citation_author=Sam Foreman;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=A comprehensive performance study of large language models on novel AI accelerators;,citation_author=Murali Emani;,citation_author=Sam Foreman;,citation_author=Varuni Sastry;,citation_author=Zhen Xie;,citation_author=Siddhisanket Raskar;,citation_author=William Arnold;,citation_author=Rajeev Thakur;,citation_author=Venkatram Vishwanath;,citation_author=Michael E Papka;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2310.04607;,citation_journal_title=arXiv preprint arXiv:2310.04607;">
<meta name="citation_reference" content="citation_title=DeepSpeed4Science initiative: Enabling large-scale scientific discovery through sophisticated AI system technologies;,citation_author=Shuaiwen Leon Song;,citation_author=Bonnie Kruft;,citation_author=Minjia Zhang;,citation_author=Conglong Li;,citation_author=Shiyang Chen;,citation_author=Chengming Zhang;,citation_author=Masahiro Tanaka;,citation_author=Xiaoxia Wu;,citation_author=Jeff Rasley;,citation_author=Ammar Ahmad Awan;,citation_author=others;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2310.04610;,citation_journal_title=arXiv preprint arXiv:2310.04610;">
<meta name="citation_reference" content="citation_title=Protein generation via genome-scale language models with bio-physical scoring;,citation_author=Gautham Dharuman;,citation_author=Logan Ward;,citation_author=Heng Ma;,citation_author=Priyanka V Setty;,citation_author=Ozan Gokdemir;,citation_author=Sam Foreman;,citation_author=Murali Emani;,citation_author=Kyle Hippe;,citation_author=Alexander Brace;,citation_author=Kristopher Keipert;,citation_author=others;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_conference_title=Proceedings of the SC’23 workshops of the international conference on high performance computing, network, storage, and analysis;">
<meta name="citation_reference" content="citation_title=MLMC: Machine learning monte carlo for lattice gauge theory;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2312.08936;,citation_journal_title=arXiv preprint arXiv:2312.08936;">
<meta name="citation_reference" content="citation_title=Snowmass 2021 computational frontier CompF03 topical group report: Machine learning;,citation_author=Phiala Shanahan;,citation_author=Kazuhiro Terao;,citation_author=Daniel Whiteson;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2209.07559;,citation_journal_title=arXiv preprint arXiv:2209.07559;">
<meta name="citation_reference" content="citation_title=Thorough characterization and analysis of large transformer model training at-scale;,citation_author=Scott Cheng;,citation_author=Jun-Liang Lin;,citation_author=Murali Emani;,citation_author=Siddhisanket Raskar;,citation_author=Sam Foreman;,citation_author=Zhen Xie;,citation_author=Venkatram Vishwanath;,citation_author=Mahmut Taylan Kandemir;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_issue=1;,citation_volume=8;,citation_journal_title=Proceedings of the ACM on Measurement and Analysis of Computing Systems;,citation_publisher=ACM New York, NY, USA;">
<meta name="citation_reference" content="citation_title=Communities through energy justice projects;,citation_author=Mary Ann Leung;,citation_author=Katharine Cahill;,citation_author=Rebecca Hartman-Baker;,citation_author=Paige Kinsley;,citation_author=Lois Curfman McInnes;,citation_author=Suzanne Parete-Koon;,citation_author=Subil Abraham;,citation_author=Lacy Beach Barrier;,citation_author=Gladys Chen;,citation_author=Lizanne DeStefano;,citation_author=others;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_issue=1;,citation_volume=15;,citation_journal_title=Journal of Computational Science;">
<meta name="citation_reference" content="citation_title=Applications of a foundation model approach for weather and climate;,citation_author=Troy Arcomano;,citation_author=Alexander Wikner;,citation_author=Romit Maulik;,citation_author=Veerabhadra Rao Kotamarthi;,citation_author=Sam Foreman;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_volume=2023;,citation_conference_title=AGU fall meeting abstracts;">
<meta name="citation_reference" content="citation_title=Toward a holistic performance evaluation of large language models across diverse ai accelerators;,citation_author=Murali Emani;,citation_author=Sam Foreman;,citation_author=Varuni Sastry;,citation_author=Zhen Xie;,citation_author=Siddhisanket Raskar;,citation_author=William Arnold;,citation_author=Rajeev Thakur;,citation_author=Venkatram Vishwanath;,citation_author=Michael E Papka;,citation_author=Sanjif Shanmugavelu;,citation_author=others;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_conference_title=2024 IEEE international parallel and distributed processing symposium workshops (IPDPSW);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Intro to HPC bootcamp: Engaging new communities through energy justice projects;,citation_author=Suzanne Parete-Koon;,citation_author=Michael Sandoval;,citation_author=Kellen Leland;,citation_author=Subil Abraham;,citation_author=Mary Ann Leung;,citation_author=Rebecca Hartman-Baker;,citation_author=Paige Kinsley;,citation_author=Lois McInnes;,citation_author=Sreeranjani Ramprakash;,citation_author=Lacy Beach Barrier;,citation_author=others;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_issue=1;,citation_volume=15;,citation_journal_title=Journal of Computational Science Education;,citation_publisher=Oak Ridge National Laboratory (ORNL), Oak Ridge, TN (United States);">
<meta name="citation_reference" content="citation_title=MProt-DPO: Breaking the ExaFLOPS barrier for multimodal protein design workflows with direct preference optimization;,citation_author=Gautham Dharuman;,citation_author=Kyle Hippe;,citation_author=Alexander Brace;,citation_author=Sam Foreman;,citation_author=Väinä Hatanpää;,citation_author=Varuni K Sastry;,citation_author=Huihuo Zheng;,citation_author=Logan Ward;,citation_author=Servesh Muralidharan;,citation_author=Archit Vasan;,citation_author=others;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_conference_title=2024 SC24: International conference for high performance computing, networking, storage and analysis SC;,citation_conference=IEEE Computer Society;">
<meta name="citation_reference" content="citation_title=Emergent abilities of large language models;,citation_author=Jason Wei;,citation_author=Yi Tay;,citation_author=Rishi Bommasani;,citation_author=Colin Raffel;,citation_author=Barret Zoph;,citation_author=Sebastian Borgeaud;,citation_author=Dani Yogatama;,citation_author=Maarten Bosma;,citation_author=Denny Zhou;,citation_author=Donald Metzler;,citation_author=Ed H. Chi;,citation_author=Tatsunori Hashimoto;,citation_author=Oriol Vinyals;,citation_author=Percy Liang;,citation_author=Jeff Dean;,citation_author=William Fedus;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2206.07682;">
<meta name="citation_reference" content="citation_title=DeepSpeed4Science initiative: Enabling large-scale scientific discovery through sophisticated AI system technologies;,citation_author=Shuaiwen Leon Song;,citation_author=Bonnie Kruft;,citation_author=Minjia Zhang;,citation_author=Conglong Li;,citation_author=Shiyang Chen;,citation_author=Chengming Zhang;,citation_author=Masahiro Tanaka;,citation_author=Xiaoxia Wu;,citation_author=Jeff Rasley;,citation_author=Ammar Ahmad Awan;,citation_author=Connor Holmes;,citation_author=Martin Cai;,citation_author=Adam Ghanem;,citation_author=Zhongzhu Zhou;,citation_author=Yuxiong He;,citation_author=Pete Luferenko;,citation_author=Divya Kumar;,citation_author=Jonathan Weyn;,citation_author=Ruixiong Zhang;,citation_author=Sylwester Klocek;,citation_author=Volodymyr Vragov;,citation_author=Mohammed AlQuraishi;,citation_author=Gustaf Ahdritz;,citation_author=Christina Floristean;,citation_author=Cristina Negri;,citation_author=Rao Kotamarthi;,citation_author=Venkatram Vishwanath;,citation_author=Arvind Ramanathan;,citation_author=Sam Foreman;,citation_author=Kyle Hippe;,citation_author=Troy Arcomano;,citation_author=Romit Maulik;,citation_author=Maxim Zvyagin;,citation_author=Alexander Brace;,citation_author=Bin Zhang;,citation_author=Cindy Orozco Bohorquez;,citation_author=Austin Clyde;,citation_author=Bharat Kale;,citation_author=Danilo Perez-Rivera;,citation_author=Heng Ma;,citation_author=Carla M. Mann;,citation_author=Michael Irvin;,citation_author=J. Gregory Pauloski;,citation_author=Logan Ward;,citation_author=Valerie Hayot;,citation_author=Murali Emani;,citation_author=Zhen Xie;,citation_author=Diangen Lin;,citation_author=Maulik Shukla;,citation_author=Ian Foster;,citation_author=James J. Davis;,citation_author=Michael E. Papka;,citation_author=Thomas Brettin;,citation_author=Prasanna Balaprakash;,citation_author=Gina Tourassi;,citation_author=John Gounley;,citation_author=Heidi Hanson;,citation_author=Thomas E Potok;,citation_author=Massimiliano Lupo Pasini;,citation_author=Kate Evans;,citation_author=Dan Lu;,citation_author=Dalton Lunga;,citation_author=Junqi Yin;,citation_author=Sajal Dash;,citation_author=Feiyi Wang;,citation_author=Mallikarjun Shankar;,citation_author=Isaac Lyngaas;,citation_author=Xiao Wang;,citation_author=Guojing Cong;,citation_author=Pei Zhang;,citation_author=Ming Fan;,citation_author=Siyan Liu;,citation_author=Adolfy Hoisie;,citation_author=Shinjae Yoo;,citation_author=Yihui Ren;,citation_author=William Tang;,citation_author=Kyle Felker;,citation_author=Alexey Svyatkovskiy;,citation_author=Hang Liu;,citation_author=Ashwin Aji;,citation_author=Angela Dalton;,citation_author=Michael Schulte;,citation_author=Karl Schulz;,citation_author=Yuntian Deng;,citation_author=Weili Nie;,citation_author=Josh Romero;,citation_author=Christian Dallago;,citation_author=Arash Vahdat;,citation_author=Chaowei Xiao;,citation_author=Thomas Gibbs;,citation_author=Anima Anandkumar;,citation_author=Rick Stevens;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2310.04610;">
<meta name="citation_reference" content="citation_title=Emergent abilities of large language models;,citation_author=Jason Wei;,citation_author=Yi Tay;,citation_author=Rishi Bommasani;,citation_author=Colin Raffel;,citation_author=Barret Zoph;,citation_author=Sebastian Borgeaud;,citation_author=Dani Yogatama;,citation_author=Maarten Bosma;,citation_author=Denny Zhou;,citation_author=Donald Metzler;,citation_author=Ed H. Chi;,citation_author=Tatsunori Hashimoto;,citation_author=Oriol Vinyals;,citation_author=Percy Liang;,citation_author=Jeff Dean;,citation_author=William Fedus;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2206.07682;">
<meta name="citation_reference" content="citation_title=The climate risk &amp;amp;amp; resilience portal (ClimRR) metadata and data dictionary;,citation_author=C. Burdi;,citation_author=Wall. T Branham;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://dub.sh/ClimRR-Metadata;">
<meta name="citation_reference" content="citation_title=Progress on $(g-2)_\mu$ from lattice QCD;,citation_author=Hartmut Wittig;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2306.04165;">
<meta name="citation_reference" content="citation_title=Hybrid Monte Carlo;,citation_author=S. Duane;,citation_author=A. D. Kennedy;,citation_author=B. J. Pendleton;,citation_author=D. Roweth;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;,citation_doi=10.1016/0370-2693(87)91197-X;,citation_volume=195;,citation_journal_title=Phys. Lett. B;">
<meta name="citation_reference" content="citation_title=Snowmass 2021 Computational Frontier CompF03 Topical Group Report: Machine Learning;,citation_author=Phiala Shanahan;,citation_author=others;,citation_publication_date=2022-09;,citation_cover_date=2022-09;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2209.07559;">
<meta name="citation_reference" content="citation_title=Applications of Machine Learning to Lattice Quantum Field Theory;,citation_author=Denis Boyda;,citation_author=others;,citation_publication_date=2022-02;,citation_cover_date=2022-02;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2202.05838;,citation_conference_title=Snowmass 2021;">
<meta name="citation_reference" content="citation_title=HMC with Normalizing Flows;,citation_author=Sam Foreman;,citation_author=Taku Izubuchi;,citation_author=Luchang Jin;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_author=Akio Tomiya;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01586;,citation_doi=10.22323/1.396.0073;,citation_volume=LATTICE2021;,citation_journal_title=PoS;">
<meta name="citation_reference" content="citation_title=LeapfrogLayers: A Trainable Framework for Effective Topological Sampling;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01582;,citation_doi=10.22323/1.396.0508;,citation_volume=LATTICE2021;,citation_journal_title=PoS;">
<meta name="citation_reference" content="citation_title=Deep Learning Hamiltonian Monte Carlo;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2021-05;,citation_cover_date=2021-05;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2105.03418;,citation_conference_title=9th International Conference on Learning Representations;">
<meta name="citation_reference" content="citation_title=Deep learning hamiltonian monte carlo;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2105.03418;">
<meta name="citation_reference" content="citation_title=Deep Learning Hamiltonian Monte Carlo;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2021-05;,citation_cover_date=2021-05;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2105.03418;,citation_conference_title=9th International Conference on Learning Representations;">
<meta name="citation_reference" content="citation_title=Deep learning hamiltonian monte carlo;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=arXiv preprint arXiv:2105.03418;">
<meta name="citation_reference" content="citation_title=LeapfrogLayers: A trainable framework for effective topological sampling;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=arXiv preprint arXiv:2112.01582;">
<meta name="citation_reference" content="citation_title=Energy Justice Analysis of Climate Data with ClimRR;,citation_author=Sam Foreman;,citation_publication_date=2023-08-07;,citation_cover_date=2023-08-07;,citation_year=2023;,citation_fulltext_html_url=https://saforem2.github.io/climate-analysis;,citation_language=en;">
<meta name="citation_reference" content="citation_author=Sam Foreman;,citation_publication_date=2023-08-19;,citation_cover_date=2023-08-19;,citation_year=2023;,citation_fulltext_html_url=https://saforem2.github.io/l2hmc-qcd;,citation_language=en;">
<meta name="citation_reference" content="citation_title=MLMC: Machine learning monte carlo for lattice gauge theory;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James Osborn;,citation_publication_date=00;,citation_cover_date=00;,citation_year=0;,citation_conference_title=40th international symposium on lattice field theory (lattice 2023) (batavia, IL, united states, 07/31/2023 - 08/04/2023);">
<meta name="citation_reference" content="citation_title=Progress on $(g-2)_\mu$ from lattice QCD;,citation_author=Hartmut Wittig;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2306.04165;">
<meta name="citation_reference" content="citation_title=Hybrid Monte Carlo;,citation_author=S. Duane;,citation_author=A. D. Kennedy;,citation_author=B. J. Pendleton;,citation_author=D. Roweth;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;,citation_doi=10.1016/0370-2693(87)91197-X;,citation_volume=195;,citation_journal_title=Phys. Lett. B;">
<meta name="citation_reference" content="citation_title=Snowmass 2021 Computational Frontier CompF03 Topical Group Report: Machine Learning;,citation_author=Phiala Shanahan;,citation_author=others;,citation_publication_date=2022-09;,citation_cover_date=2022-09;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2209.07559;">
<meta name="citation_reference" content="citation_title=Applications of Machine Learning to Lattice Quantum Field Theory;,citation_author=Denis Boyda;,citation_author=others;,citation_publication_date=2022-02;,citation_cover_date=2022-02;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2202.05838;,citation_conference_title=Snowmass 2021;">
<meta name="citation_reference" content="citation_title=LeapfrogLayers: A Trainable Framework for Effective Topological Sampling;,citation_author=S. Foreman;,citation_author=X. Jin;,citation_author=J. Osborn;,citation_publication_date=2022-07;,citation_cover_date=2022-07;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01582;,citation_doi=10.22323/1.396.0508;,citation_conference_title=The 38th international symposium on lattice field theory;">
<meta name="citation_reference" content="citation_title=HMC with Normalizing Flows;,citation_author=Sam Foreman;,citation_author=Taku Izubuchi;,citation_author=Luchang Jin;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_author=Akio Tomiya;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01586;,citation_doi=10.22323/1.396.0073;,citation_volume=LATTICE2021;,citation_journal_title=PoS;">
<meta name="citation_reference" content="citation_title=Mastering language models;,citation_author=Samuel Montgomery;,citation_publication_date=2023-10;,citation_cover_date=2023-10;,citation_year=2023;,citation_fulltext_html_url=https://towardsdatascience.com/mastering-language-models-32e1d891511a
           ;,citation_journal_title=Medium;,citation_publisher=Towards Data Science;">
<meta name="citation_reference" content="citation_title=Harnessing the power of LLMs in practice: A survey on ChatGPT and beyond;,citation_author=Jingfeng Yang;,citation_author=Hongye Jin;,citation_author=Ruixiang Tang;,citation_author=Xiaotian Han;,citation_author=Qizhang Feng;,citation_author=Haoming Jiang;,citation_author=Bing Yin;,citation_author=Xia Hu;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2304.13712;">
<meta name="citation_reference" content="citation_title=Training tips for the transformer model;,citation_author=Martin Popel;,citation_author=Ondřej Bojar;,citation_publication_date=2018-04;,citation_cover_date=2018-04;,citation_year=2018;,citation_fulltext_html_url=https://doi.org/10.2478%2Fpralin-2018-0002;,citation_issue=1;,citation_doi=10.2478/pralin-2018-0002;,citation_volume=110;,citation_journal_title=The Prague Bulletin of Mathematical Linguistics;,citation_publisher=Charles University in Prague, Karolinum Press;">
<meta name="citation_reference" content="citation_title=Attention is all you need;,citation_author=Ashish Vaswani;,citation_author=Noam Shazeer;,citation_author=Niki Parmar;,citation_author=Jakob Uszkoreit;,citation_author=Llion Jones;,citation_author=Aidan N. Gomez;,citation_author=Lukasz Kaiser;,citation_author=Illia Polosukhin;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_fulltext_html_url=https://arxiv.org/abs/1706.03762;">
<meta name="citation_reference" content="citation_title=Tree of thoughts: Deliberate problem solving with large language models;,citation_author=Shunyu Yao;,citation_author=Dian Yu;,citation_author=Jeffrey Zhao;,citation_author=Izhak Shafran;,citation_author=Thomas L. Griffiths;,citation_author=Yuan Cao;,citation_author=Karthik Narasimhan;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2305.10601;">
<meta name="citation_reference" content="citation_title=GenSLMs: Genome-scale language models reveal SARS-CoV-2 evolutionary dynamics;,citation_abstract=We seek to transform how new and emergent variants of pandemiccausing viruses, specifically SARS-CoV-2, are identified and classified. By adapting large language models (LLMs) for genomic data, we build genome-scale language models (GenSLMs) which can learn the evolutionary landscape of SARS-CoV-2 genomes. By pretraining on over 110 million prokaryotic gene sequences and finetuning a SARS-CoV-2-specific model on 1.5 million genomes, we show that GenSLMs can accurately and rapidly identify variants of concern. Thus, to our knowledge, GenSLMs represents one of the first whole genome scale foundation models which can generalize to other prediction tasks. We demonstrate scaling of GenSLMs on GPU-based supercomputers and AI-hardware accelerators utilizing 1.63 Zettaflops in training runs with a sustained performance of 121 PFLOPS in mixed precision and peak of 850 PFLOPS. We present initial scientific insights from examining GenSLMs in tracking evolutionary dynamics of SARS-CoV-2, paving the path to realizing this on large biological data.Competing Interest StatementThe authors have declared no competing interest.;,citation_author=Maxim Zvyagin;,citation_author=Alexander Brace;,citation_author=Kyle Hippe;,citation_author=Yuntian Deng;,citation_author=Bin Zhang;,citation_author=Cindy Orozco Bohorquez;,citation_author=Austin Clyde;,citation_author=Bharat Kale;,citation_author=Danilo Perez-Rivera;,citation_author=Heng Ma;,citation_author=Carla M. Mann;,citation_author=Michael Irvin;,citation_author=J. Gregory Pauloski;,citation_author=Logan Ward;,citation_author=Valerie Hayot-Sasson;,citation_author=Murali Emani;,citation_author=Sam Foreman;,citation_author=Zhen Xie;,citation_author=Diangen Lin;,citation_author=Maulik Shukla;,citation_author=Weili Nie;,citation_author=Josh Romero;,citation_author=Christian Dallago;,citation_author=Arash Vahdat;,citation_author=Chaowei Xiao;,citation_author=Thomas Gibbs;,citation_author=Ian Foster;,citation_author=James J. Davis;,citation_author=Michael E. Papka;,citation_author=Thomas Brettin;,citation_author=Rick Stevens;,citation_author=Anima Anandkumar;,citation_author=Venkatram Vishwanath;,citation_author=Arvind Ramanathan;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://www.biorxiv.org/content/early/2022/11/23/2022.10.10.511571;,citation_doi=10.1101/2022.10.10.511571;,citation_journal_title=bioRxiv;,citation_publisher=Cold Spring Harbor Laboratory;">
</head>

<body class="nav-sidebar floating nav-fixed quarto-dark"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = true;
    const queryPrefersDark = window.matchMedia('(prefers-color-scheme: dark)');
    const darkModeDefault = queryPrefersDark.matches;
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    queryPrefersDark.addEventListener("change", e => {
      if(window.localStorage.getItem("quarto-color-scheme") !== null)
        return;
      const alternate = e.matches
      toggleColorMode(alternate);
      localAlternateSentinel = e.matches ? 'alternate' : 'default'; // this is used alongside local storage!
      toggleGiscusIfUsed(alternate, darkModeDefault);
    });
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../../index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="../../../../index.html">
    <span class="navbar-title">Intro to HPC Bootcamp 2025</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/saforem2/intro-hpc-bootcamp-2025"> 
<span class="menu-text"><span class="icon" style="font-size: 1.25rem; color:var(--bs-nav-link-color);"><iconify-icon role="img" inline="" icon="ph:github-logo" aria-label="Icon github-logo from ph Iconify.design set." title="Icon github-logo from ph Iconify.design set."></iconify-icon></span></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../index.xml"> 
<span class="menu-text"><span class="icon" style="font-size: 1.25rem; color:var(--bs-nav-link-color);"><iconify-icon role="img" inline="" icon="ph:rss" aria-label="Icon rss from ph Iconify.design set." title="Icon rss from ph Iconify.design set."></iconify-icon></span></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Introduction To Sequential Data Modeling</li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
      <a href="../../../../index.html" class="sidebar-logo-link">
      </a>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../content/00-intro-AI-HPC/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[00] Intro to AI and HPC</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../content/00-intro-AI-HPC/0-compute-systems/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[0] Compute Systems</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../content/00-intro-AI-HPC/1-shared-resources/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[1] Shared Resources</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../content/00-intro-AI-HPC/2-jupyter-notebooks/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[2] Jupyter Notebooks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../content/00-intro-AI-HPC/3-homework/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[3] Homework</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../content/00-intro-AI-HPC/4-nersc/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[4] NERSC</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../content/00-intro-AI-HPC/5-mcmc-example/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[5] MCMC Example</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../content/00-intro-AI-HPC/6-linear-regression/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[6] Linear Regression</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../content/01-neural-networks/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[01] Neural Networks</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../content/01-neural-networks/0-intro/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[0] Intro to NNs</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../content/01-neural-networks/1-mnist/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[1] MNIST Example</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../content/01-neural-networks/2-advanced/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[2] Advanced</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../content/01-neural-networks/3-conv-nets/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[3] Conv. Nets</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../content/01-neural-networks/4-representation-learning/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[4] Representation Learning</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../content/02-llms/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[02] Large Language Models</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../content/02-llms/0-intro-to-llms/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[0] Intro to LLMs</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">[03] AI for Science</span></span>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#modeling-sequential-data" id="toc-modeling-sequential-data" class="nav-link active" data-scroll-target="#modeling-sequential-data">Modeling Sequential Data</a></li>
  <li><a href="#a-basic-llm-pipeline-text-prediction" id="toc-a-basic-llm-pipeline-text-prediction" class="nav-link" data-scroll-target="#a-basic-llm-pipeline-text-prediction">A Basic LLM Pipeline: Text Prediction</a>
  <ul class="collapse">
  <li><a href="#vector-data" id="toc-vector-data" class="nav-link" data-scroll-target="#vector-data"><strong>Vector Data:</strong></a></li>
  <li><a href="#example-image-data" id="toc-example-image-data" class="nav-link" data-scroll-target="#example-image-data">Example: <strong>Image Data</strong></a></li>
  <li><a href="#example-data-from-simulations" id="toc-example-data-from-simulations" class="nav-link" data-scroll-target="#example-data-from-simulations">Example: <strong>Data from simulations</strong></a></li>
  <li><a href="#sequential-data" id="toc-sequential-data" class="nav-link" data-scroll-target="#sequential-data"><strong>Sequential Data:</strong></a></li>
  <li><a href="#example-text-documents" id="toc-example-text-documents" class="nav-link" data-scroll-target="#example-text-documents">Example: <strong>Text Documents</strong></a></li>
  <li><a href="#example-genetic-sequences" id="toc-example-genetic-sequences" class="nav-link" data-scroll-target="#example-genetic-sequences">Example: <strong>Genetic Sequences</strong></a></li>
  <li><a href="#example-protein-chains" id="toc-example-protein-chains" class="nav-link" data-scroll-target="#example-protein-chains">Example: <strong>Protein Chains</strong></a></li>
  </ul></li>
  <li><a href="#elements-of-dl-sequence-modeling" id="toc-elements-of-dl-sequence-modeling" class="nav-link" data-scroll-target="#elements-of-dl-sequence-modeling">Elements of DL Sequence Modeling</a>
  <ul class="collapse">
  <li><a href="#tokenization" id="toc-tokenization" class="nav-link" data-scroll-target="#tokenization">Tokenization</a></li>
  <li><a href="#token-embedding" id="toc-token-embedding" class="nav-link" data-scroll-target="#token-embedding">Token Embedding</a></li>
  <li><a href="#homework" id="toc-homework" class="nav-link" data-scroll-target="#homework">Homework</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/saforem2/intro-hpc-bootcamp-2025/blob/main/content/02-llms/0-intro-to-llms/OLD/Sequential_Data_Models.ipynb" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.dev/saforem2/intro-hpc-bootcamp-2025/blob/main/content/02-llms/0-intro-to-llms/OLD/Sequential_Data_Models.ipynb" class="toc-action"><i class="bi empty"></i>Edit this page</a></li><li><a href="https://github.com/saforem2/intro-hpc-bootcamp-2025/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div><div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="Sequential_Data_Models.md"><i class="bi bi-file-code"></i>Github (GFM)</a></li><li><a href="Sequential_Data_Models.out.ipynb" download="Sequential_Data_Models.out.ipynb"><i class="bi bi-journal-code"></i>Jupyter</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TC329HJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Introduction To Sequential Data Modeling</h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author"><a href="https://samforeman.me">Sam Foreman</a> <a href="mailto:foremans@anl.gov" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            <a href="https://alcf.anl.gov/about/people/sam-foreman">
            </a><a href="https://alcf.anl.gov/about/people/sam-foreman">ALCF</a>
            
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">July 22, 2025</p>
    </div>
  </div>
  
    <div>
    <div class="quarto-title-meta-heading">Modified</div>
    <div class="quarto-title-meta-contents">
      <p class="date-modified">July 22, 2025</p>
    </div>
  </div>
    
  </div>
  


</header>


<p>Author/Perpetrator: Carlo Graziani, including materials on LLMs by Varuni Sastri, and discussion/editorial work by Taylor Childers, Archit Vasan, Bethany Lusch, and Venkat Vishwanath (Argonne)</p>
<p>Word embedding visualizations adapted from Kevin Gimpel (Toyota Technological Institute at Chicago) <a href="https://home.ttic.edu/~kgimpel/viz-bert/viz-bert.html">Visualizing BERT</a>.</p>
<p>Some inspiration from the blog post <a href="https://jalammar.github.io/illustrated-transformer/">“The Illustrated Transformer”</a> by Jay Alammar, highly recommended reading before next week’s deeper dive into Transformer tech by Archit Vasan. Another useful resource is <a href="https://github.com/argonne-lcf/llm-workshop/blob/main/tutorials/01-llm-101/LLMs101.ipynb">this ALCF tutorial</a>.</p>
<p>Before you begin, make sure that you have your environment set up and your repo refreshed, as described in previous lessons, and reviewed in the accompanying ‘Readme.md’ file. Make sure that you select the kernel ‘datascience/conda-2023-01-10’ at the top-left of the Jupyter notebook.</p>
<section id="modeling-sequential-data" class="level2">
<h2 class="anchored" data-anchor-id="modeling-sequential-data">Modeling Sequential Data</h2>
<p>The modern terminology for the analysis of sequential data is “large language modeling” (LLM). This usage comes from Natural Language Processing (NLP), and is perhaps unfortunate—especially from the perspective of “AI For Science,” because, as I hope to clarify shortly, this kind of modeling is more generally useful than just for NLP.</p>
<p>This session is dedicated to setting out the basics of sequential data modeling, and introducing (and, where possible motivating) a few key elements required for DL approaches to such modeling—principally transformers.</p>
</section>
<section id="a-basic-llm-pipeline-text-prediction" class="level2">
<h2 class="anchored" data-anchor-id="a-basic-llm-pipeline-text-prediction">A Basic LLM Pipeline: Text Prediction</h2>
<p>Let’s download and run a model from the HuggingFace model hub, to start getting a feeling for one very popular LLM activity: text prediction.</p>
<div id="cell-3" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="co"># Administrivia: modify this notebook so output text wraps.</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="im">from</span> IPython.display <span class="im">import</span> HTML, display</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="kw">def</span> set_css():</span>
<span id="cb1-4"><a href="#cb1-4"></a>  display(HTML(<span class="st">'''</span></span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="st">  &lt;style&gt;</span></span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="st">    pre {</span></span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="st">      white-space: pre-wrap;</span></span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="st">    }</span></span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="st">  &lt;/style&gt;</span></span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="st">  '''</span>))</span>
<span id="cb1-11"><a href="#cb1-11"></a>get_ipython().events.register(<span class="st">'pre_run_cell'</span>, set_css)</span>
<span id="cb1-12"><a href="#cb1-12"></a></span>
<span id="cb1-13"><a href="#cb1-13"></a><span class="co"># Set various proxies to download models and data</span></span>
<span id="cb1-14"><a href="#cb1-14"></a><span class="co"># !export HTTP_PROXY="http://proxy-01.pub.alcf.anl.gov:3128"</span></span>
<span id="cb1-15"><a href="#cb1-15"></a><span class="co"># !export HTTPS_PROXY="http://proxy-01.pub.alcf.anl.gov:3128"</span></span>
<span id="cb1-16"><a href="#cb1-16"></a><span class="co"># !export http_proxy="http://proxy-01.pub.alcf.anl.gov:3128"</span></span>
<span id="cb1-17"><a href="#cb1-17"></a><span class="co"># !export https_proxy="http://proxy-01.pub.alcf.anl.gov:3128"</span></span>
<span id="cb1-18"><a href="#cb1-18"></a><span class="co"># !export ftp_proxy="http://proxy-01.pub.alcf.anl.gov:3128" </span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cell-4" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a><span class="op">%</span>pip install transformers</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>In what follows, we will ask an LLM based on the gpt2 model to complete the phrase “I’m late because”</p>
<div id="cell-6" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb3-2"><a href="#cb3-2"></a></span>
<span id="cb3-3"><a href="#cb3-3"></a><span class="co"># In this framework, setting  up a "pipeline" involves selecting a (pre-trained) model,</span></span>
<span id="cb3-4"><a href="#cb3-4"></a><span class="co"># and a task---in this case, text generation </span></span>
<span id="cb3-5"><a href="#cb3-5"></a>generator <span class="op">=</span> pipeline(<span class="st">"text-generation"</span>, model<span class="op">=</span><span class="st">'gpt2'</span>)</span>
<span id="cb3-6"><a href="#cb3-6"></a></span>
<span id="cb3-7"><a href="#cb3-7"></a>prompt <span class="op">=</span> <span class="st">"I'm late because"</span></span>
<span id="cb3-8"><a href="#cb3-8"></a></span>
<span id="cb3-9"><a href="#cb3-9"></a><span class="co"># We request 5 completions of the prompt, of length 25 words</span></span>
<span id="cb3-10"><a href="#cb3-10"></a>res <span class="op">=</span> generator(prompt, max_length<span class="op">=</span><span class="dv">25</span>, num_return_sequences<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb3-11"><a href="#cb3-11"></a></span>
<span id="cb3-12"><a href="#cb3-12"></a><span class="co"># What did we get?</span></span>
<span id="cb3-13"><a href="#cb3-13"></a><span class="cf">for</span> each <span class="kw">in</span> res:</span>
<span id="cb3-14"><a href="#cb3-14"></a>    <span class="bu">print</span>(each[<span class="st">'generated_text'</span>])</span>
<span id="cb3-15"><a href="#cb3-15"></a>    <span class="bu">print</span>(<span class="st">'******************"'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Huh. These seem pretty random. What happens if we predict a single sentence, but extend its length?</p>
<div id="cell-8" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a>res <span class="op">=</span> generator(prompt, max_length<span class="op">=</span><span class="dv">100</span>, num_return_sequences<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-2"><a href="#cb4-2"></a><span class="bu">print</span>(res[<span class="dv">0</span>][<span class="st">'generated_text'</span>])</span>
<span id="cb4-3"><a href="#cb4-3"></a><span class="bu">print</span>(<span class="st">'******************"'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>There are some notable features here:</p>
<ol type="1">
<li>Each sentence is different from the previous one.</li>
<li>The sentences seem fairly disjointed, and go down weird rabbit holes after (or sometimes during) the first sentence.<br>
</li>
<li>The sentences always, or almost always, end in mid-sentence.</li>
</ol>
<p>What explains this behavior?</p>
<p>The answer to (1) is that this kind of text prediction (like ChatGPT’s) is <em>generative</em>. The text prompt is used to contruct a probability distribution over possible completions, and each generated sentence is a <em>sample</em> from that distribution.</p>
<p>The answer to (2) is: LLMs split up sentences into words or word fragments, called <em>tokens</em>. The way the samples are drawn is sequentially, one token at a time. Suppose the <span class="math inline">k</span>-th token is denoted by the symbol <span class="math inline">t_k</span> (<span class="math inline">t_k</span> could be a word, a punctuation mark, a space, etc.). At stage <span class="math inline">N</span>, the <span class="math inline">N</span>-th token is drawn randomly from the distribution <span class="math display">
\mathrm{Prob}(t_N | \mathrm{prompt}, t_1, t_2,\ldots,t_{N-1}),
</span> at stage <span class="math inline">N+1</span> the random draw is from <span class="math display">
\mathrm{Prob}(t_{N+1} | \mathrm{prompt}, t_1, t_2,\ldots,t_{N-1},t_N),
</span> and so on.</p>
<p>(If you are unfamiliar with this probability notation, know that an expression such as <span class="math inline">\mathrm{Prob}(X)</span> should be read as “the probability of occurrence of event <span class="math inline">X</span>”, while the expression <span class="math inline">\mathrm{Prob}(X|Y)</span> should be read as “the probability of occurrence of the event <span class="math inline">X</span> <em>given</em> that event <span class="math inline">Y</span> has been observed.” This is called a <em>conditional probability</em>, and we often say “Probability of <span class="math inline">X</span> conditioned on <span class="math inline">Y</span>” for <span class="math inline">\mathrm{Prob}(X|Y)</span>. The observation of <span class="math inline">Y</span> changes the probability distribution governing the occurrence of <span class="math inline">X</span>. Here, the occurrence of the prompt, and of the first <span class="math inline">N-1</span> tokens, affects the probability distribution governing the <span class="math inline">N</span>-th token <span class="math inline">t_N</span>.)</p>
<p>It follows from this fact that the sentences start growing apart at the first token <span class="math inline">t_1</span>, and, depending on the model (in this case, gpt-2), are usually more strongly influenced by recent tokens than by older ones, so that <span class="math inline">t_{90}</span> is more strongly conditioned by it’s immediate predecessors <span class="math inline">t_{89}</span>, <span class="math inline">t_{88}</span>, and <span class="math inline">t_{87}</span> than it is by the prompt, or by <span class="math inline">t_1</span>, <span class="math inline">t_2</span>, or <span class="math inline">t_3</span>. We would say that this model’s <em>attention</em>—it’s ability to maintain context over sentences and paragraphs—is quite limited.</p>
<p>The answer to (3) is also related to the generation mechanism. With this style of generation, it is not possible to require that the text create exactly 100-token complete sentences. The best that one could do is to run the code so as to stop after the first (or second, or third) “End of Sentence” (EOS) token.</p>
<p>## Where Do Deep Learning Model Architecture Choices Come From?</p>
<p>From the model development view, the elements of a DL architecture are usually the result of <em>a lot</em> of trial-and-error by researchers. However, at a deeper level, those choices are dictated by the nature of the data itself: some strategies that are successful for some types of data are nearly pointless for other types.</p>
<p>For example, last week Corey Adams lectured on the application of convolutional nets—network architectures based on local convolutional kernels—to image analysis. ConvNets were a remarkable discovery in the field, which arose through the desire to exploit <em>local 2-D spatial structure</em> in images—edges, gradients, contrasts, large coherent features, small-scale details, and so on. Convolutional kernels, together with pooling (and some other art) turn out to be exceptionally well-adapted to discovering such structure.</p>
<p>On the other hand, convolutions are not as useful if the data does not have that sort of spatial structure. It would be sort of senseless to reach for convnets to model, say, seasonal effects on product sales data across different manufacturing categories, or natural language sequences (although this has been tried).</p>
<p>So it makes sense to think about the nature of data when approaching this field. Generally speaking, there are two broad categories of data types that have dominated DL practice: vector data, and sequential data. This course so far has trafficked in vector data, but with LLMs, we move into the domain of sequential data.</p>
<p>What distinguishes these two data types?</p>
<section id="vector-data" class="level3">
<h3 class="anchored" data-anchor-id="vector-data"><strong>Vector Data:</strong></h3>
<p>Fixed-length lists of real numbers, that can be visualized as living in a high-dimensional space, one dimension per list element.</p>
</section>
<section id="example-image-data" class="level3">
<h3 class="anchored" data-anchor-id="example-image-data">Example: <strong>Image Data</strong></h3>
<p float="center">
</p><figure class="figure">
<p><img src="Figures/CIFAR-10.png" width="500" class="figure-img"></p>
</figure>
<p></p>
<p><strong>Typical queries and decisions:</strong></p>
<ul>
<li>Image classification</li>
<li>Inpainting—fill in blank regions</li>
<li>Segmentation—Identify elements in an image, e.g.&nbsp;cars, people, clouds…</li>
</ul>
</section>
<section id="example-data-from-simulations" class="level3">
<h3 class="anchored" data-anchor-id="example-data-from-simulations">Example: <strong>Data from simulations</strong></h3>
<p float="center">
</p><figure class="figure">
<p><img src="Figures/Simulations.png" width="800" class="figure-img"></p>
</figure>
<p></p>
<p><strong>Typical queries and decisions:</strong></p>
<ul>
<li>Manifold finding/data reduction, i.e.&nbsp;how many dimensions are <em>really</em> required to describe the data (this is basically what autoencoders do);</li>
<li>Emulation—train on simulation data, learn to produce similar output, or output at simulation settings not yet attempted, at much lower cost than the original simulators</li>
<li>Forecasting of weather, economics, pollution…</li>
</ul>
</section>
<section id="sequential-data" class="level3">
<h3 class="anchored" data-anchor-id="sequential-data"><strong>Sequential Data:</strong></h3>
<p><em>Sequences</em> are variable-length lists, not necessarily real-valued, possibly containing gaps or requiring completion</p>
</section>
<section id="example-text-documents" class="level3">
<h3 class="anchored" data-anchor-id="example-text-documents">Example: <strong>Text Documents</strong></h3>
<p float="center">
</p><figure class="figure">
<p><img src="Figures/Lorem.png" width="500" class="figure-img"></p>
</figure>
<p></p>
<p><strong>Typical queries and decisions:</strong></p>
<ul>
<li>Translation</li>
<li>Spell checking and correction</li>
<li>Text prediction and generation</li>
<li>Sentiment analysis</li>
</ul>
</section>
<section id="example-genetic-sequences" class="level3">
<h3 class="anchored" data-anchor-id="example-genetic-sequences">Example: <strong>Genetic Sequences</strong></h3>
<p float="center">
</p><figure class="figure">
<p><img src="Figures/RNA-codons.svg.png" width="500" class="figure-img"></p>
</figure>
<p></p>
<p><strong>Typical queries and decisions:</strong></p>
<ul>
<li>Prediction of likely variants/mutations from DNA variability</li>
<li>Realistic DNA sequence synthesis</li>
<li>Predicting gene expression</li>
</ul>
</section>
<section id="example-protein-chains" class="level3">
<h3 class="anchored" data-anchor-id="example-protein-chains">Example: <strong>Protein Chains</strong></h3>
<p float="center">
</p><figure class="figure">
<p><img src="Figures/Protein-Structure-06.png" width="500" class="figure-img"></p>
</figure>
<p></p>
<p><strong>Typical queries and decisions:</strong></p>
<ul>
<li>Predict folding structure</li>
<li>Predict chemical/binding properties</li>
</ul>
<p>Other examples of scientifically important types of sequential data include chemical compounds (sequences of atoms) and weather states (sequences of spatially-resolved temperatures, pressures, humidities, etc.).</p>
<p>It should be clear from the above that sequential data is much richer and more highly-structured, in general, than vector data.</p>
<p>Let’s take a break. In the meantime, go back to the LLM pipeline that we built at the beginning, and try seeing what kind of text prediction result you can obtain through “prompt engineering”: try making longer, or more constraining prompts, and see if you can get more sensible results from the model.</p>
</section>
</section>
<section id="elements-of-dl-sequence-modeling" class="level2">
<h2 class="anchored" data-anchor-id="elements-of-dl-sequence-modeling">Elements of DL Sequence Modeling</h2>
<p>In 2017, the paper <a href="https://arxiv.org/abs/1706.03762">Attention is All You Need</a> (Vaswani et al.) introduced the modern <em>transformer architecture</em>. Transformers were game-changers in the subject of sequential data modeling, but in important respects they built upon elements that were already in use in existing sequential data architectures, such as recurrent neural networks (RNNs), which they displaced.</p>
<p>Let’s look at two of those key elements that are needed by modern sequential models (AKA “LLMs”): tokenization, and word embedding. The third key element—attention—will be covered next week.</p>
<section id="tokenization" class="level3">
<h3 class="anchored" data-anchor-id="tokenization">Tokenization</h3>
<p>Recall that unlike vector data, sequential data can have values that are essentially arbitrary—integers, real numbers, natural language words, DNA codons, and so on. LLMs are trained and used in a manner that is largely agnostic of the data type. This is possible because in a step preliminary to training, LLMs convert the data to <em>tokens</em>. Tokens are elements of a finite, discrete set—a <em>vocabulary</em>, with a certain fixed <em>vocabulary size</em>. In the case of English natural language, the vocabulary may be made up of whole words, plus punctuation, spaces, etc. with a vocabulary size approaching 500,000; or it may be made up of sub-words, or word stems, or from other clever coding schemes, with reduced vocabulary size—as low as 30,000.</p>
<p>There is clearly a tension represented by tokenization choice: On the one hand, there are great benefits to reducing the vocabulary size, because this can lead to substantial reductions in the number of parameters required by an LLM. On the other hand, the actual distribution of sequence elements is more likely to be exposed to the model by more complex tokenizations, with larger vocabulary sizes.</p>
<p>For example, take a phrase such as “The chef added salt to the soup, because it required seasoning.” The LLM needs to be able to parse such a sentence and discern, for example, that the article “it” refers to “the soup”, and not to “the chef” or “salt” (how it does this is the subject of Attention, discussed next week). It should be clear that such relationship are easier to tease out from a word tokenization (“The”, “chef”, “added”…) than from, say, a character-by-character tokenization (“t”, “h”, “e”, “c”…). On the other hand, a character-by-character tokenization has a much smaller vocabulary size (<span class="math inline">\le 40</span> including punctuation, spaces, etc.), whereas an English word-based vocabulary would have a vocabulary of about 500,000 (although the majority of these would be rarely-used words).</p>
<p>Let’s look at some tokenization examples:</p>
<div id="cell-13" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer</span>
<span id="cb5-2"><a href="#cb5-2"></a></span>
<span id="cb5-3"><a href="#cb5-3"></a><span class="co"># A utility function to tokenize a sequence and print out some information about it.</span></span>
<span id="cb5-4"><a href="#cb5-4"></a></span>
<span id="cb5-5"><a href="#cb5-5"></a><span class="kw">def</span> tokenization_summary(tokenizer, sequence):</span>
<span id="cb5-6"><a href="#cb5-6"></a></span>
<span id="cb5-7"><a href="#cb5-7"></a>    <span class="co"># get the vocabulary</span></span>
<span id="cb5-8"><a href="#cb5-8"></a>    vocab <span class="op">=</span> tokenizer.vocab</span>
<span id="cb5-9"><a href="#cb5-9"></a>    <span class="co"># Number of entries to print</span></span>
<span id="cb5-10"><a href="#cb5-10"></a>    n <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb5-11"><a href="#cb5-11"></a></span>
<span id="cb5-12"><a href="#cb5-12"></a>    <span class="co"># Print subset of the vocabulary</span></span>
<span id="cb5-13"><a href="#cb5-13"></a>    <span class="bu">print</span>(<span class="st">"Subset of tokenizer.vocab:"</span>)</span>
<span id="cb5-14"><a href="#cb5-14"></a>    <span class="cf">for</span> i, (token, index) <span class="kw">in</span> <span class="bu">enumerate</span>(tokenizer.vocab.items()):</span>
<span id="cb5-15"><a href="#cb5-15"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>token<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>index<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-16"><a href="#cb5-16"></a>        <span class="cf">if</span> i <span class="op">&gt;=</span> n <span class="op">-</span> <span class="dv">1</span>:</span>
<span id="cb5-17"><a href="#cb5-17"></a>            <span class="cf">break</span></span>
<span id="cb5-18"><a href="#cb5-18"></a></span>
<span id="cb5-19"><a href="#cb5-19"></a>    <span class="bu">print</span>(<span class="st">"Vocab size of the tokenizer = "</span>, <span class="bu">len</span>(vocab))</span>
<span id="cb5-20"><a href="#cb5-20"></a>    <span class="bu">print</span>(<span class="st">"------------------------------------------"</span>)</span>
<span id="cb5-21"><a href="#cb5-21"></a></span>
<span id="cb5-22"><a href="#cb5-22"></a>    <span class="co"># .tokenize chunks the existing sequence into different tokens based on the rules and vocab of the tokenizer.</span></span>
<span id="cb5-23"><a href="#cb5-23"></a>    tokens <span class="op">=</span> tokenizer.tokenize(sequence)</span>
<span id="cb5-24"><a href="#cb5-24"></a>    <span class="bu">print</span>(<span class="st">"Tokens : "</span>, tokens)</span>
<span id="cb5-25"><a href="#cb5-25"></a>    <span class="bu">print</span>(<span class="st">"------------------------------------------"</span>)</span>
<span id="cb5-26"><a href="#cb5-26"></a></span>
<span id="cb5-27"><a href="#cb5-27"></a>    <span class="co"># .convert_tokens_to_ids or .encode or .tokenize converts the tokens to their corresponding numerical representation.</span></span>
<span id="cb5-28"><a href="#cb5-28"></a>    <span class="co">#  .convert_tokens_to_ids has a 1-1 mapping between tokens and numerical representation</span></span>
<span id="cb5-29"><a href="#cb5-29"></a>    <span class="co"># ids = tokenizer.convert_tokens_to_ids(tokens)</span></span>
<span id="cb5-30"><a href="#cb5-30"></a>    <span class="co"># print("encoded Ids: ", ids)</span></span>
<span id="cb5-31"><a href="#cb5-31"></a></span>
<span id="cb5-32"><a href="#cb5-32"></a>    <span class="co"># .encode also adds additional information like Start of sequence tokens and End of sequene</span></span>
<span id="cb5-33"><a href="#cb5-33"></a>    <span class="bu">print</span>(<span class="st">"tokenized sequence : "</span>, tokenizer.encode(sequence))</span>
<span id="cb5-34"><a href="#cb5-34"></a></span>
<span id="cb5-35"><a href="#cb5-35"></a>    <span class="co"># .tokenizer has additional information about attention_mask.</span></span>
<span id="cb5-36"><a href="#cb5-36"></a>    <span class="co"># encode = tokenizer(sequence)</span></span>
<span id="cb5-37"><a href="#cb5-37"></a>    <span class="co"># print("Encode sequence : ", encode)</span></span>
<span id="cb5-38"><a href="#cb5-38"></a>    <span class="co"># print("------------------------------------------")</span></span>
<span id="cb5-39"><a href="#cb5-39"></a></span>
<span id="cb5-40"><a href="#cb5-40"></a>    <span class="co"># .decode decodes the ids to raw text</span></span>
<span id="cb5-41"><a href="#cb5-41"></a>    ids <span class="op">=</span> tokenizer.convert_tokens_to_ids(tokens)</span>
<span id="cb5-42"><a href="#cb5-42"></a>    decode <span class="op">=</span> tokenizer.decode(ids)</span>
<span id="cb5-43"><a href="#cb5-43"></a>    <span class="bu">print</span>(<span class="st">"Decode sequence : "</span>, decode)</span>
<span id="cb5-44"><a href="#cb5-44"></a></span>
<span id="cb5-45"><a href="#cb5-45"></a></span>
<span id="cb5-46"><a href="#cb5-46"></a>tokenizer_1  <span class="op">=</span>  AutoTokenizer.from_pretrained(<span class="st">"gpt2"</span>) <span class="co"># GPT-2 uses "Byte-Pair Encoding (BPE)"</span></span>
<span id="cb5-47"><a href="#cb5-47"></a></span>
<span id="cb5-48"><a href="#cb5-48"></a>sequence <span class="op">=</span> <span class="st">"Counselor, please adjust your Zoom filter to appear as a human, rather than as a cat"</span></span>
<span id="cb5-49"><a href="#cb5-49"></a></span>
<span id="cb5-50"><a href="#cb5-50"></a>tokenization_summary(tokenizer_1, sequence)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>GPT-2 uses a so-called “Byte-pair encoding” (BPE), which can break up long words into subwords (e.g.&nbsp;“Coun” “sel”lor”). This allows for rare words (the majority of English vocabulary words) to be encoded in a smaller vocabulary (in this case, 50257 token IDs). This tokenization also incorporates initial whitespace before a word into the word for efficiency, so a word will be encoded differently whether it is at the beginning of the sentence (without space) or not. This is the reason for those odd-looking “Ġ” characters in the vocabulary.</p>
<p>For a description of how BPE works, see <a href="https://huggingface.co/learn/nlp-course/en/chapter6/5">this article</a>.</p>
<p>(Python tip: try typing “help(tokenizer_1)” for more information on what it’s doing and how to use it).</p>
<p>Let’s look at a different tokenizer now:</p>
<div id="cell-15" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a>tokenizer_2  <span class="op">=</span>  AutoTokenizer.from_pretrained(<span class="st">"bert-base-cased"</span>) <span class="co"># BERT uses WordPiece encoding</span></span>
<span id="cb6-2"><a href="#cb6-2"></a></span>
<span id="cb6-3"><a href="#cb6-3"></a>tokenization_summary(tokenizer_2, sequence)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>This model (part of the BERT family) uses WordPiece encoding. This is another clever strategy (described <a href="https://huggingface.co/learn/nlp-course/en/chapter6/6">here</a>) that reduces the vocabulary size to 28996, by starting with a character-level encoding, then training on a text corpus to find ways to efficiently merge some of these preliminary tokens into others representing longer strings of frequent occurrence. Note that “Counsel” occurs frequently enough to rate its own token, and the algorithm builds “counselor” out of “counsel”+“or” (actually, “##or”, where the “##” is a tag indicating that the token is a word piece). Similarly for “Zoom”=“Zoo” + “#m”.</p>
<p>Note that one could obtain a simpler tokenizer by using elementary Python ‘string’ operations to split sentences on words, punctuation, and the like, obtaining <em>very</em> large vocabulary sizes, but not requiring advance training on corpuses of text as WordPiece and BPE do. In NLP, however, such strategies are considered naive, because very large vocabulary sizes produce cripplingly large LLM parameter sizes. It is better to train a tokenizer on actual data.</p>
<p>Note also: there is, to this day, no approach to judging what is an <em>optimal</em> tokenization—one that best preserves distributional information contained in the sequence without an exploding vocabulary size.</p>
</section>
<section id="token-embedding" class="level3">
<h3 class="anchored" data-anchor-id="token-embedding">Token Embedding</h3>
<p>The strategy of choice for learning language structure from tokenized text is to find a clever way to map each token into a moderate-dimension vector space, adjusting the mapping so that</p>
<ol type="1">
<li>Similar, or associated tokens take up residence nearby each other, and</li>
<li>Different regions of the space correspond to different position in the sequence.</li>
</ol>
<p>Such a mapping from token ID to a point in a vector space is called a <em>token embedding</em>. The dimension of the vector space is often high (e.g.&nbsp;1024-dimensional), but much smaller than the vocabulary size (30,000–500,000). The choice of this dimension is made based on a compromise between expressiveness and computational cost. Various approaches have been attempted for generating such embeddings, including static algorithms that operate on a corpus of tokenized data as preprocessors for NLP tasks. Transformers, however, adjust their embeddings during training.</p>
<p>The point of an embedding is to allow computational NLP architectures to operate on familiar, and easily tensorizable data entities—vectors—which can easily be subjected to the usual sorts of DL operations.</p>
<p>Let’s take a look at a visualization of the token embedding associated with a pre-trained BERT transformer model. The following is adapted from <a href="https://home.ttic.edu/~kgimpel/viz-bert/viz-bert.html">Kevin Gimpel’s visualization</a>.</p>
<div id="cell-17" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb7-2"><a href="#cb7-2"></a><span class="im">import</span> torch</span>
<span id="cb7-3"><a href="#cb7-3"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-4"><a href="#cb7-4"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-5"><a href="#cb7-5"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> TSNE</span>
<span id="cb7-6"><a href="#cb7-6"></a><span class="im">from</span> transformers <span class="im">import</span> BertTokenizer, BertModel, BertForMaskedLM</span>
<span id="cb7-7"><a href="#cb7-7"></a><span class="im">import</span> sys</span>
<span id="cb7-8"><a href="#cb7-8"></a>np.set_printoptions(threshold<span class="op">=</span>sys.maxsize)</span>
<span id="cb7-9"><a href="#cb7-9"></a>plt.rcParams[<span class="st">'figure.figsize'</span>] <span class="op">=</span> [<span class="dv">100</span>, <span class="dv">60</span>]</span>
<span id="cb7-10"><a href="#cb7-10"></a></span>
<span id="cb7-11"><a href="#cb7-11"></a><span class="co"># Load BERT.</span></span>
<span id="cb7-12"><a href="#cb7-12"></a>model <span class="op">=</span> BertModel.from_pretrained(<span class="st">'bert-large-uncased-whole-word-masking'</span>)</span>
<span id="cb7-13"><a href="#cb7-13"></a><span class="co"># Set the model to eval mode.</span></span>
<span id="cb7-14"><a href="#cb7-14"></a>model.<span class="bu">eval</span>()</span>
<span id="cb7-15"><a href="#cb7-15"></a><span class="co"># This notebook assumes CPU execution. If you want to use GPUs, put the model on cuda and modify subsequent code blocks.</span></span>
<span id="cb7-16"><a href="#cb7-16"></a><span class="co">#model.to('cuda')</span></span>
<span id="cb7-17"><a href="#cb7-17"></a><span class="co"># Load tokenizer.</span></span>
<span id="cb7-18"><a href="#cb7-18"></a>tokenizer <span class="op">=</span> BertTokenizer.from_pretrained(<span class="st">'bert-large-uncased-whole-word-masking'</span>)</span>
<span id="cb7-19"><a href="#cb7-19"></a></span>
<span id="cb7-20"><a href="#cb7-20"></a><span class="co"># Save the BERT vocabulary to a file -- by default it will name this file "vocab.txt".</span></span>
<span id="cb7-21"><a href="#cb7-21"></a>tokenizer.save_vocabulary(save_directory<span class="op">=</span><span class="st">'.'</span>)</span>
<span id="cb7-22"><a href="#cb7-22"></a></span>
<span id="cb7-23"><a href="#cb7-23"></a><span class="bu">print</span>(<span class="st">"The vocabulary size is: "</span>, model.config.vocab_size) <span class="co"># Size of the vocabulary</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cell-18" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a><span class="co"># Get BERT's vocabulary embeddings.</span></span>
<span id="cb8-2"><a href="#cb8-2"></a>wordembs <span class="op">=</span> model.get_input_embeddings()</span>
<span id="cb8-3"><a href="#cb8-3"></a></span>
<span id="cb8-4"><a href="#cb8-4"></a><span class="co"># Convert the vocabulary embeddings to numpy.</span></span>
<span id="cb8-5"><a href="#cb8-5"></a>allinds <span class="op">=</span> np.arange(<span class="dv">0</span>,model.config.vocab_size,<span class="dv">1</span>)</span>
<span id="cb8-6"><a href="#cb8-6"></a>inputinds <span class="op">=</span> torch.LongTensor(allinds)</span>
<span id="cb8-7"><a href="#cb8-7"></a>bertwordembs <span class="op">=</span> wordembs(inputinds).detach().numpy()</span>
<span id="cb8-8"><a href="#cb8-8"></a><span class="bu">print</span>(bertwordembs.shape)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>So the array bertwordembs contains 30522 vectors of size 1024, the latter being the dimension of the embedding space.</p>
<p>The visualization of this data will be carried out by means of a projection to 2 dimensions by an algorithm called “t-SNE” (“t-distributed stochastic neighbor embedding”), which attempts to keep “similar” (in the high-dimensional space) points together, while spreading apart in the 2-dimensional projection points that are distant from each other in the high-dimensional space.</p>
<div id="cell-20" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a><span class="co"># Read in the vocabulary</span></span>
<span id="cb9-2"><a href="#cb9-2"></a>filename <span class="op">=</span> <span class="st">"vocab.txt"</span></span>
<span id="cb9-3"><a href="#cb9-3"></a><span class="cf">with</span> <span class="bu">open</span>(filename,<span class="st">'r'</span>) <span class="im">as</span> f:</span>
<span id="cb9-4"><a href="#cb9-4"></a>    bertwords <span class="op">=</span> np.array([])</span>
<span id="cb9-5"><a href="#cb9-5"></a>    <span class="cf">for</span> line <span class="kw">in</span> f:</span>
<span id="cb9-6"><a href="#cb9-6"></a>        bertwords <span class="op">=</span> np.append(bertwords, line.rstrip())</span>
<span id="cb9-7"><a href="#cb9-7"></a></span>
<span id="cb9-8"><a href="#cb9-8"></a><span class="co"># Determine vocabulary to use for t-SNE/visualization. The indices are hard-coded based partially on inspection:</span></span>
<span id="cb9-9"><a href="#cb9-9"></a>bert_char_indices_to_use <span class="op">=</span> np.arange(<span class="dv">999</span>, <span class="dv">1063</span>, <span class="dv">1</span>)</span>
<span id="cb9-10"><a href="#cb9-10"></a>bert_voc_indices_to_plot <span class="op">=</span> np.append(bert_char_indices_to_use, np.arange(<span class="dv">1996</span>, <span class="dv">5932</span>, <span class="dv">1</span>))</span>
<span id="cb9-11"><a href="#cb9-11"></a>bert_voc_indices_to_use <span class="op">=</span> np.append(bert_char_indices_to_use, np.arange(<span class="dv">1996</span>, <span class="dv">11932</span>, <span class="dv">1</span>))</span>
<span id="cb9-12"><a href="#cb9-12"></a></span>
<span id="cb9-13"><a href="#cb9-13"></a>bert_voc_indices_to_use_tensor <span class="op">=</span> torch.LongTensor(bert_voc_indices_to_use)</span>
<span id="cb9-14"><a href="#cb9-14"></a>bert_word_embs_to_use <span class="op">=</span> wordembs(bert_voc_indices_to_use_tensor).detach().numpy()</span>
<span id="cb9-15"><a href="#cb9-15"></a>bert_words_to_plot <span class="op">=</span> bertwords[bert_voc_indices_to_plot]</span>
<span id="cb9-16"><a href="#cb9-16"></a></span>
<span id="cb9-17"><a href="#cb9-17"></a></span>
<span id="cb9-18"><a href="#cb9-18"></a><span class="bu">print</span>(<span class="bu">len</span>(bert_voc_indices_to_plot))</span>
<span id="cb9-19"><a href="#cb9-19"></a><span class="bu">print</span>(<span class="bu">len</span>(bert_voc_indices_to_use))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>That is to say, 10000 words will be used to compute the t-SNE data, but only 4000 of them will be plotted. We’re ready to run the t-SNE projection.</p>
<div id="cell-22" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a><span class="co"># Run t-SNE on the BERT vocabulary embeddings we selected:</span></span>
<span id="cb10-2"><a href="#cb10-2"></a>mytsne_words <span class="op">=</span> TSNE(n_components<span class="op">=</span><span class="dv">2</span>,early_exaggeration<span class="op">=</span><span class="dv">12</span>,verbose<span class="op">=</span><span class="dv">2</span>,metric<span class="op">=</span><span class="st">'cosine'</span>,init<span class="op">=</span><span class="st">'pca'</span>,n_iter<span class="op">=</span><span class="dv">2500</span>)</span>
<span id="cb10-3"><a href="#cb10-3"></a>bert_word_embs_to_use_tsne <span class="op">=</span> mytsne_words.fit_transform(bert_word_embs_to_use)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cell-23" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1"></a><span class="co"># Plot the transformed BERT vocabulary embeddings:</span></span>
<span id="cb11-2"><a href="#cb11-2"></a>fig <span class="op">=</span> plt.figure()</span>
<span id="cb11-3"><a href="#cb11-3"></a>alltexts <span class="op">=</span> <span class="bu">list</span>()</span>
<span id="cb11-4"><a href="#cb11-4"></a><span class="cf">for</span> i, txt <span class="kw">in</span> <span class="bu">enumerate</span>(bert_words_to_plot):</span>
<span id="cb11-5"><a href="#cb11-5"></a>    plt.scatter(bert_word_embs_to_use_tsne[i,<span class="dv">0</span>], bert_word_embs_to_use_tsne[i,<span class="dv">1</span>], s<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb11-6"><a href="#cb11-6"></a>    currtext <span class="op">=</span> plt.text(bert_word_embs_to_use_tsne[i,<span class="dv">0</span>], bert_word_embs_to_use_tsne[i,<span class="dv">1</span>], txt, family<span class="op">=</span><span class="st">'sans-serif'</span>)</span>
<span id="cb11-7"><a href="#cb11-7"></a>    alltexts.append(currtext)</span>
<span id="cb11-8"><a href="#cb11-8"></a>    </span>
<span id="cb11-9"><a href="#cb11-9"></a></span>
<span id="cb11-10"><a href="#cb11-10"></a><span class="co"># Save the plot before adjusting.</span></span>
<span id="cb11-11"><a href="#cb11-11"></a>plt.savefig(<span class="st">'viz-bert-voc-tsne10k-viz4k-noadj.pdf'</span>, <span class="bu">format</span><span class="op">=</span><span class="st">'pdf'</span>)</span>
<span id="cb11-12"><a href="#cb11-12"></a></span>
<span id="cb11-13"><a href="#cb11-13"></a>plt.show</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Here’s are some close-ups of this projection. The first one has clusters of verbs with similar meanings.</p>
<p><img src="Figures/viz-bert-voc-verbs.png" align="center" width="800/"></p>
<p>Next, we see some sub-word clusters, containing the “##” tag used by BERT’s WordPiece tokenization scheme. This cluster consists of English suffixes.</p>
<p><img src="Figures/viz-bert-voc-suffixes.png" align="center" width="800/"></p>
<p>Here is what appears to be a cluster of suffixes of jurisdiction names:</p>
<p><img src="Figures/viz-bert-voc-entities.png" align="center" width="800/"></p>
</section>
<section id="homework" class="level3">
<h3 class="anchored" data-anchor-id="homework">Homework</h3>
<ol type="1">
<li><strong>Tokenization</strong></li>
</ol>
<p>Write a generic Python tokenizer, which takes a set of text lines and tabulates the different words (that is, the tokens will be simply English words), keeping track of the frequency of each word. Use the guidance in the accompanying notebook, ‘Homework_1.ipynb’.</p>
<ol start="2" type="1">
<li><strong>Embedding</strong></li>
</ol>
<p>Modify the embedding visualization code above to zoom in on various regions of the projections, and identify at least one interesting cluster of tokens.</p>


</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{foreman2025,
  author = {Foreman, Sam},
  title = {Introduction {To} {Sequential} {Data} {Modeling}},
  date = {2025-07-22},
  url = {https://saforem2.github.io/hpc-bootcamp-2025/content/02-llms/0-intro-to-llms/OLD/Sequential_Data_Models.html},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-foreman2025" class="csl-entry quarto-appendix-citeas" role="listitem">
Foreman, Sam. 2025. <span>“Introduction To Sequential Data
Modeling.”</span> July 22, 2025. <a href="https://saforem2.github.io/hpc-bootcamp-2025/content/02-llms/0-intro-to-llms/OLD/Sequential_Data_Models.html">https://saforem2.github.io/hpc-bootcamp-2025/content/02-llms/0-intro-to-llms/OLD/Sequential_Data_Models.html</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/saforem2\.github\.io\/hpc-bootcamp-2025\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<input type="hidden" id="giscus-base-theme" value="dark">
<input type="hidden" id="giscus-alt-theme" value="light">
<script>
  function loadGiscus() {
    // Function to get the theme based on body class
    const getTheme = () => {
      let baseTheme = document.getElementById('giscus-base-theme').value;
      let altTheme = document.getElementById('giscus-alt-theme').value;
      if (authorPrefersDark) {
          [baseTheme, altTheme] = [altTheme, baseTheme];
      }
      return document.body.classList.contains('quarto-dark') ? altTheme : baseTheme;
    };
    const script = document.createElement("script");
    script.src = "https://giscus.app/client.js";
    script.async = true;
    script.dataset.repo = "saforem2/intro-hpc-bootcamp-2025";
    script.dataset.repoId = "";
    script.dataset.category = "General";
    script.dataset.categoryId = "";
    script.dataset.mapping = "title";
    script.dataset.reactionsEnabled = "1";
    script.dataset.emitMetadata = "0";
    script.dataset.inputPosition = "top";
    script.dataset.theme = getTheme();
    script.dataset.lang = "en";
    script.crossOrigin = "anonymous";
    // Append the script to the desired div instead of at the end of the body
    document.getElementById("quarto-content").appendChild(script);
  }
  loadGiscus();
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://samforeman.me">
<p>samforeman.me</p>
</a>
  </li>  
</ul>
    </div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/saforem2/intro-hpc-bootcamp-2025/blob/main/content/02-llms/0-intro-to-llms/OLD/Sequential_Data_Models.ipynb" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.dev/saforem2/intro-hpc-bootcamp-2025/blob/main/content/02-llms/0-intro-to-llms/OLD/Sequential_Data_Models.ipynb" class="toc-action"><i class="bi empty"></i>Edit this page</a></li><li><a href="https://github.com/saforem2/intro-hpc-bootcamp-2025/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/saforem2">
      <i class="bi bi-twitter" role="img" aria-label="Sam Foreman Twitter">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/saforem2/intro-hpc-bootcamp-2025">
      <i class="bi bi-github" role="img" aria-label="Sam Foreman GitHub">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>