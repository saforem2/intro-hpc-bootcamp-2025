{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercise in Concurrency\n",
        "\n",
        "[Sam Foreman](https://samforeman.me)\n",
        "(\\[[ALCF](https://alcf.anl.gov/about/people/sam-foreman)\\](<https://alcf.anl.gov/about/people/sam-foreman>))  \n",
        "2025-07-22\n",
        "\n",
        "This is an exercise to help understand the usefulness of concurrency\n",
        "which is very important in supercomputering as we have very large\n",
        "numbers of computers working *concurrently* on the same problem.\n",
        "\n",
        "Here we’ll start with an example of concurrency on a single computer CPU\n",
        "that has many cores.\n",
        "\n",
        "## Loading the needed python modules"
      ],
      "id": "8627e59c-76b4-4ca8-ad2f-b9cd9c04d4a9"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import concurrent.futures\n",
        "import numpy as np\n",
        "import json\n",
        "from PIL import Image\n",
        "from itertools import repeat\n",
        "import multiprocessing\n",
        "import time"
      ],
      "id": "af72f2cb"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Retrieve ImageNet JPEG files\n",
        "\n",
        "This is a helper function that returns a python list of image filenames."
      ],
      "id": "f37b6a03-41d9-4afd-a71a-a1da00e7405d"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_image_files(config_file='ilsvrc.json', num_images = 100):\n",
        "   config = json.load(open(config_file))\n",
        "   filelist = config['data']['train_filelist']\n",
        "   \n",
        "   with open(filelist) as myfile:\n",
        "      image_filenames = [next(myfile).strip() for x in range(num_images)]\n",
        "   \n",
        "   return image_filenames"
      ],
      "id": "5fb765c5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Process Images\n",
        "\n",
        "We will imagine we are building a training batch for machine learning\n",
        "using these JPEGs. This would typically require you to 1. open the file,\n",
        "2. read the data, 3. resize the image to fit your neural network, and 4.\n",
        "add it to the list of inputs\n",
        "\n",
        "This function does this for us."
      ],
      "id": "87938c2b-3184-4d12-b7db-d5be377d8598"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_image(image_filename,resize_shape,batch_data,index):\n",
        "   # arguments:\n",
        "   #   image_filename = string giving the full path to the JPEG file to open\n",
        "   #   resize_shape   = a two dimensional tuple defining the image size in our batch, \n",
        "   #                      example: (200,100) corresponding to (width,height)\n",
        "   #   batch_data     = the numpy array that will hold our batch of images in a single  \n",
        "   #                      object with indices: (batch, width, height, channels)\n",
        "   #   index          = a unique batch ID number that corresponds to the first index of \n",
        "   #                      our batch array\n",
        "   \n",
        "   # use the PIL.Image object to open our JPEG\n",
        "   image = Image.open(image_filename)  # <- PIL.Image Object\n",
        "   \n",
        "   # use the Image.resize function to \n",
        "   image = image.resize(resize_shape)  # <- PIL.Image Object\n",
        "   # convert the image to a numpy array\n",
        "   data = np.asarray(image)            # <- numpy array of shape (width,height,3)\n",
        "   # this is a check:\n",
        "   # some of our JPEGs are black & white, so they have no channel index\n",
        "   # so this little snippet of code adds a channel index if needed\n",
        "   if len(data.shape) == 2:\n",
        "      tmp = np.zeros(data.shape + (3,))\n",
        "      tmp[...,0] = data\n",
        "      data = tmp\n",
        "   \n",
        "   # In order to copy our image, which currently has shape (width,height,3)\n",
        "   #    into the batch data array which has shape (batch_size,width,height,3),\n",
        "   #    we need to add an extra index to our data\n",
        "   data = data[np.newaxis,...]         # <- numpy array of shape (1,width,height,3)\n",
        "   # copy one JPEG image data into our batch of data, at the passed index\n",
        "   batch_data[index,...] = data"
      ],
      "id": "103c219b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can create a *serial*, AKA a single-core process, that builds a\n",
        "batch of images for our ML training."
      ],
      "id": "be24e7c7-dc5e-44b8-8331-472e00fe0b1d"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "duration:     5.32 seconds\n",
            "images per second:   188.00"
          ]
        }
      ],
      "source": [
        "# define how many images are in our batch\n",
        "batch_size = 1000\n",
        "# define our resize shape\n",
        "resize_width = 100\n",
        "resize_height = 100\n",
        "resize_shape = (resize_width,resize_height)\n",
        "# retrieve batch_size worth of JPEG filenames\n",
        "img_files = get_image_files(num_images=batch_size)\n",
        "# create a numpy array that will hold our batch data\n",
        "#     np.zero creates an array of the given shape\n",
        "#     where all entries are set to zero\n",
        "new_image = np.zeros((batch_size,resize_width,resize_height,3))\n",
        "start_time = time.time()\n",
        "# loop over the image filenames and process each one.\n",
        "for i,imagefile in enumerate(img_files):\n",
        "   process_image(imagefile,resize_shape,new_image,i)\n",
        "end_time = time.time()\n",
        "duration = end_time - start_time\n",
        "print(f'duration: {duration:8.2f} seconds')\n",
        "image_rate = batch_size / duration\n",
        "print(f'images per second: {image_rate:8.2f}')"
      ],
      "id": "55cdb231"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code above takes many seconds to execute and only uses 1 CPU-core to\n",
        "build our batch. We can speed this up using parallel threads, where each\n",
        "thread uses a different CPU core on our machine.\n",
        "\n",
        "We can use Python to tell us how many CPU cores we have:"
      ],
      "id": "66544972-22b7-405c-ad9c-5a087e36becc"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of CPU cores on my machine:  32"
          ]
        }
      ],
      "source": [
        "print('number of CPU cores on my machine: ',multiprocessing.cpu_count())"
      ],
      "id": "72212fa6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can rewrite the loop above using Python’s `ThreadPoolExecutor`\n",
        "module where we specify the number of parallel threads to use and what\n",
        "each thread will execute. The `executor.map()` function runs a function\n",
        "we specify once per thread. We also must provide a list of arguments for\n",
        "each function call. The thread pool ENDS when it runs out of arguments\n",
        "to pass to the function."
      ],
      "id": "ac69ec75-0546-4773-bd19-d556c813ad5d"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "duration:     2.80 seconds\n",
            "images per second:   357.47"
          ]
        }
      ],
      "source": [
        "# NEW: now we need to specify how many parallel threads to run:\n",
        "num_threads = 2\n",
        "\n",
        "# define how many images are in our batch\n",
        "batch_size = 1000\n",
        "# define our resize shape\n",
        "resize_width = 100\n",
        "resize_height = 100\n",
        "resize_shape = (resize_width,resize_height)\n",
        "# retrieve batch_size worth of JPEG filenames\n",
        "img_files = get_image_files(num_images=batch_size)\n",
        "# create a numpy array that will hold our batch data\n",
        "#     np.zero creates an array of the given shape\n",
        "#     where all entries are set to zero\n",
        "new_image = np.zeros((batch_size,resize_width,resize_height,3))\n",
        "\n",
        "start_time = time.time()\n",
        "# NEW: this is a fancy way to create this 'executor' object that will launch and manage our parallel threads\n",
        "with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "   # Here is where the actual threads are launched\n",
        "   #   we pass the function each thread should call 'process_image'\n",
        "   #   then we pass our input function arguments:\n",
        "   #        img_files  -> a list of filenames (batch_size long)\n",
        "   #        repeat(resize_shape) -> repeat will provide as many copies of the resize_shape as is needed\n",
        "   #        repeat(new_image) -> repeat will provide as many copies of the new_image as is needed\n",
        "   #        repeat(len(img_files)) -> repeat will provide as many copies of number of files as is needed\n",
        "   results = executor.map(process_image, img_files,repeat(resize_shape), repeat(new_image),range(len(img_files)))\n",
        "\n",
        "end_time = time.time()\n",
        "duration = end_time - start_time\n",
        "print(f'duration: {duration:8.2f} seconds')\n",
        "image_rate = batch_size / duration\n",
        "print(f'images per second: {image_rate:8.2f}')"
      ],
      "id": "6652df33"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# you can check the results of each thread using the list of \"results\" returned by the map\n",
        "# though in our case, they should simply be None since our function has no return value\n",
        "for result in results:\n",
        "   if result is not None: print(result)\n"
      ],
      "id": "e0f82800"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exersize Instructions\n",
        "\n",
        "Play with the value of `num_threads` and note how it affects run time\n",
        "and throughput. How does the return value of\n",
        "`multiprocessing.cpu_count()`, that is, how does the number of CPU cores\n",
        "on your machine impact the throughput you can achieve?"
      ],
      "id": "c30a217c-0f60-418b-b0da-d03ff17d6c57"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.6",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "2ffbed8d28ffdab8a81ac99dda4a6eabc52051a653fdcb4a791fdb3c04bf06bf"
      }
    }
  }
}