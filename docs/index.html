<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.18">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Sam Foreman">
<meta name="dcterms.date" content="2025-07-15">
<meta name="description" content="Homepage for Sam Foreman’s Intro to HPC Bootcamp 2025 Project">

<title>Intro to HPC Bootcamp 2025</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" integrity="sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./assets/favicon-sf.svg" rel="icon" type="image/svg+xml">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-9bf6f933b760cbb4c99ada293d62cb55.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-22c6c940514060718923bc7c0517e30f.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-1a95a006fa96163f90bf11620203e68d.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-174353d2fa111ba48747fab321614398.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=GTM-MRCG68M5"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'GTM-MRCG68M5', { 'anonymize_ip': true});
</script>
<script src="https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js" integrity="sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css" integrity="sha384-5TcZemv2l/9On385z///+d7MSYlvIEw9FuZTIdZ14vJLqWphw7e7ZPuOiCHJcFCP" crossorigin="anonymous">
<script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.js" integrity="sha384-cMkvdD8LoxVzGF/RPUKAcvmm49FQ0oxwDF3BGKtDXcEc+T1b2N+teh/OJfpU0jr6" crossorigin="anonymous"></script>
<script defer="" src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/auto-render.min.js" integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&amp;family=IBM+Plex+Sans+Condensed:ital,wght@0,400;0,500;0,600;0,700&amp;family=IBM+Plex+Mono:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700&amp;display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=IBM+Plex+Sans&amp;family=IBM+Plex+Sans+Condensed&amp;family=IBM+Plex+Mono&amp;display=swap" rel="stylesheet">
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-TC329HJ');</script>
<!-- End Google Tag Manager -->
<link rel="preconnect" href="https://fonts.googleapis.com">
<link href="https://iosevka-webfonts.github.io/iosevka/iosevka.css" rel="stylesheet">


<meta property="og:title" content="Intro to HPC Bootcamp 2025">
<meta property="og:description" content="Homepage for Sam Foreman’s Intro to HPC Bootcamp 2025 Project">
<meta property="og:image" content="https://saforem2.github.io/hpc-bootcamp-2025/assets/thumbnail.png">
<meta property="og:site_name" content="Intro to HPC Bootcamp 2025">
<meta name="twitter:title" content="Intro to HPC Bootcamp 2025">
<meta name="twitter:description" content="Homepage for Sam Foreman’s Intro to HPC Bootcamp 2025 Project">
<meta name="twitter:image" content="https://saforem2.github.io/hpc-bootcamp-2025/assets/thumbnail.png">
<meta name="twitter:creator" content="saforem2">
<meta name="twitter:site" content="saforem2">
<meta name="twitter:card" content="summary_large_image">
<meta name="citation_title" content="Intro to HPC Bootcamp 2025">
<meta name="citation_author" content="Sam Foreman">
<meta name="citation_publication_date" content="2025-07-15">
<meta name="citation_cover_date" content="2025-07-15">
<meta name="citation_year" content="2025">
<meta name="citation_online_date" content="2025-07-15">
<meta name="citation_fulltext_html_url" content="https://saforem2.github.io/intro-hpc-bootcamp-2025">
<meta name="citation_language" content="en">
<meta name="citation_reference" content="citation_title=The hugging face course, 2022;,citation_author=Hugging Face;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_publisher=https://huggingface.co/course;">
<meta name="citation_reference" content="citation_title=HiPerRAG: High-performance retrieval augmented generation for scientific insights;,citation_author=Ozan Gokdemir;,citation_author=Carlo Siebenschuh;,citation_author=Alexander Brace;,citation_author=Azton Wells;,citation_author=Brian Hsu;,citation_author=Kyle Hippe;,citation_author=Priyanka V. Setty;,citation_author=Aswathy Ajith;,citation_author=J. Gregory Pauloski;,citation_author=Varuni Sastry;,citation_author=Sam Foreman;,citation_author=Huihuo Zheng;,citation_author=Heng Ma;,citation_author=Bharat Kale;,citation_author=Nicholas Chia;,citation_author=Thomas Gibbs;,citation_author=Michael E. Papka;,citation_author=Thomas Brettin;,citation_author=Francis J. Alexander;,citation_author=Anima Anandkumar;,citation_author=Ian Foster;,citation_author=Rick Stevens;,citation_author=Venkatram Vishwanath;,citation_author=Arvind Ramanathan;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_fulltext_html_url=https://arxiv.org/abs/2505.04846;">
<meta name="citation_reference" content="citation_title=MOFA: Discovering materials for carbon capture with a GenAI- and simulation-based workflow;,citation_author=Xiaoli Yan;,citation_author=Nathaniel Hudson;,citation_author=Hyun Park;,citation_author=Daniel Grzenda;,citation_author=J. Gregory Pauloski;,citation_author=Marcus Schwarting;,citation_author=Haochen Pan;,citation_author=Hassan Harb;,citation_author=Samuel Foreman;,citation_author=Chris Knight;,citation_author=Tom Gibbs;,citation_author=Kyle Chard;,citation_author=Santanu Chaudhuri;,citation_author=Emad Tajkhorshid;,citation_author=Ian Foster;,citation_author=Mohamad Moosavi;,citation_author=Logan Ward;,citation_author=E. A. Huerta;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_fulltext_html_url=https://arxiv.org/abs/2501.10651;">
<meta name="citation_reference" content="citation_title=MProt-DPO: Breaking the ExaFLOPS barrier for multimodal protein design workflows with direct preference optimization;,citation_abstract=We present a scalable, end-to-end workflow for protein design. By augmenting protein sequences with natural language descriptions of their biochemical properties, we train generative models that can be preferentially aligned with protein fitness landscapes. Through complex experimental- and simulation-based observations, we integrate these measures as preferred parameters for generating new protein variants and demonstrate our workflow on five diverse supercomputers. We achieve &amp;amp;amp;gt;1 ExaFLOPS sustained performance in mixed precision on each supercomputer and a maximum sustained performance of 4.11 ExaFLOPS and peak performance of 5.57 ExaFLOPS. We establish the scientific performance of our model on two tasks: (1) across a predetermined benchmark dataset of deep mutational scanning experiments to optimize the fitness-determining mutations in the yeast protein HIS7, and (2) in optimizing the design of the enzyme malate dehydrogenase to achieve lower activation barriers (and therefore increased catalytic rates) using simulation data. Our implementation thus sets high watermarks for multimodal protein design workflows.;,citation_author=Gautham Dharuman;,citation_author=Kyle Hippe;,citation_author=Alexander Brace;,citation_author=Sam Foreman;,citation_author=Väinö Hatanpää;,citation_author=Varuni K. Sastry;,citation_author=Huihuo Zheng;,citation_author=Logan Ward;,citation_author=Servesh Muralidharan;,citation_author=Archit Vasan;,citation_author=Bharat Kale;,citation_author=Carla M. Mann;,citation_author=Heng Ma;,citation_author=Yun-Hsuan Cheng;,citation_author=Yuliana Zamora;,citation_author=Shengchao Liu;,citation_author=Chaowei Xiao;,citation_author=Murali Emani;,citation_author=Tom Gibbs;,citation_author=Mahidhar Tatineni;,citation_author=Deepak Canchi;,citation_author=Jerome Mitchell;,citation_author=Koichi Yamada;,citation_author=Maria Garzaran;,citation_author=Michael E. Papka;,citation_author=Ian Foster;,citation_author=Rick Stevens;,citation_author=Anima Anandkumar;,citation_author=Venkatram Vishwanath;,citation_author=Arvind Ramanathan;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://doi.org/10.1109/SC41406.2024.00013;,citation_doi=10.1109/SC41406.2024.00013;,citation_isbn=9798350352917;,citation_conference_title=Proceedings of the international conference for high performance computing, networking, storage, and analysis;,citation_conference=IEEE Press;,citation_series_title=SC ’24;">
<meta name="citation_reference" content="citation_title=Quality measures for dynamic graph generative models;,citation_author=Ryien Hosseini;,citation_author=Filippo Simini;,citation_author=Venkatram Vishwanath;,citation_author=Rebecca Willett;,citation_author=Henry Hoffmann;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_fulltext_html_url=https://openreview.net/forum?id=8bjspmAMBk;,citation_conference_title=The thirteenth international conference on learning representations;">
<meta name="citation_reference" content="citation_title=Superconductivity of in and sn samples;,citation_author=George Deamont;,citation_author=Sam Foreman;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=RG-inspired machine learning for lattice field theory;,citation_author=Sam Foreman;,citation_author=Joel Giedt;,citation_author=Yannick Meurice;,citation_author=Judah Unmuth-Yockey;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_volume=175;,citation_conference_title=EPJ web of conferences;,citation_conference=EDP Sciences;">
<meta name="citation_reference" content="citation_title=Large energy density in three-plate nanocapacitors due to coulomb blockade;,citation_author=A Hubler;,citation_author=S Foreman;,citation_author=J Liu;,citation_author=L Wortsmann;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=10;,citation_volume=123;,citation_journal_title=Journal of Applied Physics;,citation_publisher=AIP Publishing;">
<meta name="citation_reference" content="citation_title=Examples of renormalization group transformations for image sets;,citation_author=Samuel Foreman;,citation_author=Joel Giedt;,citation_author=Yannick Meurice;,citation_author=Judah Unmuth-Yockey;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=5;,citation_volume=98;,citation_journal_title=Physical Review E;,citation_publisher=American Physical Society;">
<meta name="citation_reference" content="citation_title=Machine learning inspired analysis of the Ising model transition;,citation_author=Samuel Foreman;,citation_author=Joel Giedt;,citation_author=Yannick Meurice;,citation_author=Judah Unmuth-Yockey;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_doi=10.22323/1.334.0245;,citation_volume=LATTICE2018;,citation_journal_title=PoS;">
<meta name="citation_reference" content="citation_title=Machine learning inspired analysis of the ising model transition;,citation_author=Samuel Foreman;,citation_author=Joel Giedt;,citation_author=Yannick Meurice;,citation_author=Judah Unmuth-Yockey;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_conference_title=Lattice 2018;">
<meta name="citation_reference" content="citation_title=Learning better physics: A machine learning approach to lattice gauge theory;,citation_author=Samuel Alfred Foreman;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_dissertation_institution=University of Iowa;">
<meta name="citation_reference" content="citation_title=Machine learning and neural networks for field theory;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;">
<meta name="citation_reference" content="citation_title=HMC with normalizing flows;,citation_author=Sam Foreman;,citation_author=Taku Izubuchi;,citation_author=Luchang Jin;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_author=Akio Tomiya;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01586;,citation_journal_title=arXiv preprint arXiv:2112.01586;">
<meta name="citation_reference" content="citation_title=LeapfrogLayers: A trainable framework for effective topological sampling;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01582;,citation_journal_title=arXiv preprint arXiv:2112.01582;">
<meta name="citation_reference" content="citation_title=Energy storage in quantum resonators;,citation_author=Jiaqi Liu;,citation_author=Alfred W Hubler;,citation_author=Samuel Alfred Foreman;,citation_author=Katharina Ott;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=Applications of machine learning to lattice quantum field theory;,citation_author=Denis Boyda;,citation_author=Salvatore Calı̀;,citation_author=Sam Foreman;,citation_author=Lena Funcke;,citation_author=Daniel C Hackett;,citation_author=Yin Lin;,citation_author=Gert Aarts;,citation_author=Andrei Alexandru;,citation_author=Xiao-Yong Jin;,citation_author=Biagio Lucini;,citation_author=others;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2202.05838;,citation_journal_title=arXiv preprint arXiv:2202.05838;">
<meta name="citation_reference" content="citation_title=Lattice QCD and particle physics;,citation_author=Andreas S Kronfeld;,citation_author=Tanmoy Bhattacharya;,citation_author=Thomas Blum;,citation_author=Norman H Christ;,citation_author=Carleton DeTar;,citation_author=William Detmold;,citation_author=Robert Edwards;,citation_author=Anna Hasenfratz;,citation_author=Huey-Wen Lin;,citation_author=Swagato Mukherjee;,citation_author=others;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2207.07641;,citation_journal_title=arXiv preprint arXiv:2207.07641;">
<meta name="citation_reference" content="citation_title=GenSLMs: Genome-scale language models reveal SARS-CoV-2 evolutionary dynamics;,citation_author=Maxim Zvyagin;,citation_author=Alexander Brace;,citation_author=Kyle Hippe;,citation_author=Yuntian Deng;,citation_author=Bin Zhang;,citation_author=Cindy Orozco Bohorquez;,citation_author=Austin Clyde;,citation_author=Bharat Kale;,citation_author=Danilo Perez-Rivera;,citation_author=Heng Ma;,citation_author=others;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_issue=6;,citation_volume=37;,citation_journal_title=The International Journal of High Performance Computing Applications;,citation_publisher=SAGE Publications Sage UK: London, England;">
<meta name="citation_reference" content="citation_title=MLMC: Machine learning monte carlo;,citation_author=Sam Foreman;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_conference_title=The international symposium on lattice field theory;">
<meta name="citation_reference" content="citation_title=Superconductivity of in and sn samples;,citation_author=George Deamont;,citation_author=Sam Foreman;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=A comprehensive performance study of large language models on novel AI accelerators;,citation_author=Murali Emani;,citation_author=Sam Foreman;,citation_author=Varuni Sastry;,citation_author=Zhen Xie;,citation_author=Siddhisanket Raskar;,citation_author=William Arnold;,citation_author=Rajeev Thakur;,citation_author=Venkatram Vishwanath;,citation_author=Michael E Papka;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2310.04607;,citation_journal_title=arXiv preprint arXiv:2310.04607;">
<meta name="citation_reference" content="citation_title=DeepSpeed4Science initiative: Enabling large-scale scientific discovery through sophisticated AI system technologies;,citation_author=Shuaiwen Leon Song;,citation_author=Bonnie Kruft;,citation_author=Minjia Zhang;,citation_author=Conglong Li;,citation_author=Shiyang Chen;,citation_author=Chengming Zhang;,citation_author=Masahiro Tanaka;,citation_author=Xiaoxia Wu;,citation_author=Jeff Rasley;,citation_author=Ammar Ahmad Awan;,citation_author=others;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2310.04610;,citation_journal_title=arXiv preprint arXiv:2310.04610;">
<meta name="citation_reference" content="citation_title=Protein generation via genome-scale language models with bio-physical scoring;,citation_author=Gautham Dharuman;,citation_author=Logan Ward;,citation_author=Heng Ma;,citation_author=Priyanka V Setty;,citation_author=Ozan Gokdemir;,citation_author=Sam Foreman;,citation_author=Murali Emani;,citation_author=Kyle Hippe;,citation_author=Alexander Brace;,citation_author=Kristopher Keipert;,citation_author=others;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_conference_title=Proceedings of the SC’23 workshops of the international conference on high performance computing, network, storage, and analysis;">
<meta name="citation_reference" content="citation_title=MLMC: Machine learning monte carlo for lattice gauge theory;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2312.08936;,citation_journal_title=arXiv preprint arXiv:2312.08936;">
<meta name="citation_reference" content="citation_title=Snowmass 2021 computational frontier CompF03 topical group report: Machine learning;,citation_author=Phiala Shanahan;,citation_author=Kazuhiro Terao;,citation_author=Daniel Whiteson;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2209.07559;,citation_journal_title=arXiv preprint arXiv:2209.07559;">
<meta name="citation_reference" content="citation_title=Thorough characterization and analysis of large transformer model training at-scale;,citation_author=Scott Cheng;,citation_author=Jun-Liang Lin;,citation_author=Murali Emani;,citation_author=Siddhisanket Raskar;,citation_author=Sam Foreman;,citation_author=Zhen Xie;,citation_author=Venkatram Vishwanath;,citation_author=Mahmut Taylan Kandemir;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_issue=1;,citation_volume=8;,citation_journal_title=Proceedings of the ACM on Measurement and Analysis of Computing Systems;,citation_publisher=ACM New York, NY, USA;">
<meta name="citation_reference" content="citation_title=Communities through energy justice projects;,citation_author=Mary Ann Leung;,citation_author=Katharine Cahill;,citation_author=Rebecca Hartman-Baker;,citation_author=Paige Kinsley;,citation_author=Lois Curfman McInnes;,citation_author=Suzanne Parete-Koon;,citation_author=Subil Abraham;,citation_author=Lacy Beach Barrier;,citation_author=Gladys Chen;,citation_author=Lizanne DeStefano;,citation_author=others;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_issue=1;,citation_volume=15;,citation_journal_title=Journal of Computational Science;">
<meta name="citation_reference" content="citation_title=Applications of a foundation model approach for weather and climate;,citation_author=Troy Arcomano;,citation_author=Alexander Wikner;,citation_author=Romit Maulik;,citation_author=Veerabhadra Rao Kotamarthi;,citation_author=Sam Foreman;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_volume=2023;,citation_conference_title=AGU fall meeting abstracts;">
<meta name="citation_reference" content="citation_title=Toward a holistic performance evaluation of large language models across diverse ai accelerators;,citation_author=Murali Emani;,citation_author=Sam Foreman;,citation_author=Varuni Sastry;,citation_author=Zhen Xie;,citation_author=Siddhisanket Raskar;,citation_author=William Arnold;,citation_author=Rajeev Thakur;,citation_author=Venkatram Vishwanath;,citation_author=Michael E Papka;,citation_author=Sanjif Shanmugavelu;,citation_author=others;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_conference_title=2024 IEEE international parallel and distributed processing symposium workshops (IPDPSW);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Intro to HPC bootcamp: Engaging new communities through energy justice projects;,citation_author=Suzanne Parete-Koon;,citation_author=Michael Sandoval;,citation_author=Kellen Leland;,citation_author=Subil Abraham;,citation_author=Mary Ann Leung;,citation_author=Rebecca Hartman-Baker;,citation_author=Paige Kinsley;,citation_author=Lois McInnes;,citation_author=Sreeranjani Ramprakash;,citation_author=Lacy Beach Barrier;,citation_author=others;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_issue=1;,citation_volume=15;,citation_journal_title=Journal of Computational Science Education;,citation_publisher=Oak Ridge National Laboratory (ORNL), Oak Ridge, TN (United States);">
<meta name="citation_reference" content="citation_title=MProt-DPO: Breaking the ExaFLOPS barrier for multimodal protein design workflows with direct preference optimization;,citation_author=Gautham Dharuman;,citation_author=Kyle Hippe;,citation_author=Alexander Brace;,citation_author=Sam Foreman;,citation_author=Väinä Hatanpää;,citation_author=Varuni K Sastry;,citation_author=Huihuo Zheng;,citation_author=Logan Ward;,citation_author=Servesh Muralidharan;,citation_author=Archit Vasan;,citation_author=others;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_conference_title=2024 SC24: International conference for high performance computing, networking, storage and analysis SC;,citation_conference=IEEE Computer Society;">
<meta name="citation_reference" content="citation_title=Emergent abilities of large language models;,citation_author=Jason Wei;,citation_author=Yi Tay;,citation_author=Rishi Bommasani;,citation_author=Colin Raffel;,citation_author=Barret Zoph;,citation_author=Sebastian Borgeaud;,citation_author=Dani Yogatama;,citation_author=Maarten Bosma;,citation_author=Denny Zhou;,citation_author=Donald Metzler;,citation_author=Ed H. Chi;,citation_author=Tatsunori Hashimoto;,citation_author=Oriol Vinyals;,citation_author=Percy Liang;,citation_author=Jeff Dean;,citation_author=William Fedus;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2206.07682;">
<meta name="citation_reference" content="citation_title=DeepSpeed4Science initiative: Enabling large-scale scientific discovery through sophisticated AI system technologies;,citation_author=Shuaiwen Leon Song;,citation_author=Bonnie Kruft;,citation_author=Minjia Zhang;,citation_author=Conglong Li;,citation_author=Shiyang Chen;,citation_author=Chengming Zhang;,citation_author=Masahiro Tanaka;,citation_author=Xiaoxia Wu;,citation_author=Jeff Rasley;,citation_author=Ammar Ahmad Awan;,citation_author=Connor Holmes;,citation_author=Martin Cai;,citation_author=Adam Ghanem;,citation_author=Zhongzhu Zhou;,citation_author=Yuxiong He;,citation_author=Pete Luferenko;,citation_author=Divya Kumar;,citation_author=Jonathan Weyn;,citation_author=Ruixiong Zhang;,citation_author=Sylwester Klocek;,citation_author=Volodymyr Vragov;,citation_author=Mohammed AlQuraishi;,citation_author=Gustaf Ahdritz;,citation_author=Christina Floristean;,citation_author=Cristina Negri;,citation_author=Rao Kotamarthi;,citation_author=Venkatram Vishwanath;,citation_author=Arvind Ramanathan;,citation_author=Sam Foreman;,citation_author=Kyle Hippe;,citation_author=Troy Arcomano;,citation_author=Romit Maulik;,citation_author=Maxim Zvyagin;,citation_author=Alexander Brace;,citation_author=Bin Zhang;,citation_author=Cindy Orozco Bohorquez;,citation_author=Austin Clyde;,citation_author=Bharat Kale;,citation_author=Danilo Perez-Rivera;,citation_author=Heng Ma;,citation_author=Carla M. Mann;,citation_author=Michael Irvin;,citation_author=J. Gregory Pauloski;,citation_author=Logan Ward;,citation_author=Valerie Hayot;,citation_author=Murali Emani;,citation_author=Zhen Xie;,citation_author=Diangen Lin;,citation_author=Maulik Shukla;,citation_author=Ian Foster;,citation_author=James J. Davis;,citation_author=Michael E. Papka;,citation_author=Thomas Brettin;,citation_author=Prasanna Balaprakash;,citation_author=Gina Tourassi;,citation_author=John Gounley;,citation_author=Heidi Hanson;,citation_author=Thomas E Potok;,citation_author=Massimiliano Lupo Pasini;,citation_author=Kate Evans;,citation_author=Dan Lu;,citation_author=Dalton Lunga;,citation_author=Junqi Yin;,citation_author=Sajal Dash;,citation_author=Feiyi Wang;,citation_author=Mallikarjun Shankar;,citation_author=Isaac Lyngaas;,citation_author=Xiao Wang;,citation_author=Guojing Cong;,citation_author=Pei Zhang;,citation_author=Ming Fan;,citation_author=Siyan Liu;,citation_author=Adolfy Hoisie;,citation_author=Shinjae Yoo;,citation_author=Yihui Ren;,citation_author=William Tang;,citation_author=Kyle Felker;,citation_author=Alexey Svyatkovskiy;,citation_author=Hang Liu;,citation_author=Ashwin Aji;,citation_author=Angela Dalton;,citation_author=Michael Schulte;,citation_author=Karl Schulz;,citation_author=Yuntian Deng;,citation_author=Weili Nie;,citation_author=Josh Romero;,citation_author=Christian Dallago;,citation_author=Arash Vahdat;,citation_author=Chaowei Xiao;,citation_author=Thomas Gibbs;,citation_author=Anima Anandkumar;,citation_author=Rick Stevens;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2310.04610;">
<meta name="citation_reference" content="citation_title=Emergent abilities of large language models;,citation_author=Jason Wei;,citation_author=Yi Tay;,citation_author=Rishi Bommasani;,citation_author=Colin Raffel;,citation_author=Barret Zoph;,citation_author=Sebastian Borgeaud;,citation_author=Dani Yogatama;,citation_author=Maarten Bosma;,citation_author=Denny Zhou;,citation_author=Donald Metzler;,citation_author=Ed H. Chi;,citation_author=Tatsunori Hashimoto;,citation_author=Oriol Vinyals;,citation_author=Percy Liang;,citation_author=Jeff Dean;,citation_author=William Fedus;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2206.07682;">
<meta name="citation_reference" content="citation_title=The climate risk &amp;amp;amp; resilience portal (ClimRR) metadata and data dictionary;,citation_author=C. Burdi;,citation_author=Wall. T Branham;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://dub.sh/ClimRR-Metadata;">
<meta name="citation_reference" content="citation_title=Progress on $(g-2)_\mu$ from lattice QCD;,citation_author=Hartmut Wittig;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2306.04165;">
<meta name="citation_reference" content="citation_title=Hybrid Monte Carlo;,citation_author=S. Duane;,citation_author=A. D. Kennedy;,citation_author=B. J. Pendleton;,citation_author=D. Roweth;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;,citation_doi=10.1016/0370-2693(87)91197-X;,citation_volume=195;,citation_journal_title=Phys. Lett. B;">
<meta name="citation_reference" content="citation_title=Snowmass 2021 Computational Frontier CompF03 Topical Group Report: Machine Learning;,citation_author=Phiala Shanahan;,citation_author=others;,citation_publication_date=2022-09;,citation_cover_date=2022-09;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2209.07559;">
<meta name="citation_reference" content="citation_title=Applications of Machine Learning to Lattice Quantum Field Theory;,citation_author=Denis Boyda;,citation_author=others;,citation_publication_date=2022-02;,citation_cover_date=2022-02;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2202.05838;,citation_conference_title=Snowmass 2021;">
<meta name="citation_reference" content="citation_title=HMC with Normalizing Flows;,citation_author=Sam Foreman;,citation_author=Taku Izubuchi;,citation_author=Luchang Jin;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_author=Akio Tomiya;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01586;,citation_doi=10.22323/1.396.0073;,citation_volume=LATTICE2021;,citation_journal_title=PoS;">
<meta name="citation_reference" content="citation_title=LeapfrogLayers: A Trainable Framework for Effective Topological Sampling;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01582;,citation_doi=10.22323/1.396.0508;,citation_volume=LATTICE2021;,citation_journal_title=PoS;">
<meta name="citation_reference" content="citation_title=Deep Learning Hamiltonian Monte Carlo;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2021-05;,citation_cover_date=2021-05;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2105.03418;,citation_conference_title=9th International Conference on Learning Representations;">
<meta name="citation_reference" content="citation_title=Deep learning hamiltonian monte carlo;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2105.03418;">
<meta name="citation_reference" content="citation_title=Deep Learning Hamiltonian Monte Carlo;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2021-05;,citation_cover_date=2021-05;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2105.03418;,citation_conference_title=9th International Conference on Learning Representations;">
<meta name="citation_reference" content="citation_title=Deep learning hamiltonian monte carlo;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=arXiv preprint arXiv:2105.03418;">
<meta name="citation_reference" content="citation_title=LeapfrogLayers: A trainable framework for effective topological sampling;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=arXiv preprint arXiv:2112.01582;">
<meta name="citation_reference" content="citation_title=Energy Justice Analysis of Climate Data with ClimRR;,citation_author=Sam Foreman;,citation_publication_date=2023-08-07;,citation_cover_date=2023-08-07;,citation_year=2023;,citation_fulltext_html_url=https://saforem2.github.io/climate-analysis;,citation_language=en;">
<meta name="citation_reference" content="citation_author=Sam Foreman;,citation_publication_date=2023-08-19;,citation_cover_date=2023-08-19;,citation_year=2023;,citation_fulltext_html_url=https://saforem2.github.io/l2hmc-qcd;,citation_language=en;">
<meta name="citation_reference" content="citation_title=MLMC: Machine learning monte carlo for lattice gauge theory;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James Osborn;,citation_publication_date=00;,citation_cover_date=00;,citation_year=0;,citation_conference_title=40th international symposium on lattice field theory (lattice 2023) (batavia, IL, united states, 07/31/2023 - 08/04/2023);">
<meta name="citation_reference" content="citation_title=Progress on $(g-2)_\mu$ from lattice QCD;,citation_author=Hartmut Wittig;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2306.04165;">
<meta name="citation_reference" content="citation_title=Hybrid Monte Carlo;,citation_author=S. Duane;,citation_author=A. D. Kennedy;,citation_author=B. J. Pendleton;,citation_author=D. Roweth;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;,citation_doi=10.1016/0370-2693(87)91197-X;,citation_volume=195;,citation_journal_title=Phys. Lett. B;">
<meta name="citation_reference" content="citation_title=Snowmass 2021 Computational Frontier CompF03 Topical Group Report: Machine Learning;,citation_author=Phiala Shanahan;,citation_author=others;,citation_publication_date=2022-09;,citation_cover_date=2022-09;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2209.07559;">
<meta name="citation_reference" content="citation_title=Applications of Machine Learning to Lattice Quantum Field Theory;,citation_author=Denis Boyda;,citation_author=others;,citation_publication_date=2022-02;,citation_cover_date=2022-02;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2202.05838;,citation_conference_title=Snowmass 2021;">
<meta name="citation_reference" content="citation_title=LeapfrogLayers: A Trainable Framework for Effective Topological Sampling;,citation_author=S. Foreman;,citation_author=X. Jin;,citation_author=J. Osborn;,citation_publication_date=2022-07;,citation_cover_date=2022-07;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01582;,citation_doi=10.22323/1.396.0508;,citation_conference_title=The 38th international symposium on lattice field theory;">
<meta name="citation_reference" content="citation_title=HMC with Normalizing Flows;,citation_author=Sam Foreman;,citation_author=Taku Izubuchi;,citation_author=Luchang Jin;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_author=Akio Tomiya;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01586;,citation_doi=10.22323/1.396.0073;,citation_volume=LATTICE2021;,citation_journal_title=PoS;">
<meta name="citation_reference" content="citation_title=Mastering language models;,citation_author=Samuel Montgomery;,citation_publication_date=2023-10;,citation_cover_date=2023-10;,citation_year=2023;,citation_fulltext_html_url=https://towardsdatascience.com/mastering-language-models-32e1d891511a
           ;,citation_journal_title=Medium;,citation_publisher=Towards Data Science;">
<meta name="citation_reference" content="citation_title=Harnessing the power of LLMs in practice: A survey on ChatGPT and beyond;,citation_author=Jingfeng Yang;,citation_author=Hongye Jin;,citation_author=Ruixiang Tang;,citation_author=Xiaotian Han;,citation_author=Qizhang Feng;,citation_author=Haoming Jiang;,citation_author=Bing Yin;,citation_author=Xia Hu;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2304.13712;">
<meta name="citation_reference" content="citation_title=Training tips for the transformer model;,citation_author=Martin Popel;,citation_author=Ondřej Bojar;,citation_publication_date=2018-04;,citation_cover_date=2018-04;,citation_year=2018;,citation_fulltext_html_url=https://doi.org/10.2478%2Fpralin-2018-0002;,citation_issue=1;,citation_doi=10.2478/pralin-2018-0002;,citation_volume=110;,citation_journal_title=The Prague Bulletin of Mathematical Linguistics;,citation_publisher=Charles University in Prague, Karolinum Press;">
<meta name="citation_reference" content="citation_title=Attention is all you need;,citation_author=Ashish Vaswani;,citation_author=Noam Shazeer;,citation_author=Niki Parmar;,citation_author=Jakob Uszkoreit;,citation_author=Llion Jones;,citation_author=Aidan N. Gomez;,citation_author=Lukasz Kaiser;,citation_author=Illia Polosukhin;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_fulltext_html_url=https://arxiv.org/abs/1706.03762;">
<meta name="citation_reference" content="citation_title=Tree of thoughts: Deliberate problem solving with large language models;,citation_author=Shunyu Yao;,citation_author=Dian Yu;,citation_author=Jeffrey Zhao;,citation_author=Izhak Shafran;,citation_author=Thomas L. Griffiths;,citation_author=Yuan Cao;,citation_author=Karthik Narasimhan;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2305.10601;">
<meta name="citation_reference" content="citation_title=GenSLMs: Genome-scale language models reveal SARS-CoV-2 evolutionary dynamics;,citation_abstract=We seek to transform how new and emergent variants of pandemiccausing viruses, specifically SARS-CoV-2, are identified and classified. By adapting large language models (LLMs) for genomic data, we build genome-scale language models (GenSLMs) which can learn the evolutionary landscape of SARS-CoV-2 genomes. By pretraining on over 110 million prokaryotic gene sequences and finetuning a SARS-CoV-2-specific model on 1.5 million genomes, we show that GenSLMs can accurately and rapidly identify variants of concern. Thus, to our knowledge, GenSLMs represents one of the first whole genome scale foundation models which can generalize to other prediction tasks. We demonstrate scaling of GenSLMs on GPU-based supercomputers and AI-hardware accelerators utilizing 1.63 Zettaflops in training runs with a sustained performance of 121 PFLOPS in mixed precision and peak of 850 PFLOPS. We present initial scientific insights from examining GenSLMs in tracking evolutionary dynamics of SARS-CoV-2, paving the path to realizing this on large biological data.Competing Interest StatementThe authors have declared no competing interest.;,citation_author=Maxim Zvyagin;,citation_author=Alexander Brace;,citation_author=Kyle Hippe;,citation_author=Yuntian Deng;,citation_author=Bin Zhang;,citation_author=Cindy Orozco Bohorquez;,citation_author=Austin Clyde;,citation_author=Bharat Kale;,citation_author=Danilo Perez-Rivera;,citation_author=Heng Ma;,citation_author=Carla M. Mann;,citation_author=Michael Irvin;,citation_author=J. Gregory Pauloski;,citation_author=Logan Ward;,citation_author=Valerie Hayot-Sasson;,citation_author=Murali Emani;,citation_author=Sam Foreman;,citation_author=Zhen Xie;,citation_author=Diangen Lin;,citation_author=Maulik Shukla;,citation_author=Weili Nie;,citation_author=Josh Romero;,citation_author=Christian Dallago;,citation_author=Arash Vahdat;,citation_author=Chaowei Xiao;,citation_author=Thomas Gibbs;,citation_author=Ian Foster;,citation_author=James J. Davis;,citation_author=Michael E. Papka;,citation_author=Thomas Brettin;,citation_author=Rick Stevens;,citation_author=Anima Anandkumar;,citation_author=Venkatram Vishwanath;,citation_author=Arvind Ramanathan;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://www.biorxiv.org/content/early/2022/11/23/2022.10.10.511571;,citation_doi=10.1101/2022.10.10.511571;,citation_journal_title=bioRxiv;,citation_publisher=Cold Spring Harbor Laboratory;">
</head>

<body class="nav-sidebar floating quarto-dark"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = true;
    const queryPrefersDark = window.matchMedia('(prefers-color-scheme: dark)');
    const darkModeDefault = queryPrefersDark.matches;
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    queryPrefersDark.addEventListener("change", e => {
      if(window.localStorage.getItem("quarto-color-scheme") !== null)
        return;
      const alternate = e.matches
      toggleColorMode(alternate);
      localAlternateSentinel = e.matches ? 'alternate' : 'default'; // this is used alongside local storage!
      toggleGiscusIfUsed(alternate, darkModeDefault);
    });
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">
      Intro to HPC Bootcamp 2025
      </li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Intro to HPC Bootcamp 2025</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="./index.html" title="Home" class="quarto-navigation-tool px-1" aria-label="Home"><i class="bi bi-home"></i></a>
    <a href="https://github.com/saforem2/intro-hpc-bootcamp-2025" title="GitHub" class="quarto-navigation-tool px-1" aria-label="GitHub"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./00-intro-AI-HPC/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[00] Intro to AI and HPC</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-intro-AI-HPC/0-compute-systems/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[0] Compute Systems</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-intro-AI-HPC/1-shared-resources/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[1] Shared Resources</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-intro-AI-HPC/2-jupyter-notebooks/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[2] Jupyter Notebooks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-intro-AI-HPC/3-python/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[3] Using Python</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-intro-AI-HPC/4-data/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[4] Working with Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-intro-AI-HPC/5-mcmc-example/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[5] MCMC Example</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-intro-AI-HPC/6-linear-regression/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[6] Linear Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-intro-AI-HPC/7-statistical-learning/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[7] Statistical Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-intro-AI-HPC/8-clustering/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[8] Clustering</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./01-neural-networks/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[01] Neural Networks</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-neural-networks/0-intro/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[0] Intro to NNs</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-neural-networks/1-mnist/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[1] MNIST Example</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-neural-networks/1-mnist-ipynb/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[1] MNIST Example (ipynb)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-neural-networks/2-advanced/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[2] Advanced</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-neural-networks/3-conv-nets/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[3] Conv. Nets</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-neural-networks/4-representation-learning/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[4] Representation Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-neural-networks/5-distributed-training/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[5] Distributed Training</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./02-llms/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[02] Large Language Models</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-llms/00-intro-to-llms/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[0] Intro to LLMs</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-llms/01-hands-on-llms/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[1] Hands-on LLMs</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-llms/06-parallel-training/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[6] Parallel Training</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-llms/08-shakespeare-example-colab/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">[8] Shakespeare Example (Colab)</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#project-contents" id="toc-project-contents" class="nav-link active" data-scroll-target="#project-contents">📂 Project Contents</a></li>
  <li><a href="#distributed-training-example" id="toc-distributed-training-example" class="nav-link" data-scroll-target="#distributed-training-example">🌐 Distributed Training Example</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/saforem2/intro-hpc-bootcamp-2025/blob/main/index.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/saforem2/intro-hpc-bootcamp-2025/edit/main/index.qmd" class="toc-action"><i class="bi empty"></i>Edit this page</a></li><li><a href="https://github.com/saforem2/intro-hpc-bootcamp-2025/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div><div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="index.ipynb" download="index.ipynb"><i class="bi bi-journal-code"></i>Jupyter</a></li><li><a href="README.md"><i class="bi bi-file-code"></i>Github (GFM)</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TC329HJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Intro to HPC Bootcamp 2025</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
  <div class="quarto-categories">
    <div class="quarto-category">ai4science</div>
    <div class="quarto-category">hpc</div>
    <div class="quarto-category">llm</div>
  </div>
  </div>

<div>
  <div class="description">
    Homepage for Sam Foreman’s Intro to HPC Bootcamp 2025 Project
  </div>
</div>

<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author"><a href="https://samforeman.me">Sam Foreman</a> <a href="mailto:foremans@anl.gov" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            <a href="https://alcf.anl.gov/about/people/sam-foreman">
            </a><a href="https://alcf.anl.gov/about/people/sam-foreman">ALCF</a>
            
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">July 15, 2025</p>
    </div>
  </div>
  
    <div>
    <div class="quarto-title-meta-heading">Modified</div>
    <div class="quarto-title-meta-contents">
      <p class="date-modified">August 14, 2025</p>
    </div>
  </div>
    
  </div>
  


</header>


<section id="project-contents" class="level2">
<h2 class="anchored" data-anchor-id="project-contents">📂 Project Contents</h2>
<ul>
<li><p>🏡 <a href="./">Intro to {AI, HPC} for Science/</a></p>
<ul>
<li>📂 <a href="00-intro-AI-HPC/"><strong>[00] Intro to AI and HPC</strong>/</a>
<ul>
<li>📄 <a href="./00-intro-AI-HPC/0-compute-systems/">[0] Compute systems</a></li>
<li>📄 <a href="./00-intro-AI-HPC/1-shared-resources/">[1] Shared-resources</a></li>
<li>📄 <a href="./00-intro-AI-HPC/2-jupyter-notebooks/">[2] Jupyter Notebooks</a></li>
<li>📄 <a href="./00-intro-AI-HPC/3-python/">[3] Using Python</a></li>
<li>📄 <a href="./00-intro-AI-HPC/4-data/">[4] Working with Data</a></li>
<li>📗 <a href="./00-intro-AI-HPC/5-mcmc-example/">[5] MCMC Example</a></li>
<li>📗 <a href="./00-intro-AI-HPC/6-linear-regression/">[6] Linear Regression</a></li>
<li>📗 <a href="./00-intro-AI-HPC/7-statistical-learning/">[7] Statistical Learning</a></li>
<li>📗 <a href="./00-intro-AI-HPC/8-clustering/">[8] Clustering</a></li>
</ul></li>
<li>📂 <a href="./01-neural-networks/"><strong>[01] Neural Networks/</strong></a>
<ul>
<li>📄 <a href="./01-neural-networks/0-intro/">[0] Intro</a></li>
<li>📗 <a href="./01-neural-networks/1-mnist/">[1] MNIST</a></li>
<li>📗 <a href="./01-neural-networks/1-mnist-ipynb/">[1] MNIST (ipynb)</a></li>
<li>📗 <a href="./01-neural-networks/2-advanced/">[2] Advanced</a></li>
<li>📗 <a href="./01-neural-networks/3-conv-nets/">[3] Conv. Nets</a></li>
<li>📗 <a href="./01-neural-networks/4-representation-learning/">[4] Representation Learning</a></li>
<li>📄 <a href="./01-neural-networks/5-distributed-training/">[5] Distributed Training</a></li>
</ul></li>
<li>📂 <a href="./02-llms/"><strong>[02] Large Language Models</strong></a>
<ul>
<li>📗 <a href="./02-llms/00-intro-to-llms/">[00] Intro to LLMs</a></li>
<li>📗 <a href="./02-llms/01-hands-on-llms/">[01] Hands-on LLMs</a></li>
<li>📄 <a href="./02-llms/02-prompt-engineering/">[02] Prompt Engineering</a> </li>
<li>📗 <a href="./02-llms/06-parallel-training/">[06] Parallel Training</a></li>
<li>📗 <a href="./02-llms/07-shakespeare-example/">[07] Shakespeare Example</a></li>
<li>📗 <a href="./02-llms/08-shakespeare-example-colab/">[08] Shakespeare Example (colab)</a></li>
</ul></li>
</ul>
<p></p></li>
</ul>
<details closed="">
<summary>
<h2 class="anchored">
🏔️ Instructions for Running @ NERSC
</h2>
</summary>
<ol type="1">
<li><p>Start terminal</p></li>
<li><p>Create symlink:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1"></a><span class="co"># symlink </span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="fu">ln</span> <span class="at">-s</span> /global/cfs/cdirs/m4388 <span class="va">$HOME</span>/m4388</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div></li>
<li><p>Navigate to <code>m4388</code> directory:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1"></a><span class="bu">cd</span> <span class="va">$HOME</span>/m4388</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div></li>
<li><p>Clone repo (somewhere) in <code>$HOME/$USER/</code>:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1"></a><span class="fu">mkdir</span> <span class="va">$USER</span> <span class="kw">&amp;&amp;</span> <span class="bu">cd</span> <span class="va">$USER</span></span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="fu">git</span> clone https://github.com/saforem2/intro-hpc-bootcamp-2025</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div></li>
<li><p>Find all Jupyter notebooks:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1"></a><span class="co"># find all *.ipynb files</span></span>
<span id="cb4-2"><a href="#cb4-2"></a><span class="fu">ls</span> <span class="pp">**</span>/<span class="pp">**</span>/<span class="pp">**</span>.ipynb <span class="kw">|</span> <span class="fu">grep</span> <span class="at">-v</span> <span class="st">"cache"</span> <span class="kw">|</span> <span class="fu">sort</span> <span class="kw">|</span> <span class="fu">uniq</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div></li>
</ol>
</details>
</section>
<section id="distributed-training-example" class="level2">
<h2 class="anchored" data-anchor-id="distributed-training-example">🌐 Distributed Training Example</h2>
<ol type="1">
<li><p>Login to Perlmutter:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1"></a><span class="fu">ssh</span> <span class="op">&lt;</span>user<span class="op">&gt;</span>@perlmutter.nersc.gov </span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="bu">[</span> <span class="ot">-d</span> <span class="va">$HOME</span>/m4388 <span class="bu">]</span> <span class="kw">||</span> <span class="fu">ln</span> <span class="at">-s</span> /global/cfs/cdirs/m4388 <span class="va">$HOME</span>/m4388</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div></li>
<li><p>Request an interactive job:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1"></a><span class="va">NODES</span><span class="op">=</span>2 <span class="kw">;</span> <span class="va">HRS</span><span class="op">=</span>02 <span class="kw">;</span> <span class="va">QUEUE</span><span class="op">=</span>interactive <span class="kw">;</span> <span class="ex">salloc</span> <span class="at">--nodes</span> <span class="va">$NODES</span> <span class="at">--qos</span> <span class="va">$QUEUE</span> <span class="at">--time</span> <span class="va">$HRS</span>:30:00 <span class="at">-C</span> <span class="st">'gpu'</span> <span class="at">--gpus</span><span class="op">=</span><span class="va">$((</span> <span class="dv">4</span> <span class="op">*</span> <span class="va">NODES</span> <span class="va">))</span> <span class="at">-A</span> m4388_g</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div></li>
<li><p>Clone <a href="https://github.com/saforem2/wordplay">wordplay</a> and navigate into it:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1"></a><span class="fu">mkdir</span> <span class="at">-p</span> <span class="st">"</span><span class="va">${HOME}</span><span class="st">/m4388/Project5/</span><span class="va">${USER}</span><span class="st">"</span></span>
<span id="cb7-2"><a href="#cb7-2"></a><span class="bu">cd</span> <span class="st">"</span><span class="va">${HOME}</span><span class="st">/m4388/Project5/</span><span class="va">${USER}</span><span class="st">"</span></span>
<span id="cb7-3"><a href="#cb7-3"></a><span class="fu">git</span> clone https://github.com/saforem2/wordplay <span class="kw">&amp;&amp;</span> <span class="bu">cd</span> wordplay</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div></li>
<li><p>Setup Python:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb8"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1"></a><span class="bu">source</span> <span class="op">&lt;(</span><span class="ex">curl</span> <span class="at">-L</span> https://bit.ly/ezpz-utils<span class="op">)</span></span>
<span id="cb8-2"><a href="#cb8-2"></a><span class="ex">ezpz_setup_python</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div></li>
<li><p>Setup <a href="https://wandb.ai">wandb</a>:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb9"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1"></a><span class="ex">wandb</span> login</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div></li>
<li><p>Install <a href="https://github.com/saforem2/wordplay"><code>wordplay</code></a>:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb10"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1"></a><span class="ex">python3</span> <span class="at">-m</span> pip install <span class="at">-e</span> <span class="st">"."</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div></li>
<li><p>Run <code>ezpz-test</code> (simple test to verify distributed functionality):</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb11"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1"></a><span class="ex">ezpz-test</span>  <span class="co"># &lt;- SHOULD WORK (🤞)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div></li>
<li><p>Prepare data:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb12"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb12-1"><a href="#cb12-1"></a><span class="ex">python3</span> <span class="at">-m</span> wordplay.prepare</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div></li>
<li><p>Run distributed training:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb13"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb13-1"><a href="#cb13-1"></a>  <span class="ex">ezpz-launch</span> <span class="at">-m</span> wordplay <span class="dt">\</span></span>
<span id="cb13-2"><a href="#cb13-2"></a>    train.backend=DDP <span class="dt">\</span></span>
<span id="cb13-3"><a href="#cb13-3"></a>    train.eval_interval=100 <span class="dt">\</span></span>
<span id="cb13-4"><a href="#cb13-4"></a>    data=shakespeare <span class="dt">\</span></span>
<span id="cb13-5"><a href="#cb13-5"></a>    train.dtype=bf16 <span class="dt">\</span></span>
<span id="cb13-6"><a href="#cb13-6"></a>    model.batch_size=8 <span class="dt">\</span></span>
<span id="cb13-7"><a href="#cb13-7"></a>    model.block_size=2048 <span class="dt">\</span></span>
<span id="cb13-8"><a href="#cb13-8"></a>    train.max_iters=1000 <span class="dt">\</span></span>
<span id="cb13-9"><a href="#cb13-9"></a>    train.log_interval=10 <span class="dt">\</span></span>
<span id="cb13-10"><a href="#cb13-10"></a>    train.compile=true</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><details closed="">
<summary>
Output
</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb14"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb14-1"><a href="#cb14-1"></a><span class="kw">(</span><span class="ex">👻</span> pytorch2.6.0<span class="kw">)</span></span>
<span id="cb14-2"><a href="#cb14-2"></a><span class="co">#[~/m/P/f/p/s/wordplay][🌱 main][🤷✓] via ⨁ v</span></span>
<span id="cb14-3"><a href="#cb14-3"></a><span class="co">#[08/14/25 @ 05:52:20][nid001237]</span></span>
<span id="cb14-4"><a href="#cb14-4"></a><span class="kw">;</span> <span class="ex">eezpz-launch-m</span> wordplay train.backend=DDP train.eval_interval=100 data=shakespeare train.dtype=bf16 model.batch_size=8 model.block_size=2048 train.max_iters=1000 train.log_interval=10 train.compile=true</span>
<span id="cb14-5"><a href="#cb14-5"></a><span class="ex">[2025-08-14</span> 05:53:17,261718]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/__init__:265:ezpz</span><span class="pp">]</span> Setting logging level to <span class="st">'INFO'</span> on <span class="st">'RANK == 0'</span></span>
<span id="cb14-6"><a href="#cb14-6"></a><span class="ex">[2025-08-14</span> 05:53:17,264886]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/__init__:266:ezpz</span><span class="pp">]</span> Setting logging level to <span class="st">'CRITICAL'</span> on all others <span class="st">'RANK != 0'</span></span>
<span id="cb14-7"><a href="#cb14-7"></a></span>
<span id="cb14-8"><a href="#cb14-8"></a></span>
<span id="cb14-9"><a href="#cb14-9"></a><span class="ex">[2025-08-14</span> 05:53:17,283662]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/launch:225</span><span class="pp">]</span> ======== [ezpz.launch: START] ========</span>
<span id="cb14-10"><a href="#cb14-10"></a><span class="ex">[2025-08-14</span> 05:53:17,508744]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/slurm:90</span><span class="pp">]</span> Checking jobid 41622690 for hostname nid001237...</span>
<span id="cb14-11"><a href="#cb14-11"></a><span class="ex">[2025-08-14</span> 05:53:17,509756]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/slurm:92</span><span class="pp">]</span> Found nid001237 in nodelist for 41622690</span>
<span id="cb14-12"><a href="#cb14-12"></a><span class="ex">[2025-08-14</span> 05:53:17,713837]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/slurm:90</span><span class="pp">]</span> Checking jobid 41622690 for hostname nid001237...</span>
<span id="cb14-13"><a href="#cb14-13"></a><span class="ex">[2025-08-14</span> 05:53:17,714591]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/slurm:92</span><span class="pp">]</span> Found nid001237 in nodelist for 41622690</span>
<span id="cb14-14"><a href="#cb14-14"></a><span class="ex">[2025-08-14</span> 05:53:17,977002]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/slurm:90</span><span class="pp">]</span> Checking jobid 41622690 for hostname nid001237...</span>
<span id="cb14-15"><a href="#cb14-15"></a><span class="ex">[2025-08-14</span> 05:53:17,977846]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/slurm:92</span><span class="pp">]</span> Found nid001237 in nodelist for 41622690</span>
<span id="cb14-16"><a href="#cb14-16"></a><span class="ex">[2025-08-14</span> 05:53:18,057066]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/slurm:109</span><span class="pp">]</span> Writing [<span class="st">'nid001237'</span>, <span class="st">'001240'</span>] to /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/wordplay/nodefile-41622690</span>
<span id="cb14-17"><a href="#cb14-17"></a><span class="ex">[2025-08-14</span> 05:53:18,089205]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/launch:230</span><span class="pp">]</span> Job ID: 41622690</span>
<span id="cb14-18"><a href="#cb14-18"></a><span class="ex">[2025-08-14</span> 05:53:18,089621]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/launch:231</span><span class="pp">]</span> nodelist: [<span class="st">'nid001237'</span>, <span class="st">'001240'</span>]</span>
<span id="cb14-19"><a href="#cb14-19"></a><span class="ex">[2025-08-14</span> 05:53:18,090032]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/launch:232</span><span class="pp">]</span> hostfile: /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/wordplay/nodefile-41622690</span>
<span id="cb14-20"><a href="#cb14-20"></a><span class="ex">[2025-08-14</span> 05:53:18,241020]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/slurm:90</span><span class="pp">]</span> Checking jobid 41622690 for hostname nid001237...</span>
<span id="cb14-21"><a href="#cb14-21"></a><span class="ex">[2025-08-14</span> 05:53:18,241792]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/slurm:92</span><span class="pp">]</span> Found nid001237 in nodelist for 41622690</span>
<span id="cb14-22"><a href="#cb14-22"></a><span class="ex">[2025-08-14</span> 05:53:18,328647]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/launch:253</span><span class="pp">]</span> Building command to execute by piecing together:</span>
<span id="cb14-23"><a href="#cb14-23"></a></span>
<span id="cb14-24"><a href="#cb14-24"></a>        <span class="kw">(</span><span class="ex">1.</span><span class="kw">)</span> <span class="ex">[</span><span class="st">'launch_cmd'</span><span class="ex">]</span> + <span class="er">(</span><span class="ex">2.</span><span class="kw">)</span> <span class="ex">[</span><span class="st">'python'</span><span class="ex">]</span> + <span class="er">(</span><span class="ex">3.</span><span class="kw">)</span> <span class="ex">[</span><span class="st">'cmd_to_launch'</span><span class="ex">]</span></span>
<span id="cb14-25"><a href="#cb14-25"></a></span>
<span id="cb14-26"><a href="#cb14-26"></a><span class="ex">[2025-08-14</span> 05:53:18,330096]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/launch:257</span><span class="pp">]</span> <span class="er">(</span><span class="ex">1.</span><span class="kw">)</span> <span class="ex">[</span><span class="st">'launch_cmd'</span><span class="ex">]:</span> srun <span class="at">-u</span> <span class="at">--verbose</span> <span class="at">-N2</span> <span class="at">-n8</span></span>
<span id="cb14-27"><a href="#cb14-27"></a><span class="ex">[2025-08-14</span> 05:53:18,330544]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/launch:258</span><span class="pp">]</span> <span class="er">(</span><span class="ex">2.</span><span class="kw">)</span> <span class="ex">[</span><span class="st">'python'</span><span class="ex">]:</span> /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/wordplay/venvs/perlmutter/pytorch2.6.0/bin/python3</span>
<span id="cb14-28"><a href="#cb14-28"></a><span class="ex">[2025-08-14</span> 05:53:18,330996]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/launch:259</span><span class="pp">]</span> <span class="er">(</span><span class="ex">3.</span><span class="kw">)</span> <span class="ex">[</span><span class="st">'cmd_to_launch'</span><span class="ex">]:</span>  <span class="at">-m</span> wordplay train.backend=DDP train.eval_interval=100 data=shakespeare train.dtype=bf16 model.batch_size=8 model.block_size=2048 train.max_iters=1000 train.log_interval=10 train.compile=true</span>
<span id="cb14-29"><a href="#cb14-29"></a><span class="ex">[2025-08-14</span> 05:53:18,331986]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/launch:264</span><span class="pp">]</span> Took: 1.05 seconds to build command.</span>
<span id="cb14-30"><a href="#cb14-30"></a><span class="ex">[2025-08-14</span> 05:53:18,332539]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/launch:268</span><span class="pp">]</span> Executing:</span>
<span id="cb14-31"><a href="#cb14-31"></a>        <span class="ex">srun</span></span>
<span id="cb14-32"><a href="#cb14-32"></a>        <span class="ex">-u</span></span>
<span id="cb14-33"><a href="#cb14-33"></a>        <span class="ex">--verbose</span></span>
<span id="cb14-34"><a href="#cb14-34"></a>        <span class="ex">-N2</span></span>
<span id="cb14-35"><a href="#cb14-35"></a>        <span class="ex">-n8</span></span>
<span id="cb14-36"><a href="#cb14-36"></a>        <span class="ex">/global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/wordplay/venvs/perlmutter/pytorch2.6.0/bin/python3</span></span>
<span id="cb14-37"><a href="#cb14-37"></a>        <span class="ex">-m</span></span>
<span id="cb14-38"><a href="#cb14-38"></a>        <span class="ex">wordplay</span></span>
<span id="cb14-39"><a href="#cb14-39"></a>        <span class="ex">train.backend=DDP</span></span>
<span id="cb14-40"><a href="#cb14-40"></a>        <span class="ex">train.eval_interval=100</span></span>
<span id="cb14-41"><a href="#cb14-41"></a>        <span class="va">data</span><span class="op">=</span>shakespeare</span>
<span id="cb14-42"><a href="#cb14-42"></a>        <span class="ex">train.dtype=bf16</span></span>
<span id="cb14-43"><a href="#cb14-43"></a>        <span class="ex">model.batch_size=8</span></span>
<span id="cb14-44"><a href="#cb14-44"></a>        <span class="ex">model.block_size=2048</span></span>
<span id="cb14-45"><a href="#cb14-45"></a>        <span class="ex">train.max_iters=1000</span></span>
<span id="cb14-46"><a href="#cb14-46"></a>        <span class="ex">train.log_interval=10</span></span>
<span id="cb14-47"><a href="#cb14-47"></a>        <span class="ex">train.compile=true</span></span>
<span id="cb14-48"><a href="#cb14-48"></a><span class="ex">[2025-08-14</span> 05:53:18,334155]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/launch:276</span><span class="pp">]</span> Execution started @ 2025-08-14-055318...</span>
<span id="cb14-49"><a href="#cb14-49"></a><span class="ex">[2025-08-14</span> 05:53:18,334619]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/launch:277</span><span class="pp">]</span> ======== [ezpz.launch: STOP] ========</span>
<span id="cb14-50"><a href="#cb14-50"></a></span>
<span id="cb14-51"><a href="#cb14-51"></a><span class="ex">srun:</span> defined options</span>
<span id="cb14-52"><a href="#cb14-52"></a><span class="ex">srun:</span> <span class="at">--------------------</span> <span class="at">--------------------</span></span>
<span id="cb14-53"><a href="#cb14-53"></a><span class="ex">srun:</span> <span class="er">(</span><span class="ex">null</span><span class="kw">)</span>              <span class="bu">:</span> nid<span class="pp">[</span><span class="ss">001237,001240</span><span class="pp">]</span></span>
<span id="cb14-54"><a href="#cb14-54"></a><span class="ex">srun:</span> gpus                : 8</span>
<span id="cb14-55"><a href="#cb14-55"></a><span class="ex">srun:</span> jobid               : 41622690</span>
<span id="cb14-56"><a href="#cb14-56"></a><span class="ex">srun:</span> job-name            : interactive</span>
<span id="cb14-57"><a href="#cb14-57"></a><span class="ex">srun:</span> mpi                 : cray_shasta</span>
<span id="cb14-58"><a href="#cb14-58"></a><span class="ex">srun:</span> nodes               : 2</span>
<span id="cb14-59"><a href="#cb14-59"></a><span class="ex">srun:</span> ntasks              : 8</span>
<span id="cb14-60"><a href="#cb14-60"></a><span class="ex">srun:</span> oom-kill-step       : 0</span>
<span id="cb14-61"><a href="#cb14-61"></a><span class="ex">srun:</span> slurmd-debug        : error</span>
<span id="cb14-62"><a href="#cb14-62"></a><span class="ex">srun:</span> unbuffered          : set</span>
<span id="cb14-63"><a href="#cb14-63"></a><span class="ex">srun:</span> verbose             : 1</span>
<span id="cb14-64"><a href="#cb14-64"></a><span class="ex">srun:</span> <span class="at">--------------------</span> <span class="at">--------------------</span></span>
<span id="cb14-65"><a href="#cb14-65"></a><span class="ex">srun:</span> end of defined options</span>
<span id="cb14-66"><a href="#cb14-66"></a><span class="ex">srun:</span> jobid 41622690: nodes<span class="er">(</span><span class="ex">2</span><span class="kw">)</span><span class="ex">:</span><span class="st">'nid[001237,001240]'</span><span class="ex">,</span> cpu counts: 128<span class="er">(</span><span class="ex">x2</span><span class="kw">)</span></span>
<span id="cb14-67"><a href="#cb14-67"></a><span class="ex">srun:</span> CpuBindType=<span class="er">(</span><span class="ex">null</span> type<span class="kw">)</span></span>
<span id="cb14-68"><a href="#cb14-68"></a><span class="ex">srun:</span> launching StepId=41622690.1 on host nid001237, 4 tasks: <span class="pp">[</span><span class="ss">0</span><span class="pp">-</span><span class="ss">3</span><span class="pp">]</span></span>
<span id="cb14-69"><a href="#cb14-69"></a><span class="ex">srun:</span> launching StepId=41622690.1 on host nid001240, 4 tasks: <span class="pp">[</span><span class="ss">4</span><span class="pp">-</span><span class="ss">7</span><span class="pp">]</span></span>
<span id="cb14-70"><a href="#cb14-70"></a><span class="ex">srun:</span> topology/default: init: topology Default plugin loaded</span>
<span id="cb14-71"><a href="#cb14-71"></a><span class="ex">srun:</span> Node nid001237, 4 tasks started</span>
<span id="cb14-72"><a href="#cb14-72"></a><span class="ex">srun:</span> Node nid001240, 4 tasks started</span>
<span id="cb14-73"><a href="#cb14-73"></a><span class="ex">[2025-08-14</span> 05:54:16,894992]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/__init__:265:ezpz</span><span class="pp">]</span> Setting logging level to <span class="st">'INFO'</span> on <span class="st">'RANK == 0'</span></span>
<span id="cb14-74"><a href="#cb14-74"></a><span class="ex">[2025-08-14</span> 05:54:16,897554]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/__init__:266:ezpz</span><span class="pp">]</span> Setting logging level to <span class="st">'CRITICAL'</span> on all others <span class="st">'RANK != 0'</span></span>
<span id="cb14-75"><a href="#cb14-75"></a><span class="ex">[2025-08-14</span> 05:54:17,040731]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/configs:81</span><span class="pp">]</span> Setting HF_DATASETS_CACHE to /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/wordplay/.cache/huggingface/datasets</span>
<span id="cb14-76"><a href="#cb14-76"></a><span class="ex">[2025-08-14</span> 05:54:18,062573]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1159</span><span class="pp">]</span> Using fw=<span class="st">'ddp'</span> with torch_<span class="dt">{device</span><span class="op">,</span><span class="dt">backend}</span>= {cuda, nccl}</span>
<span id="cb14-77"><a href="#cb14-77"></a><span class="ex">[2025-08-14</span> 05:54:18,063295]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1026</span><span class="pp">]</span> Caught MASTER_PORT=56513 from environment!</span>
<span id="cb14-78"><a href="#cb14-78"></a><span class="ex">[2025-08-14</span> 05:54:18,372603]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1042</span><span class="pp">]</span> Using torch.distributed.init_process_group with</span>
<span id="cb14-79"><a href="#cb14-79"></a><span class="ex">-</span> master_addr=<span class="st">'nid001237'</span></span>
<span id="cb14-80"><a href="#cb14-80"></a><span class="ex">-</span> master_port=<span class="st">'56513'</span></span>
<span id="cb14-81"><a href="#cb14-81"></a><span class="ex">-</span> world_size=8</span>
<span id="cb14-82"><a href="#cb14-82"></a><span class="ex">-</span> rank=0</span>
<span id="cb14-83"><a href="#cb14-83"></a><span class="ex">-</span> local_rank=0</span>
<span id="cb14-84"><a href="#cb14-84"></a><span class="ex">-</span> timeout=datetime.timedelta<span class="er">(</span><span class="va">seconds</span><span class="op">=</span>3600<span class="kw">)</span></span>
<span id="cb14-85"><a href="#cb14-85"></a><span class="ex">-</span> backend=<span class="st">'nccl'</span></span>
<span id="cb14-86"><a href="#cb14-86"></a><span class="ex">[2025-08-14</span> 05:54:18,373741]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:759</span><span class="pp">]</span> Calling torch.distributed.init_process_group_with: rank=0 world_size=8 backend=nccl</span>
<span id="cb14-87"><a href="#cb14-87"></a><span class="ex">[rank6]:[W814</span> 05:54:18.650817367 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 6]  using GPU 2 to perform barrier as devices usedby this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier<span class="er">(</span><span class="kw">)</span> <span class="ex">to</span> force use of a particular device, or call init_process_group<span class="er">(</span><span class="kw">)</span> <span class="ex">with</span> a device_id.</span>
<span id="cb14-88"><a href="#cb14-88"></a><span class="ex">[rank4]:[W814</span> 05:54:18.001713707 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 4]  using GPU 0 to perform barrier as devices usedby this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier<span class="er">(</span><span class="kw">)</span> <span class="ex">to</span> force use of a particular device, or call init_process_group<span class="er">(</span><span class="kw">)</span> <span class="ex">with</span> a device_id.</span>
<span id="cb14-89"><a href="#cb14-89"></a><span class="ex">[rank0]:[W814</span> 05:54:19.906551058 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices usedby this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier<span class="er">(</span><span class="kw">)</span> <span class="ex">to</span> force use of a particular device, or call init_process_group<span class="er">(</span><span class="kw">)</span> <span class="ex">with</span> a device_id.</span>
<span id="cb14-90"><a href="#cb14-90"></a><span class="ex">[rank5]:[W814</span> 05:54:19.231412634 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 5]  using GPU 1 to perform barrier as devices usedby this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier<span class="er">(</span><span class="kw">)</span> <span class="ex">to</span> force use of a particular device, or call init_process_group<span class="er">(</span><span class="kw">)</span> <span class="ex">with</span> a device_id.</span>
<span id="cb14-91"><a href="#cb14-91"></a><span class="ex">[rank7]:[W814</span> 05:54:19.394309045 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 7]  using GPU 3 to perform barrier as devices usedby this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier<span class="er">(</span><span class="kw">)</span> <span class="ex">to</span> force use of a particular device, or call init_process_group<span class="er">(</span><span class="kw">)</span> <span class="ex">with</span> a device_id.</span>
<span id="cb14-92"><a href="#cb14-92"></a><span class="ex">[rank3]:[W814</span> 05:54:19.232206867 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices usedby this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier<span class="er">(</span><span class="kw">)</span> <span class="ex">to</span> force use of a particular device, or call init_process_group<span class="er">(</span><span class="kw">)</span> <span class="ex">with</span> a device_id.</span>
<span id="cb14-93"><a href="#cb14-93"></a><span class="ex">[rank1]:[W814</span> 05:54:19.258096849 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices usedby this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier<span class="er">(</span><span class="kw">)</span> <span class="ex">to</span> force use of a particular device, or call init_process_group<span class="er">(</span><span class="kw">)</span> <span class="ex">with</span> a device_id.</span>
<span id="cb14-94"><a href="#cb14-94"></a><span class="ex">[rank2]:[W814</span> 05:54:19.258138279 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices usedby this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier<span class="er">(</span><span class="kw">)</span> <span class="ex">to</span> force use of a particular device, or call init_process_group<span class="er">(</span><span class="kw">)</span> <span class="ex">with</span> a device_id.</span>
<span id="cb14-95"><a href="#cb14-95"></a><span class="ex">[2025-08-14</span> 05:54:20,179821]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1377</span><span class="pp">]</span> Using device=<span class="st">'cuda'</span> with backend=<span class="st">'nccl'</span> + <span class="st">'nccl'</span> for distributed training.</span>
<span id="cb14-96"><a href="#cb14-96"></a><span class="ex">[2025-08-14</span> 05:54:20,181272]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1422</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'nid001237'</span><span class="pp">][</span><span class="ss">0/7</span><span class="pp">]</span></span>
<span id="cb14-97"><a href="#cb14-97"></a><span class="ex">[2025-08-14</span> 05:54:20,179635]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1422</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'nid001237'</span><span class="pp">][</span><span class="ss">1/7</span><span class="pp">]</span></span>
<span id="cb14-98"><a href="#cb14-98"></a><span class="ex">[2025-08-14</span> 05:54:20,179688]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1422</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'nid001240'</span><span class="pp">][</span><span class="ss">6/7</span><span class="pp">]</span></span>
<span id="cb14-99"><a href="#cb14-99"></a><span class="ex">[2025-08-14</span> 05:54:20,179683]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1422</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'nid001240'</span><span class="pp">][</span><span class="ss">7/7</span><span class="pp">]</span></span>
<span id="cb14-100"><a href="#cb14-100"></a><span class="ex">[2025-08-14</span> 05:54:20,179727]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1422</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'nid001237'</span><span class="pp">][</span><span class="ss">2/7</span><span class="pp">]</span></span>
<span id="cb14-101"><a href="#cb14-101"></a><span class="ex">[2025-08-14</span> 05:54:20,179700]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1422</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'nid001237'</span><span class="pp">][</span><span class="ss">3/7</span><span class="pp">]</span></span>
<span id="cb14-102"><a href="#cb14-102"></a><span class="ex">[2025-08-14</span> 05:54:20,179702]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1422</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'nid001240'</span><span class="pp">][</span><span class="ss">4/7</span><span class="pp">]</span></span>
<span id="cb14-103"><a href="#cb14-103"></a><span class="ex">[2025-08-14</span> 05:54:20,179691]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1422</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'nid001240'</span><span class="pp">][</span><span class="ss">5/7</span><span class="pp">]</span></span>
<span id="cb14-104"><a href="#cb14-104"></a><span class="ex">[2025-08-14</span> 05:54:20,213261]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/configs:317</span><span class="pp">]</span> Loading val from /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/wordplay/data/shakespeare_char/val.bin</span>
<span id="cb14-105"><a href="#cb14-105"></a><span class="ex">[2025-08-14</span> 05:54:20,215366]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/configs:317</span><span class="pp">]</span> Loading train from /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/wordplay/data/shakespeare_char/train.bin</span>
<span id="cb14-106"><a href="#cb14-106"></a><span class="ex">[2025-08-14</span> 05:54:20,221097]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/configs:442</span><span class="pp">]</span> Tokens per iteration: 131,072</span>
<span id="cb14-107"><a href="#cb14-107"></a><span class="ex">[2025-08-14</span> 05:54:20,221681]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/configs:465</span><span class="pp">]</span> Using self.ptdtype=torch.float16 on self.device_type=<span class="st">'cuda'</span></span>
<span id="cb14-108"><a href="#cb14-108"></a><span class="ex">[2025-08-14</span> 05:54:20,222155]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/configs:471</span><span class="pp">]</span> Initializing a new model from scratch</span>
<span id="cb14-109"><a href="#cb14-109"></a><span class="ex">[2025-08-14</span> 05:54:20,223622]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1648</span><span class="pp">]</span> Setting up wandb from rank=0</span>
<span id="cb14-110"><a href="#cb14-110"></a><span class="ex">[2025-08-14</span> 05:54:20,224043]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1649</span><span class="pp">]</span> Using WB_PROJECT=WordPlay</span>
<span id="cb14-111"><a href="#cb14-111"></a><span class="ex">wandb:</span> Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.</span>
<span id="cb14-112"><a href="#cb14-112"></a><span class="ex">wandb:</span> Currently logged in as: foremans <span class="er">(</span><span class="ex">aurora_gpt</span><span class="kw">)</span> <span class="ex">to</span> https://api.wandb.ai. Use <span class="kw">`</span><span class="ex">wandb</span> login <span class="at">--relogin</span><span class="kw">`</span> to force relogin</span>
<span id="cb14-113"><a href="#cb14-113"></a><span class="ex">wandb:</span> Tracking run with wandb version 0.19.7</span>
<span id="cb14-114"><a href="#cb14-114"></a><span class="ex">wandb:</span> Run data is saved locally in /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/outputs/runs/pytorch/DDP/2025-08-14/05-54-17/wandb/run-20250814_055421-qqpij4mt</span>
<span id="cb14-115"><a href="#cb14-115"></a><span class="ex">wandb:</span> Run <span class="kw">`</span><span class="ex">wandb</span> offline<span class="kw">`</span> to turn off syncing.</span>
<span id="cb14-116"><a href="#cb14-116"></a><span class="ex">wandb:</span> Syncing run helpful-sea-138</span>
<span id="cb14-117"><a href="#cb14-117"></a><span class="ex">wandb:</span> ⭐️ View project at https://wandb.ai/aurora_gpt/WordPlay</span>
<span id="cb14-118"><a href="#cb14-118"></a><span class="ex">wandb:</span> 🚀 View run at https://wandb.ai/aurora_gpt/WordPlay/runs/qqpij4mt</span>
<span id="cb14-119"><a href="#cb14-119"></a><span class="ex">[2025-08-14</span> 05:54:22,857365]<span class="pp">[</span><span class="ss">C</span><span class="pp">][</span><span class="ss">wordplay/trainer:322</span><span class="pp">]</span> RANK=1:devid=<span class="st">'cuda:1'</span></span>
<span id="cb14-120"><a href="#cb14-120"></a><span class="ex">[2025-08-14</span> 05:54:22,858391]<span class="pp">[</span><span class="ss">C</span><span class="pp">][</span><span class="ss">wordplay/trainer:322</span><span class="pp">]</span> RANK=3:devid=<span class="st">'cuda:3'</span></span>
<span id="cb14-121"><a href="#cb14-121"></a><span class="ex">[2025-08-14</span> 05:54:22,859157]<span class="pp">[</span><span class="ss">C</span><span class="pp">][</span><span class="ss">wordplay/trainer:322</span><span class="pp">]</span> RANK=2:devid=<span class="st">'cuda:2'</span></span>
<span id="cb14-122"><a href="#cb14-122"></a><span class="ex">[2025-08-14</span> 05:54:22,925017]<span class="pp">[</span><span class="ss">C</span><span class="pp">][</span><span class="ss">wordplay/trainer:322</span><span class="pp">]</span> RANK=7:devid=<span class="st">'cuda:3'</span></span>
<span id="cb14-123"><a href="#cb14-123"></a><span class="ex">[2025-08-14</span> 05:54:22,925164]<span class="pp">[</span><span class="ss">C</span><span class="pp">][</span><span class="ss">wordplay/trainer:322</span><span class="pp">]</span> RANK=6:devid=<span class="st">'cuda:2'</span></span>
<span id="cb14-124"><a href="#cb14-124"></a><span class="ex">[2025-08-14</span> 05:54:22,931160]<span class="pp">[</span><span class="ss">C</span><span class="pp">][</span><span class="ss">wordplay/trainer:322</span><span class="pp">]</span> RANK=4:devid=<span class="st">'cuda:0'</span></span>
<span id="cb14-125"><a href="#cb14-125"></a><span class="ex">[2025-08-14</span> 05:54:23,025155]<span class="pp">[</span><span class="ss">C</span><span class="pp">][</span><span class="ss">wordplay/trainer:322</span><span class="pp">]</span> RANK=5:devid=<span class="st">'cuda:1'</span></span>
<span id="cb14-126"><a href="#cb14-126"></a><span class="ex">[2025-08-14</span> 05:54:23,585980]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1678</span><span class="pp">]</span> wandb.run=<span class="pp">[</span><span class="ss">helpful</span><span class="pp">-</span><span class="ss">sea</span><span class="pp">-</span><span class="ss">138</span><span class="pp">]</span><span class="er">(</span><span class="ex">https://wandb.ai/aurora_gpt/WordPlay/runs/qqpij4mt</span><span class="kw">)</span></span>
<span id="cb14-127"><a href="#cb14-127"></a><span class="ex">[2025-08-14</span> 05:54:23,693859]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1722</span><span class="pp">]</span> Running on machine=<span class="st">'Perlmutter'</span></span>
<span id="cb14-128"><a href="#cb14-128"></a><span class="ex">[2025-08-14</span> 05:54:23,695938]<span class="pp">[</span><span class="ss">W</span><span class="pp">][</span><span class="ss">wordplay/__main__:93:__main__</span><span class="pp">]</span> {</span>
<span id="cb14-129"><a href="#cb14-129"></a>    <span class="st">"train"</span><span class="ex">:</span> {</span>
<span id="cb14-130"><a href="#cb14-130"></a>        <span class="st">"framework"</span><span class="ex">:</span> <span class="st">"pytorch"</span>,</span>
<span id="cb14-131"><a href="#cb14-131"></a>        <span class="st">"backend"</span><span class="ex">:</span> <span class="st">"DDP"</span>,</span>
<span id="cb14-132"><a href="#cb14-132"></a>        <span class="st">"device"</span><span class="ex">:</span> null,</span>
<span id="cb14-133"><a href="#cb14-133"></a>        <span class="st">"seed"</span><span class="ex">:</span> null,</span>
<span id="cb14-134"><a href="#cb14-134"></a>        <span class="st">"port"</span><span class="ex">:</span> null,</span>
<span id="cb14-135"><a href="#cb14-135"></a>        <span class="st">"ds_config_path"</span><span class="ex">:</span> null,</span>
<span id="cb14-136"><a href="#cb14-136"></a>        <span class="st">"precision"</span><span class="ex">:</span> null,</span>
<span id="cb14-137"><a href="#cb14-137"></a>        <span class="st">"ngpus"</span><span class="ex">:</span> null,</span>
<span id="cb14-138"><a href="#cb14-138"></a>        <span class="st">"use_wandb"</span><span class="ex">:</span> true,</span>
<span id="cb14-139"><a href="#cb14-139"></a>        <span class="st">"eval_interval"</span><span class="ex">:</span> 100,</span>
<span id="cb14-140"><a href="#cb14-140"></a>        <span class="st">"log_interval"</span><span class="ex">:</span> 10,</span>
<span id="cb14-141"><a href="#cb14-141"></a>        <span class="st">"eval_iters"</span><span class="ex">:</span> 200,</span>
<span id="cb14-142"><a href="#cb14-142"></a>        <span class="st">"eval_only"</span><span class="ex">:</span> false,</span>
<span id="cb14-143"><a href="#cb14-143"></a>        <span class="st">"always_save_checkpoint"</span><span class="ex">:</span> false,</span>
<span id="cb14-144"><a href="#cb14-144"></a>        <span class="st">"init_from"</span><span class="ex">:</span> <span class="st">"scratch"</span>,</span>
<span id="cb14-145"><a href="#cb14-145"></a>        <span class="st">"wandb_project"</span><span class="ex">:</span> <span class="st">"WordPlay"</span>,</span>
<span id="cb14-146"><a href="#cb14-146"></a>        <span class="st">"max_iters"</span><span class="ex">:</span> 1000,</span>
<span id="cb14-147"><a href="#cb14-147"></a>        <span class="st">"warmup_iters"</span><span class="ex">:</span> 100,</span>
<span id="cb14-148"><a href="#cb14-148"></a>        <span class="st">"dtype"</span><span class="ex">:</span> <span class="st">"bf16"</span>,</span>
<span id="cb14-149"><a href="#cb14-149"></a>        <span class="st">"compile"</span><span class="ex">:</span> true</span>
<span id="cb14-150"><a href="#cb14-150"></a>    <span class="er">}</span><span class="ex">,</span></span>
<span id="cb14-151"><a href="#cb14-151"></a>    <span class="st">"model"</span><span class="ex">:</span> {</span>
<span id="cb14-152"><a href="#cb14-152"></a>        <span class="st">"n_layer"</span><span class="ex">:</span> 12,</span>
<span id="cb14-153"><a href="#cb14-153"></a>        <span class="st">"n_head"</span><span class="ex">:</span> 12,</span>
<span id="cb14-154"><a href="#cb14-154"></a>        <span class="st">"n_embd"</span><span class="ex">:</span> 768,</span>
<span id="cb14-155"><a href="#cb14-155"></a>        <span class="st">"batch_size"</span><span class="ex">:</span> 8,</span>
<span id="cb14-156"><a href="#cb14-156"></a>        <span class="st">"block_size"</span><span class="ex">:</span> 2048,</span>
<span id="cb14-157"><a href="#cb14-157"></a>        <span class="st">"activation"</span><span class="ex">:</span> <span class="st">"gelu"</span>,</span>
<span id="cb14-158"><a href="#cb14-158"></a>        <span class="st">"dropout"</span><span class="ex">:</span> 0.0,</span>
<span id="cb14-159"><a href="#cb14-159"></a>        <span class="st">"bias"</span><span class="ex">:</span> false,</span>
<span id="cb14-160"><a href="#cb14-160"></a>        <span class="st">"vocab_size"</span><span class="ex">:</span> 65</span>
<span id="cb14-161"><a href="#cb14-161"></a>    <span class="er">}</span><span class="ex">,</span></span>
<span id="cb14-162"><a href="#cb14-162"></a>    <span class="st">"data"</span><span class="ex">:</span> {</span>
<span id="cb14-163"><a href="#cb14-163"></a>        <span class="st">"dataset"</span><span class="ex">:</span> <span class="st">"shakespeare_char"</span>,</span>
<span id="cb14-164"><a href="#cb14-164"></a>        <span class="st">"out_dir"</span><span class="ex">:</span> <span class="st">"out-shakespeare-char"</span>,</span>
<span id="cb14-165"><a href="#cb14-165"></a>        <span class="st">"root_path"</span><span class="ex">:</span> null</span>
<span id="cb14-166"><a href="#cb14-166"></a>    <span class="er">}</span><span class="ex">,</span></span>
<span id="cb14-167"><a href="#cb14-167"></a>    <span class="st">"optimizer"</span><span class="ex">:</span> {</span>
<span id="cb14-168"><a href="#cb14-168"></a>        <span class="st">"gas"</span><span class="ex">:</span> 1,</span>
<span id="cb14-169"><a href="#cb14-169"></a>        <span class="st">"name"</span><span class="ex">:</span> <span class="st">"AdamW"</span>,</span>
<span id="cb14-170"><a href="#cb14-170"></a>        <span class="st">"learning_rate"</span><span class="ex">:</span> 0.0006,</span>
<span id="cb14-171"><a href="#cb14-171"></a>        <span class="st">"weight_decay"</span><span class="ex">:</span> 0.1,</span>
<span id="cb14-172"><a href="#cb14-172"></a>        <span class="st">"beta1"</span><span class="ex">:</span> 0.9,</span>
<span id="cb14-173"><a href="#cb14-173"></a>        <span class="st">"beta2"</span><span class="ex">:</span> 0.95,</span>
<span id="cb14-174"><a href="#cb14-174"></a>        <span class="st">"grad_clip"</span><span class="ex">:</span> 1.0,</span>
<span id="cb14-175"><a href="#cb14-175"></a>        <span class="st">"decay_lr"</span><span class="ex">:</span> true,</span>
<span id="cb14-176"><a href="#cb14-176"></a>        <span class="st">"lr_decay_iters"</span><span class="ex">:</span> 600000,</span>
<span id="cb14-177"><a href="#cb14-177"></a>        <span class="st">"min_lr"</span><span class="ex">:</span> 6e-05</span>
<span id="cb14-178"><a href="#cb14-178"></a>    <span class="er">}</span></span>
<span id="cb14-179"><a href="#cb14-179"></a><span class="er">}</span></span>
<span id="cb14-180"><a href="#cb14-180"></a><span class="ex">[2025-08-14</span> 05:54:23,698890]<span class="pp">[</span><span class="ss">W</span><span class="pp">][</span><span class="ss">wordplay/__main__:94:__main__</span><span class="pp">]</span> Output dir: /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/outputs/runs/pytorch/DDP/2025-08-14/05-54-17</span>
<span id="cb14-181"><a href="#cb14-181"></a><span class="ex">[2025-08-14</span> 05:54:23,699444]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:234</span><span class="pp">]</span> Initializing a new model from scratch</span>
<span id="cb14-182"><a href="#cb14-182"></a><span class="ex">[2025-08-14</span> 05:54:24,575640]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/model:255</span><span class="pp">]</span> number of parameters: 85.00M</span>
<span id="cb14-183"><a href="#cb14-183"></a><span class="ex">[2025-08-14</span> 05:54:24,625918]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:251</span><span class="pp">]</span> Model size: num_params=85003776</span>
<span id="cb14-184"><a href="#cb14-184"></a><span class="ex">[2025-08-14</span> 05:54:24,637219]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/model:445</span><span class="pp">]</span> num decayed parameter tensors: 50, with 86,557,440 parameters</span>
<span id="cb14-185"><a href="#cb14-185"></a><span class="ex">[2025-08-14</span> 05:54:24,637872]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/model:449</span><span class="pp">]</span> num non-decayed parameter tensors: 25, with 19,200 parameters</span>
<span id="cb14-186"><a href="#cb14-186"></a><span class="ex">[2025-08-14</span> 05:54:24,638937]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/model:465</span><span class="pp">]</span> using fused AdamW: True</span>
<span id="cb14-187"><a href="#cb14-187"></a><span class="ex">[2025-08-14</span> 05:54:25,662969]<span class="pp">[</span><span class="ss">C</span><span class="pp">][</span><span class="ss">wordplay/trainer:322</span><span class="pp">]</span> RANK=0:devid=<span class="st">'cuda:0'</span></span>
<span id="cb14-188"><a href="#cb14-188"></a><span class="ex">[2025-08-14</span> 05:54:25,748890]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:361</span><span class="pp">]</span> • self.model=OptimizedModule<span class="er">(</span></span>
<span id="cb14-189"><a href="#cb14-189"></a>  <span class="kw">(</span><span class="ex">_orig_mod</span><span class="kw">)</span><span class="bu">:</span> GPT<span class="er">(</span></span>
<span id="cb14-190"><a href="#cb14-190"></a>    <span class="kw">(</span><span class="ex">transformer</span><span class="kw">)</span><span class="bu">:</span> ModuleDict<span class="er">(</span></span>
<span id="cb14-191"><a href="#cb14-191"></a>      <span class="kw">(</span><span class="ex">wte</span><span class="kw">)</span><span class="bu">:</span> Embedding<span class="er">(</span><span class="ex">65,</span> 768<span class="kw">)</span></span>
<span id="cb14-192"><a href="#cb14-192"></a>      <span class="kw">(</span><span class="ex">wpe</span><span class="kw">)</span><span class="bu">:</span> Embedding<span class="er">(</span><span class="ex">2048,</span> 768<span class="kw">)</span></span>
<span id="cb14-193"><a href="#cb14-193"></a>      <span class="kw">(</span><span class="ex">drop</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb14-194"><a href="#cb14-194"></a>      <span class="kw">(</span><span class="ex">h</span><span class="kw">)</span><span class="bu">:</span> ModuleList<span class="er">(</span></span>
<span id="cb14-195"><a href="#cb14-195"></a>        <span class="kw">(</span><span class="ex">0-11</span><span class="kw">)</span><span class="bu">:</span> 12 x Block<span class="er">(</span></span>
<span id="cb14-196"><a href="#cb14-196"></a>          <span class="kw">(</span><span class="ex">ln_1</span><span class="kw">)</span><span class="bu">:</span> LayerNorm<span class="er">(</span><span class="kw">)</span></span>
<span id="cb14-197"><a href="#cb14-197"></a>          <span class="kw">(</span><span class="ex">attn</span><span class="kw">)</span><span class="bu">:</span> CausalSelfAttention<span class="er">(</span></span>
<span id="cb14-198"><a href="#cb14-198"></a>            <span class="kw">(</span><span class="ex">c_attn</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>2304, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb14-199"><a href="#cb14-199"></a>            <span class="kw">(</span><span class="ex">c_proj</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>768, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb14-200"><a href="#cb14-200"></a>            <span class="kw">(</span><span class="ex">attn_dropout</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb14-201"><a href="#cb14-201"></a>            <span class="kw">(</span><span class="ex">resid_dropout</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb14-202"><a href="#cb14-202"></a>          <span class="kw">)</span></span>
<span id="cb14-203"><a href="#cb14-203"></a>          <span class="kw">(</span><span class="ex">ln_2</span><span class="kw">)</span><span class="bu">:</span> LayerNorm<span class="er">(</span><span class="kw">)</span></span>
<span id="cb14-204"><a href="#cb14-204"></a>          <span class="kw">(</span><span class="ex">mlp</span><span class="kw">)</span><span class="bu">:</span> MLP<span class="er">(</span></span>
<span id="cb14-205"><a href="#cb14-205"></a>            <span class="kw">(</span><span class="ex">c_fc</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>3072, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb14-206"><a href="#cb14-206"></a>            <span class="kw">(</span><span class="ex">act_fn</span><span class="kw">)</span><span class="bu">:</span> GELU<span class="er">(</span><span class="va">approximate</span><span class="op">=</span><span class="st">'none'</span><span class="kw">)</span></span>
<span id="cb14-207"><a href="#cb14-207"></a>            <span class="kw">(</span><span class="ex">c_proj</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>3072, <span class="va">out_features</span><span class="op">=</span>768, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb14-208"><a href="#cb14-208"></a>            <span class="kw">(</span><span class="ex">dropout</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb14-209"><a href="#cb14-209"></a>          <span class="kw">)</span></span>
<span id="cb14-210"><a href="#cb14-210"></a>        <span class="kw">)</span></span>
<span id="cb14-211"><a href="#cb14-211"></a>      <span class="kw">)</span></span>
<span id="cb14-212"><a href="#cb14-212"></a>      <span class="kw">(</span><span class="ex">ln_f</span><span class="kw">)</span><span class="bu">:</span> LayerNorm<span class="er">(</span><span class="kw">)</span></span>
<span id="cb14-213"><a href="#cb14-213"></a>    <span class="kw">)</span></span>
<span id="cb14-214"><a href="#cb14-214"></a>    <span class="kw">(</span><span class="ex">lm_head</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>65, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb14-215"><a href="#cb14-215"></a>  <span class="kw">)</span></span>
<span id="cb14-216"><a href="#cb14-216"></a><span class="kw">)</span></span>
<span id="cb14-217"><a href="#cb14-217"></a><span class="ex">[2025-08-14</span> 05:54:25,752694]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:362</span><span class="pp">]</span> • self.grad_scaler=<span class="op">&lt;</span>torch.cuda.amp.grad_scaler.GradScaler object at 0x14da15e752b0<span class="op">&gt;</span></span>
<span id="cb14-218"><a href="#cb14-218"></a><span class="ex">[2025-08-14</span> 05:54:25,753734]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:363</span><span class="pp">]</span> • self.model_engine=DistributedDataParallel<span class="er">(</span></span>
<span id="cb14-219"><a href="#cb14-219"></a>  <span class="kw">(</span><span class="ex">module</span><span class="kw">)</span><span class="bu">:</span> OptimizedModule<span class="er">(</span></span>
<span id="cb14-220"><a href="#cb14-220"></a>    <span class="kw">(</span><span class="ex">_orig_mod</span><span class="kw">)</span><span class="bu">:</span> GPT<span class="er">(</span></span>
<span id="cb14-221"><a href="#cb14-221"></a>      <span class="kw">(</span><span class="ex">transformer</span><span class="kw">)</span><span class="bu">:</span> ModuleDict<span class="er">(</span></span>
<span id="cb14-222"><a href="#cb14-222"></a>        <span class="kw">(</span><span class="ex">wte</span><span class="kw">)</span><span class="bu">:</span> Embedding<span class="er">(</span><span class="ex">65,</span> 768<span class="kw">)</span></span>
<span id="cb14-223"><a href="#cb14-223"></a>        <span class="kw">(</span><span class="ex">wpe</span><span class="kw">)</span><span class="bu">:</span> Embedding<span class="er">(</span><span class="ex">2048,</span> 768<span class="kw">)</span></span>
<span id="cb14-224"><a href="#cb14-224"></a>        <span class="kw">(</span><span class="ex">drop</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb14-225"><a href="#cb14-225"></a>        <span class="kw">(</span><span class="ex">h</span><span class="kw">)</span><span class="bu">:</span> ModuleList<span class="er">(</span></span>
<span id="cb14-226"><a href="#cb14-226"></a>          <span class="kw">(</span><span class="ex">0-11</span><span class="kw">)</span><span class="bu">:</span> 12 x Block<span class="er">(</span></span>
<span id="cb14-227"><a href="#cb14-227"></a>            <span class="kw">(</span><span class="ex">ln_1</span><span class="kw">)</span><span class="bu">:</span> LayerNorm<span class="er">(</span><span class="kw">)</span></span>
<span id="cb14-228"><a href="#cb14-228"></a>            <span class="kw">(</span><span class="ex">attn</span><span class="kw">)</span><span class="bu">:</span> CausalSelfAttention<span class="er">(</span></span>
<span id="cb14-229"><a href="#cb14-229"></a>              <span class="kw">(</span><span class="ex">c_attn</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>2304, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb14-230"><a href="#cb14-230"></a>              <span class="kw">(</span><span class="ex">c_proj</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>768, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb14-231"><a href="#cb14-231"></a>              <span class="kw">(</span><span class="ex">attn_dropout</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb14-232"><a href="#cb14-232"></a>              <span class="kw">(</span><span class="ex">resid_dropout</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb14-233"><a href="#cb14-233"></a>            <span class="kw">)</span></span>
<span id="cb14-234"><a href="#cb14-234"></a>            <span class="kw">(</span><span class="ex">ln_2</span><span class="kw">)</span><span class="bu">:</span> LayerNorm<span class="er">(</span><span class="kw">)</span></span>
<span id="cb14-235"><a href="#cb14-235"></a>            <span class="kw">(</span><span class="ex">mlp</span><span class="kw">)</span><span class="bu">:</span> MLP<span class="er">(</span></span>
<span id="cb14-236"><a href="#cb14-236"></a>              <span class="kw">(</span><span class="ex">c_fc</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>3072, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb14-237"><a href="#cb14-237"></a>              <span class="kw">(</span><span class="ex">act_fn</span><span class="kw">)</span><span class="bu">:</span> GELU<span class="er">(</span><span class="va">approximate</span><span class="op">=</span><span class="st">'none'</span><span class="kw">)</span></span>
<span id="cb14-238"><a href="#cb14-238"></a>              <span class="kw">(</span><span class="ex">c_proj</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>3072, <span class="va">out_features</span><span class="op">=</span>768, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb14-239"><a href="#cb14-239"></a>              <span class="kw">(</span><span class="ex">dropout</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb14-240"><a href="#cb14-240"></a>            <span class="kw">)</span></span>
<span id="cb14-241"><a href="#cb14-241"></a>          <span class="kw">)</span></span>
<span id="cb14-242"><a href="#cb14-242"></a>        <span class="kw">)</span></span>
<span id="cb14-243"><a href="#cb14-243"></a>        <span class="kw">(</span><span class="ex">ln_f</span><span class="kw">)</span><span class="bu">:</span> LayerNorm<span class="er">(</span><span class="kw">)</span></span>
<span id="cb14-244"><a href="#cb14-244"></a>      <span class="kw">)</span></span>
<span id="cb14-245"><a href="#cb14-245"></a>      <span class="kw">(</span><span class="ex">lm_head</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>65, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb14-246"><a href="#cb14-246"></a>    <span class="kw">)</span></span>
<span id="cb14-247"><a href="#cb14-247"></a>  <span class="kw">)</span></span>
<span id="cb14-248"><a href="#cb14-248"></a><span class="kw">)</span></span>
<span id="cb14-249"><a href="#cb14-249"></a><span class="ex">[2025-08-14</span> 05:54:25,757292]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:364</span><span class="pp">]</span> • self.optimizer=AdamW <span class="er">(</span></span>
<span id="cb14-250"><a href="#cb14-250"></a><span class="ex">Parameter</span> Group 0</span>
<span id="cb14-251"><a href="#cb14-251"></a>    <span class="ex">amsgrad:</span> False</span>
<span id="cb14-252"><a href="#cb14-252"></a>    <span class="ex">betas:</span> <span class="er">(</span><span class="ex">0.9,</span> 0.95<span class="kw">)</span></span>
<span id="cb14-253"><a href="#cb14-253"></a>    <span class="ex">capturable:</span> False</span>
<span id="cb14-254"><a href="#cb14-254"></a>    <span class="ex">differentiable:</span> False</span>
<span id="cb14-255"><a href="#cb14-255"></a>    <span class="ex">eps:</span> 1e-08</span>
<span id="cb14-256"><a href="#cb14-256"></a>    <span class="ex">foreach:</span> None</span>
<span id="cb14-257"><a href="#cb14-257"></a>    <span class="ex">fused:</span> True</span>
<span id="cb14-258"><a href="#cb14-258"></a>    <span class="ex">lr:</span> 0.0006</span>
<span id="cb14-259"><a href="#cb14-259"></a>    <span class="ex">maximize:</span> False</span>
<span id="cb14-260"><a href="#cb14-260"></a>    <span class="ex">weight_decay:</span> 0.1</span>
<span id="cb14-261"><a href="#cb14-261"></a></span>
<span id="cb14-262"><a href="#cb14-262"></a><span class="ex">Parameter</span> Group 1</span>
<span id="cb14-263"><a href="#cb14-263"></a>    <span class="ex">amsgrad:</span> False</span>
<span id="cb14-264"><a href="#cb14-264"></a>    <span class="ex">betas:</span> <span class="er">(</span><span class="ex">0.9,</span> 0.95<span class="kw">)</span></span>
<span id="cb14-265"><a href="#cb14-265"></a>    <span class="ex">capturable:</span> False</span>
<span id="cb14-266"><a href="#cb14-266"></a>    <span class="ex">differentiable:</span> False</span>
<span id="cb14-267"><a href="#cb14-267"></a>    <span class="ex">eps:</span> 1e-08</span>
<span id="cb14-268"><a href="#cb14-268"></a>    <span class="ex">foreach:</span> None</span>
<span id="cb14-269"><a href="#cb14-269"></a>    <span class="ex">fused:</span> True</span>
<span id="cb14-270"><a href="#cb14-270"></a>    <span class="ex">lr:</span> 0.0006</span>
<span id="cb14-271"><a href="#cb14-271"></a>    <span class="ex">maximize:</span> False</span>
<span id="cb14-272"><a href="#cb14-272"></a>    <span class="ex">weight_decay:</span> 0.0</span>
<span id="cb14-273"><a href="#cb14-273"></a><span class="kw">)</span></span>
<span id="cb14-274"><a href="#cb14-274"></a><span class="ex">[2025-08-14</span> 05:54:25,759725]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:796</span><span class="pp">]</span> Startup time: 8.6967</span>
<span id="cb14-275"><a href="#cb14-275"></a>                <span class="ex">Training</span> Legend</span>
<span id="cb14-276"><a href="#cb14-276"></a><span class="ex">┏━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓</span></span>
<span id="cb14-277"><a href="#cb14-277"></a><span class="ex">┃</span>        abbr ┃ desc                           ┃</span>
<span id="cb14-278"><a href="#cb14-278"></a><span class="ex">┡━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩</span></span>
<span id="cb14-279"><a href="#cb14-279"></a><span class="ex">│</span>        step │ Current training iteration     │</span>
<span id="cb14-280"><a href="#cb14-280"></a><span class="ex">│</span>        loss │ Loss value                     │</span>
<span id="cb14-281"><a href="#cb14-281"></a><span class="ex">│</span>          dt │ Elapsed time per training step │</span>
<span id="cb14-282"><a href="#cb14-282"></a><span class="ex">│</span>         dtf │ Elapsed time per forward step  │</span>
<span id="cb14-283"><a href="#cb14-283"></a><span class="ex">│</span>         dtb │ Elapsed time per backward step │</span>
<span id="cb14-284"><a href="#cb14-284"></a><span class="ex">│</span>         sps │ Samples per second             │</span>
<span id="cb14-285"><a href="#cb14-285"></a><span class="ex">│</span> sps_per_gpu │ Samples per second <span class="er">(</span><span class="ex">per</span> GPU<span class="kw">)</span>   <span class="ex">│</span></span>
<span id="cb14-286"><a href="#cb14-286"></a><span class="ex">│</span>         tps │ Tokens per second              │</span>
<span id="cb14-287"><a href="#cb14-287"></a><span class="ex">│</span> tps_per_gpu │ Tokens per second <span class="er">(</span><span class="ex">per</span> GPU<span class="kw">)</span>    <span class="ex">│</span></span>
<span id="cb14-288"><a href="#cb14-288"></a><span class="ex">│</span>         mfu │ Model flops utilization        │</span>
<span id="cb14-289"><a href="#cb14-289"></a><span class="ex">└─────────────┴────────────────────────────────┘</span></span>
<span id="cb14-290"><a href="#cb14-290"></a><span class="ex">[2025-08-14</span> 05:54:27,146477]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:807</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'prompt'</span><span class="pp">]</span>: <span class="st">'What is an LLM?'</span></span>
<span id="cb14-291"><a href="#cb14-291"></a><span class="ex">[2025-08-14</span> 05:54:27,147296]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:810</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'response'</span><span class="pp">]</span>:</span>
<span id="cb14-292"><a href="#cb14-292"></a></span>
<span id="cb14-293"><a href="#cb14-293"></a><span class="ex">What</span> is an LLM<span class="pp">?</span> <span class="st">'hkk ''Evllll VWccm UzcW!W'':zlWk W  z! XXwltMMV!Qyyx'</span>y kDDvVX<span class="kw">;</span><span class="ex">WWlyy</span>  jKy<span class="kw">;</span><span class="ex">kkyyxxx</span><span class="va">$-</span><span class="ex">WDll</span>  l!<span class="kw">;</span><span class="ex">WWmmWW</span> eeJJzq.vv<span class="kw">;</span><span class="ot">! </span><span class="fu">w</span><span class="kw">;;</span><span class="ex">z</span><span class="st">'tlWDDDWklUJ ;yyNlccxQ-D V!MMG'</span><span class="ex">zt</span><span class="kw">;</span><span class="ex">WWk</span> lllUU D-kkXWUvvMy<span class="kw">;;</span><span class="ex">JrMCzl</span><span class="kw">;</span><span class="ex">Uve,z</span><span class="kw">;</span><span class="st">''</span><span class="ex">:VWQ-y</span><span class="va">$l</span><span class="ex">--o.cJD.yM</span><span class="st">'yyyZyyyVV$Qt!!kxuJeeD kll'</span><span class="ex">Uy-J</span><span class="st">'vV!tmkzJuM?!ppXXG;'</span></span>
<span id="cb14-294"><a href="#cb14-294"></a><span class="ex">[2025-08-14</span> 05:55:22,838950]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=10 loss=3.01934 dt=0.0778009 dtf=0.0055681 dtb=0.0124092 sps=102.827 sps_per_gpu=12.8533 tps=1.68471e+06 tps_per_gpu=210589 mfu=49.7121</span>
<span id="cb14-295"><a href="#cb14-295"></a><span class="ex">[2025-08-14</span> 05:55:23,622530]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=20 loss=2.73268 dt=0.0783059 dtf=0.00546336 dtb=0.0124693 sps=102.163 sps_per_gpu=12.7704 tps=1.67385e+06 tps_per_gpu=209231 mfu=49.6801</span>
<span id="cb14-296"><a href="#cb14-296"></a><span class="ex">[2025-08-14</span> 05:55:24,407385]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=30 loss=2.5634 dt=0.0784503 dtf=0.00536114 dtb=0.0125228 sps=101.975 sps_per_gpu=12.7469 tps=1.67076e+06 tps_per_gpu=208846 mfu=49.6421</span>
<span id="cb14-297"><a href="#cb14-297"></a><span class="ex">[2025-08-14</span> 05:55:25,192393]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=40 loss=2.51223 dt=0.0784606 dtf=0.00545081 dtb=0.012732 sps=101.962 sps_per_gpu=12.7452 tps=1.67054e+06 tps_per_gpu=208818 mfu=49.6073</span>
<span id="cb14-298"><a href="#cb14-298"></a><span class="ex">[2025-08-14</span> 05:55:25,977765]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=50 loss=2.49004 dt=0.079029 dtf=0.00523198 dtb=0.0125401 sps=101.229 sps_per_gpu=12.6536 tps=1.65853e+06 tps_per_gpu=207316 mfu=49.5406</span>
<span id="cb14-299"><a href="#cb14-299"></a><span class="ex">[2025-08-14</span> 05:55:26,761465]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=60 loss=2.45537 dt=0.07775 dtf=0.00518063 dtb=0.0127289 sps=102.894 sps_per_gpu=12.8617 tps=1.68581e+06 tps_per_gpu=210727 mfu=49.561</span>
<span id="cb14-300"><a href="#cb14-300"></a><span class="ex">[2025-08-14</span> 05:55:27,546584]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=70 loss=2.46909 dt=0.0782411 dtf=0.00528915 dtb=0.0125154 sps=102.248 sps_per_gpu=12.781 tps=1.67523e+06 tps_per_gpu=209404 mfu=49.5481</span>
<span id="cb14-301"><a href="#cb14-301"></a><span class="ex">[2025-08-14</span> 05:55:28,332687]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=80 loss=2.48264 dt=0.0792809 dtf=0.00552908 dtb=0.0130663 sps=100.907 sps_per_gpu=12.6134 tps=1.65326e+06 tps_per_gpu=206657 mfu=49.4717</span>
<span id="cb14-302"><a href="#cb14-302"></a><span class="ex">[2025-08-14</span> 05:55:29,118556]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=90 loss=2.51034 dt=0.0781782 dtf=0.00514289 dtb=0.0124665 sps=102.33 sps_per_gpu=12.7913 tps=1.67658e+06 tps_per_gpu=209573 mfu=49.4718</span>
<span id="cb14-303"><a href="#cb14-303"></a><span class="ex">[2025-08-14</span> 05:55:29,904022]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=100 loss=2.46516 dt=0.078483 dtf=0.00516737 dtb=0.0129046 sps=101.933 sps_per_gpu=12.7416 tps=1.67007e+06 tps_per_gpu=208758 mfu=49.4526</span>
<span id="cb14-304"><a href="#cb14-304"></a><span class="ex">[2025-08-14</span> 05:55:30,990755]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:807</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'prompt'</span><span class="pp">]</span>: <span class="st">'What is an LLM?'</span></span>
<span id="cb14-305"><a href="#cb14-305"></a><span class="ex">[2025-08-14</span> 05:55:30,991344]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:810</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'response'</span><span class="pp">]</span>:</span>
<span id="cb14-306"><a href="#cb14-306"></a></span>
<span id="cb14-307"><a href="#cb14-307"></a><span class="ex">What</span> is an LLM<span class="pp">?</span> denour sad is thot wind<span class="kw">;</span></span>
<span id="cb14-308"><a href="#cb14-308"></a><span class="ex">Ae</span> micome lofas t butowhatiom, ar thy mitheath anshthath o w gesurcingero w on</span>
<span id="cb14-309"><a href="#cb14-309"></a></span>
<span id="cb14-310"><a href="#cb14-310"></a><span class="ex">GArsitheath</span> the,</span>
<span id="cb14-311"><a href="#cb14-311"></a><span class="ex">Tordist</span> w nofout thoru ol t arthim he my,</span>
<span id="cb14-312"><a href="#cb14-312"></a><span class="ex">Thich</span> thingay</span>
<span id="cb14-313"><a href="#cb14-313"></a><span class="ex">Thot</span> we wiman hineisoule blt me s hat f aul the t,</span>
<span id="cb14-314"><a href="#cb14-314"></a><span class="ex">Tyoffove.</span></span>
<span id="cb14-315"><a href="#cb14-315"></a><span class="ex">Haicede</span> t tounon</span>
<span id="cb14-316"><a href="#cb14-316"></a><span class="ex">[2025-08-14</span> 05:55:40,218926]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:750</span><span class="pp">]</span> Saving checkpoint to: /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/outputs/runs/pytorch/DDP/2025-08-14/05-54-17</span>
<span id="cb14-317"><a href="#cb14-317"></a><span class="ex">[2025-08-14</span> 05:55:40,219705]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:751</span><span class="pp">]</span> Saving model to: /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/outputs/runs/pytorch/DDP/2025-08-14/05-54-17/model.pth</span>
<span id="cb14-318"><a href="#cb14-318"></a><span class="ex">[2025-08-14</span> 05:55:42,195499]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/configs:141</span><span class="pp">]</span> Appending /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/outputs/runs/pytorch/DDP/2025-08-14/05-54-17 to /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/wordplay/src/ckpts/checkpoints.log</span>
<span id="cb14-319"><a href="#cb14-319"></a><span class="ex">[2025-08-14</span> 05:55:42,999389]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=110 loss=2.43177 dt=0.0780071 dtf=0.00545025 dtb=0.0126532 sps=102.555 sps_per_gpu=12.8193 tps=1.68026e+06 tps_per_gpu=210032 mfu=49.4654</span>
<span id="cb14-320"><a href="#cb14-320"></a><span class="ex">[2025-08-14</span> 05:55:43,785978]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=120 loss=2.44182 dt=0.078106 dtf=0.00545009 dtb=0.0125079 sps=102.425 sps_per_gpu=12.8031 tps=1.67813e+06 tps_per_gpu=209766 mfu=49.4707</span>
<span id="cb14-321"><a href="#cb14-321"></a><span class="ex">[2025-08-14</span> 05:55:44,572009]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=130 loss=2.44907 dt=0.0785986 dtf=0.00526247 dtb=0.0123562 sps=101.783 sps_per_gpu=12.7229 tps=1.66761e+06 tps_per_gpu=208451 mfu=49.4444</span>
<span id="cb14-322"><a href="#cb14-322"></a><span class="ex">[2025-08-14</span> 05:55:45,358627]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=140 loss=2.39859 dt=0.0794152 dtf=0.00549359 dtb=0.0128465 sps=100.736 sps_per_gpu=12.592 tps=1.65047e+06 tps_per_gpu=206308 mfu=49.3701</span>
<span id="cb14-323"><a href="#cb14-323"></a><span class="ex">[2025-08-14</span> 05:55:46,146387]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=150 loss=2.42138 dt=0.079703 dtf=0.00618074 dtb=0.012967 sps=100.373 sps_per_gpu=12.5466 tps=1.6445e+06 tps_per_gpu=205563 mfu=49.2856</span>
<span id="cb14-324"><a href="#cb14-324"></a><span class="ex">[2025-08-14</span> 05:55:46,933663]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=160 loss=2.41715 dt=0.0793599 dtf=0.00549591 dtb=0.0130799 sps=100.807 sps_per_gpu=12.6008 tps=1.65161e+06 tps_per_gpu=206452 mfu=49.2306</span>
<span id="cb14-325"><a href="#cb14-325"></a><span class="ex">[2025-08-14</span> 05:55:47,721057]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=170 loss=2.44814 dt=0.0789742 dtf=0.00546218 dtb=0.012633 sps=101.299 sps_per_gpu=12.6624 tps=1.65968e+06 tps_per_gpu=207460 mfu=49.2049</span>
<span id="cb14-326"><a href="#cb14-326"></a><span class="ex">[2025-08-14</span> 05:55:48,507992]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=180 loss=2.41629 dt=0.0787978 dtf=0.00542163 dtb=0.0128453 sps=101.526 sps_per_gpu=12.6907 tps=1.6634e+06 tps_per_gpu=207925 mfu=49.1928</span>
<span id="cb14-327"><a href="#cb14-327"></a><span class="ex">[2025-08-14</span> 05:55:49,297076]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=190 loss=2.38078 dt=0.0781823 dtf=0.00540887 dtb=0.0122009 sps=102.325 sps_per_gpu=12.7906 tps=1.67649e+06 tps_per_gpu=209561 mfu=49.2204</span>
<span id="cb14-328"><a href="#cb14-328"></a><span class="ex">[2025-08-14</span> 05:55:50,085624]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=200 loss=2.38881 dt=0.0787827 dtf=0.00544194 dtb=0.012954 sps=101.545 sps_per_gpu=12.6931 tps=1.66372e+06 tps_per_gpu=207964 mfu=49.2077</span>
<span id="cb14-329"><a href="#cb14-329"></a><span class="ex">[2025-08-14</span> 05:55:51,182746]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:807</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'prompt'</span><span class="pp">]</span>: <span class="st">'What is an LLM?'</span></span>
<span id="cb14-330"><a href="#cb14-330"></a><span class="ex">[2025-08-14</span> 05:55:51,183345]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:810</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'response'</span><span class="pp">]</span>:</span>
<span id="cb14-331"><a href="#cb14-331"></a></span>
<span id="cb14-332"><a href="#cb14-332"></a><span class="ex">What</span> is an LLM<span class="pp">?</span></span>
<span id="cb14-333"><a href="#cb14-333"></a><span class="ex">TYMMurcomarl</span> he ffal ther the arisplit at in fil an arices tor<span class="dt">\'</span>se iom o foul yof forsthe,</span>
<span id="cb14-334"><a href="#cb14-334"></a><span class="ex">ADe</span> ce he the her slashe th ous ar me andone be the sorthe spof aris indllfll thir me ay the bldorom n de</span>
<span id="cb14-335"><a href="#cb14-335"></a><span class="ex">She</span> thit t,</span>
<span id="cb14-336"><a href="#cb14-336"></a><span class="ex">Clou</span> lllethe fourth wit thin, pr thee th bl hes</span>
<span id="cb14-337"><a href="#cb14-337"></a><span class="ex">[2025-08-14</span> 05:56:00,419222]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:750</span><span class="pp">]</span> Saving checkpoint to: /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/outputs/runs/pytorch/DDP/2025-08-14/05-54-17</span>
<span id="cb14-338"><a href="#cb14-338"></a><span class="ex">[2025-08-14</span> 05:56:00,420026]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:751</span><span class="pp">]</span> Saving model to: /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/outputs/runs/pytorch/DDP/2025-08-14/05-54-17/model.pth</span>
<span id="cb14-339"><a href="#cb14-339"></a><span class="ex">[2025-08-14</span> 05:56:03,473861]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/configs:141</span><span class="pp">]</span> Appending /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/outputs/runs/pytorch/DDP/2025-08-14/05-54-17 to /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/wordplay/src/ckpts/checkpoints.log</span>
<span id="cb14-340"><a href="#cb14-340"></a><span class="ex">[2025-08-14</span> 05:56:04,301502]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=210 loss=2.40137 dt=0.0777987 dtf=0.00521268 dtb=0.012754 sps=102.829 sps_per_gpu=12.8537 tps=1.68476e+06 tps_per_gpu=210595 mfu=49.2582</span>
<span id="cb14-341"><a href="#cb14-341"></a><span class="ex">[2025-08-14</span> 05:56:05,090312]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=220 loss=2.32615 dt=0.0785563 dtf=0.00518237 dtb=0.0124011 sps=101.838 sps_per_gpu=12.7297 tps=1.66851e+06 tps_per_gpu=208564 mfu=49.2558</span>
<span id="cb14-342"><a href="#cb14-342"></a><span class="ex">[2025-08-14</span> 05:56:05,875417]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=230 loss=2.28453 dt=0.0781005 dtf=0.00532893 dtb=0.0126092 sps=102.432 sps_per_gpu=12.804 tps=1.67825e+06 tps_per_gpu=209781 mfu=49.2824</span>
<span id="cb14-343"><a href="#cb14-343"></a><span class="ex">[2025-08-14</span> 05:56:06,662143]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=240 loss=2.32075 dt=0.0790562 dtf=0.0056354 dtb=0.0128831 sps=101.194 sps_per_gpu=12.6492 tps=1.65796e+06 tps_per_gpu=207245 mfu=49.2464</span>
<span id="cb14-344"><a href="#cb14-344"></a><span class="ex">[2025-08-14</span> 05:56:07,448907]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=250 loss=2.26398 dt=0.0782558 dtf=0.00549903 dtb=0.0123185 sps=102.229 sps_per_gpu=12.7786 tps=1.67492e+06 tps_per_gpu=209365 mfu=49.2641</span>
<span id="cb14-345"><a href="#cb14-345"></a><span class="ex">[2025-08-14</span> 05:56:08,237097]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=260 loss=2.20778 dt=0.0779999 dtf=0.00544577 dtb=0.0125349 sps=102.564 sps_per_gpu=12.8205 tps=1.68041e+06 tps_per_gpu=210052 mfu=49.2962</span>
<span id="cb14-346"><a href="#cb14-346"></a><span class="ex">[2025-08-14</span> 05:56:09,024535]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=270 loss=2.13115 dt=0.0790745 dtf=0.00544547 dtb=0.0127346 sps=101.17 sps_per_gpu=12.6463 tps=1.65758e+06 tps_per_gpu=207197 mfu=49.2577</span>
<span id="cb14-347"><a href="#cb14-347"></a><span class="ex">[2025-08-14</span> 05:56:09,812910]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=280 loss=2.1087 dt=0.078672 dtf=0.00547284 dtb=0.0126957 sps=101.688 sps_per_gpu=12.711 tps=1.66606e+06 tps_per_gpu=208257 mfu=49.2481</span>
<span id="cb14-348"><a href="#cb14-348"></a><span class="ex">[2025-08-14</span> 05:56:10,600338]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=290 loss=2.07268 dt=0.0785346 dtf=0.00520987 dtb=0.0126892 sps=101.866 sps_per_gpu=12.7332 tps=1.66897e+06 tps_per_gpu=208621 mfu=49.2481</span>
<span id="cb14-349"><a href="#cb14-349"></a><span class="ex">[2025-08-14</span> 05:56:11,388671]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=300 loss=1.94068 dt=0.0790002 dtf=0.00531021 dtb=0.0126261 sps=101.266 sps_per_gpu=12.6582 tps=1.65914e+06 tps_per_gpu=207392 mfu=49.219</span>
<span id="cb14-350"><a href="#cb14-350"></a><span class="ex">[2025-08-14</span> 05:56:12,465166]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:807</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'prompt'</span><span class="pp">]</span>: <span class="st">'What is an LLM?'</span></span>
<span id="cb14-351"><a href="#cb14-351"></a><span class="ex">[2025-08-14</span> 05:56:12,465770]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:810</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'response'</span><span class="pp">]</span>:</span>
<span id="cb14-352"><a href="#cb14-352"></a></span>
<span id="cb14-353"><a href="#cb14-353"></a><span class="ex">What</span> is an LLM<span class="pp">?</span></span>
<span id="cb14-354"><a href="#cb14-354"></a></span>
<span id="cb14-355"><a href="#cb14-355"></a><span class="ex">BHORLINUS:</span></span>
<span id="cb14-356"><a href="#cb14-356"></a><span class="ex">You</span> hes.</span>
<span id="cb14-357"><a href="#cb14-357"></a></span>
<span id="cb14-358"><a href="#cb14-358"></a><span class="ex">SORONE:</span></span>
<span id="cb14-359"><a href="#cb14-359"></a><span class="ex">What</span> the the he opteresint o of men sign ond the be, them wit ook hom sace win comend faren thy to the sate, the there my ford thim helinguss<span class="pp">?</span></span>
<span id="cb14-360"><a href="#cb14-360"></a></span>
<span id="cb14-361"><a href="#cb14-361"></a><span class="ex">Gest</span> will ningure lan friner thing fornce, his blout of dete to hee tweer he hou</span>
<span id="cb14-362"><a href="#cb14-362"></a><span class="ex">[2025-08-14</span> 05:56:21,695714]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:750</span><span class="pp">]</span> Saving checkpoint to: /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/outputs/runs/pytorch/DDP/2025-08-14/05-54-17</span>
<span id="cb14-363"><a href="#cb14-363"></a><span class="ex">[2025-08-14</span> 05:56:21,696469]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:751</span><span class="pp">]</span> Saving model to: /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/outputs/runs/pytorch/DDP/2025-08-14/05-54-17/model.pth</span>
<span id="cb14-364"><a href="#cb14-364"></a><span class="ex">[2025-08-14</span> 05:56:24,287565]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/configs:141</span><span class="pp">]</span> Appending /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/outputs/runs/pytorch/DDP/2025-08-14/05-54-17 to /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/wordplay/src/ckpts/checkpoints.log</span>
<span id="cb14-365"><a href="#cb14-365"></a><span class="ex">[2025-08-14</span> 05:56:25,085517]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=310 loss=1.95217 dt=0.0780975 dtf=0.0054995 dtb=0.0122778 sps=102.436 sps_per_gpu=12.8045 tps=1.67831e+06 tps_per_gpu=209789 mfu=49.2495</span>
<span id="cb14-366"><a href="#cb14-366"></a><span class="ex">[2025-08-14</span> 05:56:25,870824]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=320 loss=1.82002 dt=0.0780001 dtf=0.00549541 dtb=0.012604 sps=102.564 sps_per_gpu=12.8205 tps=1.68041e+06 tps_per_gpu=210051 mfu=49.283</span>
<span id="cb14-367"><a href="#cb14-367"></a><span class="ex">[2025-08-14</span> 05:56:26,657320]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=330 loss=1.80354 dt=0.080137 dtf=0.00549193 dtb=0.0133185 sps=99.8291 sps_per_gpu=12.4786 tps=1.6356e+06 tps_per_gpu=204450 mfu=49.181</span>
<span id="cb14-368"><a href="#cb14-368"></a><span class="ex">[2025-08-14</span> 05:56:27,444509]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=340 loss=1.7014 dt=0.0786976 dtf=0.00530128 dtb=0.012458 sps=101.655 sps_per_gpu=12.7069 tps=1.66551e+06 tps_per_gpu=208189 mfu=49.1775</span>
<span id="cb14-369"><a href="#cb14-369"></a><span class="ex">[2025-08-14</span> 05:56:28,230760]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=350 loss=1.70333 dt=0.0786828 dtf=0.00523585 dtb=0.0120742 sps=101.674 sps_per_gpu=12.7093 tps=1.66583e+06 tps_per_gpu=208228 mfu=49.1752</span>
<span id="cb14-370"><a href="#cb14-370"></a><span class="ex">[2025-08-14</span> 05:56:29,017482]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=360 loss=1.63698 dt=0.078231 dtf=0.00522951 dtb=0.0119305 sps=102.261 sps_per_gpu=12.7827 tps=1.67545e+06 tps_per_gpu=209431 mfu=49.2016</span>
<span id="cb14-371"><a href="#cb14-371"></a><span class="ex">[2025-08-14</span> 05:56:29,804709]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=370 loss=1.6209 dt=0.078897 dtf=0.00537987 dtb=0.0121035 sps=101.398 sps_per_gpu=12.6748 tps=1.66131e+06 tps_per_gpu=207663 mfu=49.1836</span>
<span id="cb14-372"><a href="#cb14-372"></a><span class="ex">[2025-08-14</span> 05:56:30,590656]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=380 loss=1.62243 dt=0.0783268 dtf=0.00511256 dtb=0.0119576 sps=102.136 sps_per_gpu=12.767 tps=1.6734e+06 tps_per_gpu=209175 mfu=49.2031</span>
<span id="cb14-373"><a href="#cb14-373"></a><span class="ex">[2025-08-14</span> 05:56:31,378053]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=390 loss=1.46302 dt=0.0787818 dtf=0.00514412 dtb=0.0120985 sps=101.546 sps_per_gpu=12.6933 tps=1.66373e+06 tps_per_gpu=207967 mfu=49.1921</span>
<span id="cb14-374"><a href="#cb14-374"></a><span class="ex">[2025-08-14</span> 05:56:32,164231]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=400 loss=1.48415 dt=0.0786123 dtf=0.00519092 dtb=0.0120484 sps=101.765 sps_per_gpu=12.7206 tps=1.66732e+06 tps_per_gpu=208415 mfu=49.1928</span>
<span id="cb14-375"><a href="#cb14-375"></a><span class="ex">[2025-08-14</span> 05:56:33,253719]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:807</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'prompt'</span><span class="pp">]</span>: <span class="st">'What is an LLM?'</span></span>
<span id="cb14-376"><a href="#cb14-376"></a><span class="ex">[2025-08-14</span> 05:56:33,254320]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:810</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'response'</span><span class="pp">]</span>:</span>
<span id="cb14-377"><a href="#cb14-377"></a></span>
<span id="cb14-378"><a href="#cb14-378"></a><span class="ex">What</span> is an LLM<span class="pp">?</span></span>
<span id="cb14-379"><a href="#cb14-379"></a></span>
<span id="cb14-380"><a href="#cb14-380"></a><span class="ex">EONTES:</span></span>
<span id="cb14-381"><a href="#cb14-381"></a><span class="ex">The</span> sir, or accution of him. Well oftiess a somet</span>
<span id="cb14-382"><a href="#cb14-382"></a><span class="ex">to</span> marry be of our livery: anst the nemble to tearture,</span>
<span id="cb14-383"><a href="#cb14-383"></a><span class="ex">to</span> prompt out sicibler out himself too suction.</span>
<span id="cb14-384"><a href="#cb14-384"></a><span class="ex">I</span> but stain time acfficiancel<span class="dt">\'</span>d cament, and all</span>
<span id="cb14-385"><a href="#cb14-385"></a><span class="ex">nom</span> officious laptimes famits of finge, have</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div></details></li>
</ul></li>
</ol>
<details class="code-fold">
<summary>👀</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1"></a><span class="im">import</span> datetime</span>
<span id="cb15-2"><a href="#cb15-2"></a><span class="im">from</span> rich <span class="im">import</span> <span class="bu">print</span></span>
<span id="cb15-3"><a href="#cb15-3"></a>now <span class="op">=</span> datetime.datetime.now()</span>
<span id="cb15-4"><a href="#cb15-4"></a><span class="bu">print</span>(<span class="st">' '</span>.join([ <span class="st">"[#838383]Last Updated[/]:"</span>, <span class="ss">f"[#E599F7]</span><span class="sc">{</span>now<span class="sc">.</span>strftime(<span class="st">"%Y-%m-</span><span class="sc">%d</span><span class="st">"</span>)<span class="sc">}</span><span class="ss">[/]"</span>, <span class="st">"[#838383]@[/]"</span>, <span class="ss">f"[#00CCFF]</span><span class="sc">{</span>now<span class="sc">.</span>strftime(<span class="st">"%H:%M:%S"</span>)<span class="sc">}</span><span class="ss">[/]"</span>, ]))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #838383; text-decoration-color: #838383">Last Updated</span>: <span style="color: #e599f7; text-decoration-color: #e599f7; font-weight: bold">2025</span><span style="color: #e599f7; text-decoration-color: #e599f7">-</span><span style="color: #e599f7; text-decoration-color: #e599f7; font-weight: bold">08</span><span style="color: #e599f7; text-decoration-color: #e599f7">-</span><span style="color: #e599f7; text-decoration-color: #e599f7; font-weight: bold">12</span> <span style="color: #838383; text-decoration-color: #838383">@</span> <span style="color: #00ccff; text-decoration-color: #00ccff; font-weight: bold">16:53:47</span>
</pre>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{foreman2025,
  author = {Foreman, Sam},
  title = {Intro to {HPC} {Bootcamp} 2025},
  date = {2025-07-15},
  url = {https://saforem2.github.io/intro-hpc-bootcamp-2025},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-foreman2025" class="csl-entry quarto-appendix-citeas" role="listitem">
Foreman, Sam. 2025. <span>“Intro to HPC Bootcamp 2025.”</span> July 15,
2025. <a href="https://saforem2.github.io/intro-hpc-bootcamp-2025">https://saforem2.github.io/intro-hpc-bootcamp-2025</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/saforem2\.github\.io\/hpc-bootcamp-2025\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<input type="hidden" id="giscus-base-theme" value="dark">
<input type="hidden" id="giscus-alt-theme" value="light">
<script>
  function loadGiscus() {
    // Function to get the theme based on body class
    const getTheme = () => {
      let baseTheme = document.getElementById('giscus-base-theme').value;
      let altTheme = document.getElementById('giscus-alt-theme').value;
      if (authorPrefersDark) {
          [baseTheme, altTheme] = [altTheme, baseTheme];
      }
      return document.body.classList.contains('quarto-dark') ? altTheme : baseTheme;
    };
    const script = document.createElement("script");
    script.src = "https://giscus.app/client.js";
    script.async = true;
    script.dataset.repo = "saforem2/intro-hpc-bootcamp-2025";
    script.dataset.repoId = "R_kgDOPQ7DhQ";
    script.dataset.category = "General";
    script.dataset.categoryId = "DIC_kwDOPQ7Dhc4CtXSR";
    script.dataset.mapping = "title";
    script.dataset.reactionsEnabled = "1";
    script.dataset.emitMetadata = "0";
    script.dataset.inputPosition = "top";
    script.dataset.theme = getTheme();
    script.dataset.lang = "en";
    script.crossOrigin = "anonymous";
    // Append the script to the desired div instead of at the end of the body
    document.getElementById("quarto-content").appendChild(script);
  }
  loadGiscus();
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb16" data-shortcodes="false"><pre class="sourceCode numberSource markdown number-lines code-with-copy"><code class="sourceCode markdown"><span id="cb16-1"><a href="#cb16-1"></a><span class="co">---</span></span>
<span id="cb16-2"><a href="#cb16-2"></a><span class="co"># toc: true</span></span>
<span id="cb16-3"><a href="#cb16-3"></a><span class="an">title:</span><span class="co"> "Intro to HPC Bootcamp 2025"</span></span>
<span id="cb16-4"><a href="#cb16-4"></a><span class="an">description:</span><span class="co"> "Homepage for Sam Foreman's Intro to HPC Bootcamp 2025 Project"</span></span>
<span id="cb16-5"><a href="#cb16-5"></a><span class="an">categories:</span></span>
<span id="cb16-6"><a href="#cb16-6"></a><span class="co">  - ai4science</span></span>
<span id="cb16-7"><a href="#cb16-7"></a><span class="co">  - hpc</span></span>
<span id="cb16-8"><a href="#cb16-8"></a><span class="co">  - llm</span></span>
<span id="cb16-9"><a href="#cb16-9"></a><span class="an">date:</span><span class="co"> 2025-07-15</span></span>
<span id="cb16-10"><a href="#cb16-10"></a><span class="an">date-modified:</span><span class="co"> last-modified</span></span>
<span id="cb16-11"><a href="#cb16-11"></a><span class="an">citation:</span></span>
<span id="cb16-12"><a href="#cb16-12"></a><span class="co">   author: Sam Foreman</span></span>
<span id="cb16-13"><a href="#cb16-13"></a><span class="co">   type: webpage</span></span>
<span id="cb16-14"><a href="#cb16-14"></a><span class="co">   title: "Intro to HPC Bootcamp 2025"</span></span>
<span id="cb16-15"><a href="#cb16-15"></a><span class="co">   url: https://saforem2.github.io/intro-hpc-bootcamp-2025</span></span>
<span id="cb16-16"><a href="#cb16-16"></a><span class="an">open-graph:</span></span>
<span id="cb16-17"><a href="#cb16-17"></a><span class="co">  title: "Intro to HPC Bootcamp 2025"</span></span>
<span id="cb16-18"><a href="#cb16-18"></a><span class="co">  description: "Homepage for Sam Foreman's Intro to HPC Bootcamp 2025 Project"</span></span>
<span id="cb16-19"><a href="#cb16-19"></a><span class="co">  # image: "./assets/thumbnail.png"</span></span>
<span id="cb16-20"><a href="#cb16-20"></a><span class="an">twitter-card:</span></span>
<span id="cb16-21"><a href="#cb16-21"></a><span class="co">  title: "Intro to HPC Bootcamp 2025"</span></span>
<span id="cb16-22"><a href="#cb16-22"></a><span class="co">  description: "Homepage for Sam Foreman's Intro to HPC Bootcamp 2025 Project"</span></span>
<span id="cb16-23"><a href="#cb16-23"></a><span class="co">  site: "saforem2"</span></span>
<span id="cb16-24"><a href="#cb16-24"></a><span class="co">  creator: "saforem2"</span></span>
<span id="cb16-25"><a href="#cb16-25"></a><span class="an">sidebar:</span><span class="co"> sidebar</span></span>
<span id="cb16-26"><a href="#cb16-26"></a><span class="co"># format: live-html</span></span>
<span id="cb16-27"><a href="#cb16-27"></a><span class="co"># format:</span></span>
<span id="cb16-28"><a href="#cb16-28"></a><span class="co">#   live-html:</span></span>
<span id="cb16-29"><a href="#cb16-29"></a><span class="co">#     respect-user-color-scheme: true</span></span>
<span id="cb16-30"><a href="#cb16-30"></a><span class="co">#     date-modified: last-modified</span></span>
<span id="cb16-31"><a href="#cb16-31"></a><span class="co">#     link-external-newwindow: true</span></span>
<span id="cb16-32"><a href="#cb16-32"></a><span class="co">#     link-external-icon: false</span></span>
<span id="cb16-33"><a href="#cb16-33"></a><span class="co">#     callout-appearance: simple</span></span>
<span id="cb16-34"><a href="#cb16-34"></a><span class="co">#     code-tools: true</span></span>
<span id="cb16-35"><a href="#cb16-35"></a><span class="co">#     code-link: true</span></span>
<span id="cb16-36"><a href="#cb16-36"></a><span class="co">#     code-line-numbers: true</span></span>
<span id="cb16-37"><a href="#cb16-37"></a><span class="co">#     toc: true</span></span>
<span id="cb16-38"><a href="#cb16-38"></a><span class="co">#     self-contained: false</span></span>
<span id="cb16-39"><a href="#cb16-39"></a><span class="co">#     default-image-extension: svg</span></span>
<span id="cb16-40"><a href="#cb16-40"></a><span class="co">#     toc-title: ""</span></span>
<span id="cb16-41"><a href="#cb16-41"></a><span class="co">#     page-layout: article</span></span>
<span id="cb16-42"><a href="#cb16-42"></a><span class="co">#     fig-width: 6.4</span></span>
<span id="cb16-43"><a href="#cb16-43"></a><span class="co">#     fig-height: 4.8</span></span>
<span id="cb16-44"><a href="#cb16-44"></a><span class="co">#     grid:</span></span>
<span id="cb16-45"><a href="#cb16-45"></a><span class="co">#       body-width: 1000px</span></span>
<span id="cb16-46"><a href="#cb16-46"></a><span class="co">#       margin-width: 250px</span></span>
<span id="cb16-47"><a href="#cb16-47"></a><span class="co">#       sidebar-width: 250px</span></span>
<span id="cb16-48"><a href="#cb16-48"></a><span class="co">#       # gutter-width: 1.5rem</span></span>
<span id="cb16-49"><a href="#cb16-49"></a><span class="co">#     fig-align: center</span></span>
<span id="cb16-50"><a href="#cb16-50"></a><span class="co">#     fig-responsive: true</span></span>
<span id="cb16-51"><a href="#cb16-51"></a><span class="co">#     anchor-sections: true</span></span>
<span id="cb16-52"><a href="#cb16-52"></a><span class="co">#     code-overflow: scroll</span></span>
<span id="cb16-53"><a href="#cb16-53"></a><span class="co">#     code-copy: hover</span></span>
<span id="cb16-54"><a href="#cb16-54"></a><span class="co">#     code-summary: " "</span></span>
<span id="cb16-55"><a href="#cb16-55"></a><span class="co">#     citations-hover: true</span></span>
<span id="cb16-56"><a href="#cb16-56"></a><span class="co">#     crossrefs-hover: true</span></span>
<span id="cb16-57"><a href="#cb16-57"></a><span class="co">#     html-math-method: katex</span></span>
<span id="cb16-58"><a href="#cb16-58"></a><span class="co">#     footnotes-hover: true</span></span>
<span id="cb16-59"><a href="#cb16-59"></a><span class="co">#     section-divs: true</span></span>
<span id="cb16-60"><a href="#cb16-60"></a><span class="co">#     highlight-style:</span></span>
<span id="cb16-61"><a href="#cb16-61"></a><span class="co">#       light: github</span></span>
<span id="cb16-62"><a href="#cb16-62"></a><span class="co">#       dark: github-dark</span></span>
<span id="cb16-63"><a href="#cb16-63"></a><span class="co">#     theme:</span></span>
<span id="cb16-64"><a href="#cb16-64"></a><span class="co">#       dark:</span></span>
<span id="cb16-65"><a href="#cb16-65"></a><span class="co">#         - css/common.scss</span></span>
<span id="cb16-66"><a href="#cb16-66"></a><span class="co">#         - css/dark.scss</span></span>
<span id="cb16-67"><a href="#cb16-67"></a><span class="co">#         - css/syntax-dark.scss</span></span>
<span id="cb16-68"><a href="#cb16-68"></a><span class="co">#         - css/callout-cards.scss</span></span>
<span id="cb16-69"><a href="#cb16-69"></a><span class="co">#         - default</span></span>
<span id="cb16-70"><a href="#cb16-70"></a><span class="co">#       light:</span></span>
<span id="cb16-71"><a href="#cb16-71"></a><span class="co">#         - css/common.scss</span></span>
<span id="cb16-72"><a href="#cb16-72"></a><span class="co">#         - css/light.scss</span></span>
<span id="cb16-73"><a href="#cb16-73"></a><span class="co">#         - css/syntax-light.scss</span></span>
<span id="cb16-74"><a href="#cb16-74"></a><span class="co">#         - css/callout-cards.scss</span></span>
<span id="cb16-75"><a href="#cb16-75"></a><span class="co">#         - default</span></span>
<span id="cb16-76"><a href="#cb16-76"></a><span class="co">#     include-in-header:</span></span>
<span id="cb16-77"><a href="#cb16-77"></a><span class="co">#       - text: | # KaTeX</span></span>
<span id="cb16-78"><a href="#cb16-78"></a><span class="co">#           &lt;link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css" integrity="sha384-5TcZemv2l/9On385z///+d7MSYlvIEw9FuZTIdZ14vJLqWphw7e7ZPuOiCHJcFCP" crossorigin="anonymous"&gt;</span></span>
<span id="cb16-79"><a href="#cb16-79"></a><span class="co">#           &lt;script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.js" integrity="sha384-cMkvdD8LoxVzGF/RPUKAcvmm49FQ0oxwDF3BGKtDXcEc+T1b2N+teh/OJfpU0jr6" crossorigin="anonymous"&gt;&lt;/script&gt;</span></span>
<span id="cb16-80"><a href="#cb16-80"></a><span class="co">#           &lt;script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/auto-render.min.js" integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" crossorigin="anonymous" onload="renderMathInElement(document.body);"&gt;&lt;/script&gt;</span></span>
<span id="cb16-81"><a href="#cb16-81"></a><span class="co">#           &lt;link rel="preconnect" href="https://fonts.googleapis.com"&gt;</span></span>
<span id="cb16-82"><a href="#cb16-82"></a><span class="co">#           &lt;link rel="preconnect" href="https://fonts.gstatic.com" crossorigin&gt;</span></span>
<span id="cb16-83"><a href="#cb16-83"></a><span class="co">#           &lt;link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&amp;family=IBM+Plex+Sans+Condensed:ital,wght@0,400;0,500;0,600;0,700&amp;family=IBM+Plex+Mono:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700&amp;display=swap" rel="stylesheet"&gt;</span></span>
<span id="cb16-84"><a href="#cb16-84"></a><span class="co">#           &lt;link href="https://fonts.googleapis.com/css?family=IBM+Plex+Sans&amp;family=IBM+Plex+Sans+Condensed&amp;family=IBM+Plex+Mono&amp;display=swap" rel="stylesheet"&gt;</span></span>
<span id="cb16-85"><a href="#cb16-85"></a><span class="co">#           &lt;!-- Google Tag Manager --&gt;</span></span>
<span id="cb16-86"><a href="#cb16-86"></a><span class="co">#           &lt;script&gt;(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&amp;l='+l:'';j.async=true;j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-TC329HJ');&lt;/script&gt;</span></span>
<span id="cb16-87"><a href="#cb16-87"></a><span class="co">#           &lt;!-- End Google Tag Manager --&gt;</span></span>
<span id="cb16-88"><a href="#cb16-88"></a><span class="co">#     include-before-body:</span></span>
<span id="cb16-89"><a href="#cb16-89"></a><span class="co">#       - text: |</span></span>
<span id="cb16-90"><a href="#cb16-90"></a><span class="co">#           &lt;!-- Google Tag Manager (noscript) --&gt;</span></span>
<span id="cb16-91"><a href="#cb16-91"></a><span class="co">#           &lt;noscript&gt;&lt;iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TC329HJ" height="0" width="0" style="display:none;visibility:hidden"&gt;&lt;/iframe&gt;&lt;/noscript&gt;</span></span>
<span id="cb16-92"><a href="#cb16-92"></a><span class="co">#           &lt;!-- End Google Tag Manager (noscript) --&gt;</span></span>
<span id="cb16-93"><a href="#cb16-93"></a><span class="co">#     header-includes: |</span></span>
<span id="cb16-94"><a href="#cb16-94"></a><span class="co">#       &lt;link href="https://iosevka-webfonts.github.io/iosevka/iosevka.css" rel="stylesheet"&gt;</span></span>
<span id="cb16-95"><a href="#cb16-95"></a></span>
<span id="cb16-96"><a href="#cb16-96"></a><span class="co">---</span></span>
<span id="cb16-97"><a href="#cb16-97"></a></span>
<span id="cb16-98"><a href="#cb16-98"></a><span class="fu">## 📂 Project Contents</span></span>
<span id="cb16-99"><a href="#cb16-99"></a></span>
<span id="cb16-100"><a href="#cb16-100"></a><span class="ss">- </span>🏡 <span class="co">[</span><span class="ot">Intro to {AI, HPC} for Science/</span><span class="co">](./)</span></span>
<span id="cb16-101"><a href="#cb16-101"></a></span>
<span id="cb16-102"><a href="#cb16-102"></a><span class="ss">    - </span>📂 <span class="co">[</span><span class="ot">**\[00\] Intro to AI and HPC**/</span><span class="co">](00-intro-AI-HPC/)</span></span>
<span id="cb16-103"><a href="#cb16-103"></a><span class="ss">        - </span>📄 <span class="co">[</span><span class="ot">\[0\] Compute systems</span><span class="co">](./00-intro-AI-HPC/0-compute-systems/)</span></span>
<span id="cb16-104"><a href="#cb16-104"></a><span class="ss">        - </span>📄 <span class="co">[</span><span class="ot">\[1\] Shared-resources</span><span class="co">](./00-intro-AI-HPC/1-shared-resources/)</span></span>
<span id="cb16-105"><a href="#cb16-105"></a><span class="ss">        - </span>📄 <span class="co">[</span><span class="ot">\[2\] Jupyter Notebooks</span><span class="co">](./00-intro-AI-HPC/2-jupyter-notebooks/)</span></span>
<span id="cb16-106"><a href="#cb16-106"></a><span class="ss">        - </span>📄 <span class="co">[</span><span class="ot">\[3\] Using Python</span><span class="co">](./00-intro-AI-HPC/3-python/)</span></span>
<span id="cb16-107"><a href="#cb16-107"></a><span class="ss">        - </span>📄 <span class="co">[</span><span class="ot">\[4\] Working with Data</span><span class="co">](./00-intro-AI-HPC/4-data/)</span></span>
<span id="cb16-108"><a href="#cb16-108"></a><span class="ss">        - </span>📗 <span class="co">[</span><span class="ot">\[5\] MCMC Example</span><span class="co">](./00-intro-AI-HPC/5-mcmc-example/)</span></span>
<span id="cb16-109"><a href="#cb16-109"></a><span class="ss">        - </span>📗 <span class="co">[</span><span class="ot">\[6\] Linear Regression</span><span class="co">](./00-intro-AI-HPC/6-linear-regression/)</span></span>
<span id="cb16-110"><a href="#cb16-110"></a><span class="ss">        - </span>📗 <span class="co">[</span><span class="ot">\[7\] Statistical Learning</span><span class="co">](./00-intro-AI-HPC/7-statistical-learning/)</span></span>
<span id="cb16-111"><a href="#cb16-111"></a><span class="ss">        - </span>📗 <span class="co">[</span><span class="ot">\[8\] Clustering</span><span class="co">](./00-intro-AI-HPC/8-clustering/)</span> </span>
<span id="cb16-112"><a href="#cb16-112"></a></span>
<span id="cb16-113"><a href="#cb16-113"></a><span class="ss">    - </span>📂 <span class="co">[</span><span class="ot">**\[01\] Neural Networks/**</span><span class="co">](./01-neural-networks/)</span></span>
<span id="cb16-114"><a href="#cb16-114"></a><span class="ss">        - </span>📄 <span class="co">[</span><span class="ot">\[0\] Intro</span><span class="co">](./01-neural-networks/0-intro/)</span></span>
<span id="cb16-115"><a href="#cb16-115"></a><span class="ss">        - </span>📗 <span class="co">[</span><span class="ot">\[1\] MNIST</span><span class="co">](./01-neural-networks/1-mnist/)</span></span>
<span id="cb16-116"><a href="#cb16-116"></a><span class="ss">        - </span>📗 <span class="co">[</span><span class="ot">\[1\] MNIST (ipynb)</span><span class="co">](./01-neural-networks/1-mnist-ipynb/)</span></span>
<span id="cb16-117"><a href="#cb16-117"></a><span class="ss">        - </span>📗 <span class="co">[</span><span class="ot">\[2\] Advanced</span><span class="co">](./01-neural-networks/2-advanced/)</span></span>
<span id="cb16-118"><a href="#cb16-118"></a><span class="ss">        - </span>📗 <span class="co">[</span><span class="ot">\[3\] Conv. Nets</span><span class="co">](./01-neural-networks/3-conv-nets/)</span></span>
<span id="cb16-119"><a href="#cb16-119"></a><span class="ss">        - </span>📗 <span class="co">[</span><span class="ot">\[4\] Representation Learning</span><span class="co">](./01-neural-networks/4-representation-learning/)</span></span>
<span id="cb16-120"><a href="#cb16-120"></a><span class="ss">        - </span>📄 <span class="co">[</span><span class="ot">\[5\] Distributed Training</span><span class="co">](./01-neural-networks/5-distributed-training/)</span></span>
<span id="cb16-121"><a href="#cb16-121"></a></span>
<span id="cb16-122"><a href="#cb16-122"></a><span class="ss">    - </span>📂 <span class="co">[</span><span class="ot">**\[02\] Large Language Models**</span><span class="co">](./02-llms/)</span></span>
<span id="cb16-123"><a href="#cb16-123"></a><span class="ss">        - </span>📗 <span class="co">[</span><span class="ot">\[00\] Intro to LLMs</span><span class="co">](./02-llms/00-intro-to-llms/)</span></span>
<span id="cb16-124"><a href="#cb16-124"></a><span class="ss">        - </span>📗 <span class="co">[</span><span class="ot">\[01\] Hands-on LLMs</span><span class="co">](./02-llms/01-hands-on-llms/)</span></span>
<span id="cb16-125"><a href="#cb16-125"></a><span class="ss">        - </span>📄 <span class="co">[</span><span class="ot">\[02\] Prompt Engineering</span><span class="co">](./02-llms/02-prompt-engineering/)</span></span>
<span id="cb16-126"><a href="#cb16-126"></a>        <span class="co">&lt;!-- - 📄 [03-training-llms](./02-llms/03-training-llms/) --&gt;</span></span>
<span id="cb16-127"><a href="#cb16-127"></a>        <span class="co">&lt;!-- - 📄 [04-evaluating-llms](./02-llms/03-training-llms/) --&gt;</span></span>
<span id="cb16-128"><a href="#cb16-128"></a>        <span class="co">&lt;!-- - 📄 []() --&gt;</span></span>
<span id="cb16-129"><a href="#cb16-129"></a><span class="ss">        - </span>📗 <span class="co">[</span><span class="ot">\[06\] Parallel Training</span><span class="co">](./02-llms/06-parallel-training/)</span></span>
<span id="cb16-130"><a href="#cb16-130"></a><span class="ss">        - </span>📗 <span class="co">[</span><span class="ot">\[07\] Shakespeare Example</span><span class="co">](./02-llms/07-shakespeare-example/)</span></span>
<span id="cb16-131"><a href="#cb16-131"></a><span class="ss">        - </span>📗 <span class="co">[</span><span class="ot">\[08\] Shakespeare Example (colab)</span><span class="co">](./02-llms/08-shakespeare-example-colab/)</span></span>
<span id="cb16-132"><a href="#cb16-132"></a></span>
<span id="cb16-133"><a href="#cb16-133"></a>    <span class="co">&lt;!-- - 📂 [03-ai-for-science/](./03-ai-for-science/) --&gt;</span></span>
<span id="cb16-134"><a href="#cb16-134"></a></span>
<span id="cb16-135"><a href="#cb16-135"></a><span class="dt">&lt;</span><span class="kw">details</span><span class="ot"> closed</span><span class="dt">&gt;&lt;</span><span class="kw">summary</span><span class="dt">&gt;&lt;</span><span class="kw">h2</span><span class="dt">&gt;</span> 🏔️ Instructions for Running @ NERSC<span class="dt">&lt;/</span><span class="kw">h2</span><span class="dt">&gt;&lt;/</span><span class="kw">summary</span><span class="dt">&gt;</span></span>
<span id="cb16-136"><a href="#cb16-136"></a></span>
<span id="cb16-137"><a href="#cb16-137"></a><span class="ss">1. </span>Start terminal</span>
<span id="cb16-138"><a href="#cb16-138"></a><span class="ss">1. </span>Create symlink:</span>
<span id="cb16-139"><a href="#cb16-139"></a></span>
<span id="cb16-140"><a href="#cb16-140"></a>    <span class="in">```bash</span></span>
<span id="cb16-141"><a href="#cb16-141"></a>    <span class="co"># symlink </span></span>
<span id="cb16-142"><a href="#cb16-142"></a>    <span class="fu">ln</span> <span class="at">-s</span> /global/cfs/cdirs/m4388 <span class="va">$HOME</span>/m4388</span>
<span id="cb16-143"><a href="#cb16-143"></a>    <span class="in">```</span></span>
<span id="cb16-144"><a href="#cb16-144"></a></span>
<span id="cb16-145"><a href="#cb16-145"></a><span class="ss">1. </span>Navigate to <span class="in">`m4388`</span> directory:</span>
<span id="cb16-146"><a href="#cb16-146"></a></span>
<span id="cb16-147"><a href="#cb16-147"></a>   <span class="in">```bash</span></span>
<span id="cb16-148"><a href="#cb16-148"></a>   <span class="bu">cd</span> <span class="va">$HOME</span>/m4388</span>
<span id="cb16-149"><a href="#cb16-149"></a>   <span class="in">```</span></span>
<span id="cb16-150"><a href="#cb16-150"></a></span>
<span id="cb16-151"><a href="#cb16-151"></a><span class="ss">1. </span>Clone repo (somewhere) in <span class="in">`$HOME/$USER/`</span>:</span>
<span id="cb16-152"><a href="#cb16-152"></a></span>
<span id="cb16-153"><a href="#cb16-153"></a>   <span class="in">```bash</span></span>
<span id="cb16-154"><a href="#cb16-154"></a>   <span class="fu">mkdir</span> <span class="va">$USER</span> <span class="kw">&amp;&amp;</span> <span class="bu">cd</span> <span class="va">$USER</span></span>
<span id="cb16-155"><a href="#cb16-155"></a>   <span class="fu">git</span> clone https://github.com/saforem2/intro-hpc-bootcamp-2025</span>
<span id="cb16-156"><a href="#cb16-156"></a>   <span class="in">```</span></span>
<span id="cb16-157"><a href="#cb16-157"></a></span>
<span id="cb16-158"><a href="#cb16-158"></a><span class="ss">1. </span>Find all Jupyter notebooks:</span>
<span id="cb16-159"><a href="#cb16-159"></a></span>
<span id="cb16-160"><a href="#cb16-160"></a>    <span class="in">```bash</span></span>
<span id="cb16-161"><a href="#cb16-161"></a>    <span class="co"># find all *.ipynb files</span></span>
<span id="cb16-162"><a href="#cb16-162"></a>    <span class="fu">ls</span> <span class="pp">**</span>/<span class="pp">**</span>/<span class="pp">**</span>.ipynb <span class="kw">|</span> <span class="fu">grep</span> <span class="at">-v</span> <span class="st">"cache"</span> <span class="kw">|</span> <span class="fu">sort</span> <span class="kw">|</span> <span class="fu">uniq</span></span>
<span id="cb16-163"><a href="#cb16-163"></a>    <span class="in">```</span></span>
<span id="cb16-164"><a href="#cb16-164"></a></span>
<span id="cb16-165"><a href="#cb16-165"></a></span>
<span id="cb16-166"><a href="#cb16-166"></a><span class="dt">&lt;/</span><span class="kw">details</span><span class="dt">&gt;</span></span>
<span id="cb16-167"><a href="#cb16-167"></a></span>
<span id="cb16-168"><a href="#cb16-168"></a><span class="fu">## 🌐 Distributed Training Example</span></span>
<span id="cb16-169"><a href="#cb16-169"></a></span>
<span id="cb16-170"><a href="#cb16-170"></a><span class="ss">1. </span>Login to Perlmutter:</span>
<span id="cb16-171"><a href="#cb16-171"></a></span>
<span id="cb16-172"><a href="#cb16-172"></a>    <span class="in">```bash</span></span>
<span id="cb16-173"><a href="#cb16-173"></a>    <span class="fu">ssh</span> <span class="op">&lt;</span>user<span class="op">&gt;</span>@perlmutter.nersc.gov </span>
<span id="cb16-174"><a href="#cb16-174"></a>    <span class="bu">[</span> <span class="ot">-d</span> <span class="va">$HOME</span>/m4388 <span class="bu">]</span> <span class="kw">||</span> <span class="fu">ln</span> <span class="at">-s</span> /global/cfs/cdirs/m4388 <span class="va">$HOME</span>/m4388</span>
<span id="cb16-175"><a href="#cb16-175"></a>    <span class="kw">```</span></span>
<span id="cb16-176"><a href="#cb16-176"></a></span>
<span id="cb16-177"><a href="#cb16-177"></a><span class="ex">1.</span> Request an interactive job:</span>
<span id="cb16-178"><a href="#cb16-178"></a></span>
<span id="cb16-179"><a href="#cb16-179"></a>    <span class="kw">```</span>bash</span>
<span id="cb16-180"><a href="#cb16-180"></a>    <span class="va">NODES</span><span class="op">=</span>2 <span class="kw">;</span> <span class="va">HRS</span><span class="op">=</span>02 <span class="kw">;</span> <span class="va">QUEUE</span><span class="op">=</span>interactive <span class="kw">;</span> <span class="ex">salloc</span> <span class="at">--nodes</span> <span class="va">$NODES</span> <span class="at">--qos</span> <span class="va">$QUEUE</span> <span class="at">--time</span> <span class="va">$HRS</span>:30:00 <span class="at">-C</span> <span class="st">'gpu'</span> <span class="at">--gpus</span><span class="op">=</span><span class="va">$((</span> <span class="dv">4</span> <span class="op">*</span> <span class="va">NODES</span> <span class="va">))</span> <span class="at">-A</span> m4388_g</span>
<span id="cb16-181"><a href="#cb16-181"></a>    <span class="kw">```</span></span>
<span id="cb16-182"><a href="#cb16-182"></a></span>
<span id="cb16-183"><a href="#cb16-183"></a><span class="ex">1.</span> Clone <span class="pp">[</span><span class="ss">wordplay</span><span class="pp">]</span><span class="er">(</span><span class="ex">https://github.com/saforem2/wordplay</span><span class="kw">)</span> <span class="ex">and</span> navigate into it:</span>
<span id="cb16-184"><a href="#cb16-184"></a></span>
<span id="cb16-185"><a href="#cb16-185"></a>    <span class="kw">```</span>bash</span>
<span id="cb16-186"><a href="#cb16-186"></a>    <span class="fu">mkdir</span> <span class="at">-p</span> <span class="st">"</span><span class="va">${HOME}</span><span class="st">/m4388/Project5/</span><span class="va">${USER}</span><span class="st">"</span></span>
<span id="cb16-187"><a href="#cb16-187"></a>    <span class="bu">cd</span> <span class="st">"</span><span class="va">${HOME}</span><span class="st">/m4388/Project5/</span><span class="va">${USER}</span><span class="st">"</span></span>
<span id="cb16-188"><a href="#cb16-188"></a>    <span class="fu">git</span> clone https://github.com/saforem2/wordplay <span class="kw">&amp;&amp;</span> <span class="bu">cd</span> wordplay</span>
<span id="cb16-189"><a href="#cb16-189"></a>    <span class="kw">```</span> </span>
<span id="cb16-190"><a href="#cb16-190"></a></span>
<span id="cb16-191"><a href="#cb16-191"></a><span class="ex">1.</span> Setup Python:</span>
<span id="cb16-192"><a href="#cb16-192"></a></span>
<span id="cb16-193"><a href="#cb16-193"></a>    <span class="kw">```</span>bash</span>
<span id="cb16-194"><a href="#cb16-194"></a>    <span class="bu">source</span> <span class="op">&lt;(</span><span class="ex">curl</span> <span class="at">-L</span> https://bit.ly/ezpz-utils<span class="op">)</span></span>
<span id="cb16-195"><a href="#cb16-195"></a>    <span class="ex">ezpz_setup_python</span></span>
<span id="cb16-196"><a href="#cb16-196"></a>    <span class="kw">```</span></span>
<span id="cb16-197"><a href="#cb16-197"></a></span>
<span id="cb16-198"><a href="#cb16-198"></a><span class="ex">1.</span> Setup <span class="pp">[</span><span class="ss">wandb</span><span class="pp">]</span><span class="er">(</span><span class="ex">https://wandb.ai</span><span class="kw">)</span><span class="bu">:</span></span>
<span id="cb16-199"><a href="#cb16-199"></a></span>
<span id="cb16-200"><a href="#cb16-200"></a>    <span class="kw">```</span>bash</span>
<span id="cb16-201"><a href="#cb16-201"></a>    <span class="ex">wandb</span> login</span>
<span id="cb16-202"><a href="#cb16-202"></a>    <span class="kw">```</span></span>
<span id="cb16-203"><a href="#cb16-203"></a></span>
<span id="cb16-204"><a href="#cb16-204"></a><span class="ex">1.</span> Install <span class="pp">[</span><span class="ss">`wordplay`</span><span class="pp">]</span><span class="er">(</span><span class="ex">https://github.com/saforem2/wordplay</span><span class="kw">)</span><span class="bu">:</span></span>
<span id="cb16-205"><a href="#cb16-205"></a></span>
<span id="cb16-206"><a href="#cb16-206"></a>    <span class="kw">```</span>bash</span>
<span id="cb16-207"><a href="#cb16-207"></a>    <span class="ex">python3</span> <span class="at">-m</span> pip install <span class="at">-e</span> <span class="st">"."</span></span>
<span id="cb16-208"><a href="#cb16-208"></a>    <span class="kw">```</span></span>
<span id="cb16-209"><a href="#cb16-209"></a></span>
<span id="cb16-210"><a href="#cb16-210"></a><span class="ex">1.</span> Run <span class="kw">`</span>ezpz-test<span class="kw">`</span> <span class="kw">(</span><span class="ex">simple</span> test to verify distributed functionality<span class="kw">)</span><span class="bu">:</span></span>
<span id="cb16-211"><a href="#cb16-211"></a></span>
<span id="cb16-212"><a href="#cb16-212"></a>    <span class="kw">```</span>bash</span>
<span id="cb16-213"><a href="#cb16-213"></a>    <span class="ex">ezpz-test</span>  <span class="co"># &lt;- SHOULD WORK (🤞)</span></span>
<span id="cb16-214"><a href="#cb16-214"></a>    <span class="kw">```</span></span>
<span id="cb16-215"><a href="#cb16-215"></a></span>
<span id="cb16-216"><a href="#cb16-216"></a><span class="ex">1.</span> Prepare data:</span>
<span id="cb16-217"><a href="#cb16-217"></a></span>
<span id="cb16-218"><a href="#cb16-218"></a>    <span class="kw">```</span>bash</span>
<span id="cb16-219"><a href="#cb16-219"></a>    <span class="ex">python3</span> <span class="at">-m</span> wordplay.prepare</span>
<span id="cb16-220"><a href="#cb16-220"></a>    <span class="kw">```</span></span>
<span id="cb16-221"><a href="#cb16-221"></a></span>
<span id="cb16-222"><a href="#cb16-222"></a><span class="ex">1.</span> Run distributed training:</span>
<span id="cb16-223"><a href="#cb16-223"></a></span>
<span id="cb16-224"><a href="#cb16-224"></a>    <span class="kw">```</span>bash</span>
<span id="cb16-225"><a href="#cb16-225"></a>      <span class="ex">ezpz-launch</span> <span class="at">-m</span> wordplay <span class="dt">\</span></span>
<span id="cb16-226"><a href="#cb16-226"></a>        train.backend=DDP <span class="dt">\</span></span>
<span id="cb16-227"><a href="#cb16-227"></a>        train.eval_interval=100 <span class="dt">\</span></span>
<span id="cb16-228"><a href="#cb16-228"></a>        data=shakespeare <span class="dt">\</span></span>
<span id="cb16-229"><a href="#cb16-229"></a>        train.dtype=bf16 <span class="dt">\</span></span>
<span id="cb16-230"><a href="#cb16-230"></a>        model.batch_size=8 <span class="dt">\</span></span>
<span id="cb16-231"><a href="#cb16-231"></a>        model.block_size=2048 <span class="dt">\</span></span>
<span id="cb16-232"><a href="#cb16-232"></a>        train.max_iters=1000 <span class="dt">\</span></span>
<span id="cb16-233"><a href="#cb16-233"></a>        train.log_interval=10 <span class="dt">\</span></span>
<span id="cb16-234"><a href="#cb16-234"></a>        train.compile=true</span>
<span id="cb16-235"><a href="#cb16-235"></a>    <span class="kw">```</span></span>
<span id="cb16-236"><a href="#cb16-236"></a></span>
<span id="cb16-237"><a href="#cb16-237"></a>    <span class="ex">-</span> <span class="op">&lt;</span>details closed<span class="op">&gt;&lt;</span>summary<span class="op">&gt;</span>Output<span class="op">&lt;</span>/summary<span class="op">&gt;</span></span>
<span id="cb16-238"><a href="#cb16-238"></a></span>
<span id="cb16-239"><a href="#cb16-239"></a>        <span class="kw">```</span>bash</span>
<span id="cb16-240"><a href="#cb16-240"></a>        <span class="kw">(</span><span class="ex">👻</span> pytorch2.6.0<span class="kw">)</span></span>
<span id="cb16-241"><a href="#cb16-241"></a>        <span class="co">#[~/m/P/f/p/s/wordplay][🌱 main][🤷✓] via ⨁ v</span></span>
<span id="cb16-242"><a href="#cb16-242"></a>        <span class="co">#[08/14/25 @ 05:52:20][nid001237]</span></span>
<span id="cb16-243"><a href="#cb16-243"></a>        <span class="kw">;</span> <span class="ex">eezpz-launch-m</span> wordplay train.backend=DDP train.eval_interval=100 data=shakespeare train.dtype=bf16 model.batch_size=8 model.block_size=2048 train.max_iters=1000 train.log_interval=10 train.compile=true</span>
<span id="cb16-244"><a href="#cb16-244"></a>        <span class="ex">[2025-08-14</span> 05:53:17,261718]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/__init__:265:ezpz</span><span class="pp">]</span> Setting logging level to <span class="st">'INFO'</span> on <span class="st">'RANK == 0'</span></span>
<span id="cb16-245"><a href="#cb16-245"></a>        <span class="ex">[2025-08-14</span> 05:53:17,264886]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/__init__:266:ezpz</span><span class="pp">]</span> Setting logging level to <span class="st">'CRITICAL'</span> on all others <span class="st">'RANK != 0'</span></span>
<span id="cb16-246"><a href="#cb16-246"></a></span>
<span id="cb16-247"><a href="#cb16-247"></a></span>
<span id="cb16-248"><a href="#cb16-248"></a>        <span class="ex">[2025-08-14</span> 05:53:17,283662]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/launch:225</span><span class="pp">]</span> ======== [ezpz.launch: START] ========</span>
<span id="cb16-249"><a href="#cb16-249"></a>        <span class="ex">[2025-08-14</span> 05:53:17,508744]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/slurm:90</span><span class="pp">]</span> Checking jobid 41622690 for hostname nid001237...</span>
<span id="cb16-250"><a href="#cb16-250"></a>        <span class="ex">[2025-08-14</span> 05:53:17,509756]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/slurm:92</span><span class="pp">]</span> Found nid001237 in nodelist for 41622690</span>
<span id="cb16-251"><a href="#cb16-251"></a>        <span class="ex">[2025-08-14</span> 05:53:17,713837]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/slurm:90</span><span class="pp">]</span> Checking jobid 41622690 for hostname nid001237...</span>
<span id="cb16-252"><a href="#cb16-252"></a>        <span class="ex">[2025-08-14</span> 05:53:17,714591]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/slurm:92</span><span class="pp">]</span> Found nid001237 in nodelist for 41622690</span>
<span id="cb16-253"><a href="#cb16-253"></a>        <span class="ex">[2025-08-14</span> 05:53:17,977002]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/slurm:90</span><span class="pp">]</span> Checking jobid 41622690 for hostname nid001237...</span>
<span id="cb16-254"><a href="#cb16-254"></a>        <span class="ex">[2025-08-14</span> 05:53:17,977846]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/slurm:92</span><span class="pp">]</span> Found nid001237 in nodelist for 41622690</span>
<span id="cb16-255"><a href="#cb16-255"></a>        <span class="ex">[2025-08-14</span> 05:53:18,057066]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/slurm:109</span><span class="pp">]</span> Writing [<span class="st">'nid001237'</span>, <span class="st">'001240'</span>] to /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/wordplay/nodefile-41622690</span>
<span id="cb16-256"><a href="#cb16-256"></a>        <span class="ex">[2025-08-14</span> 05:53:18,089205]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/launch:230</span><span class="pp">]</span> Job ID: 41622690</span>
<span id="cb16-257"><a href="#cb16-257"></a>        <span class="ex">[2025-08-14</span> 05:53:18,089621]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/launch:231</span><span class="pp">]</span> nodelist: [<span class="st">'nid001237'</span>, <span class="st">'001240'</span>]</span>
<span id="cb16-258"><a href="#cb16-258"></a>        <span class="ex">[2025-08-14</span> 05:53:18,090032]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/launch:232</span><span class="pp">]</span> hostfile: /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/wordplay/nodefile-41622690</span>
<span id="cb16-259"><a href="#cb16-259"></a>        <span class="ex">[2025-08-14</span> 05:53:18,241020]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/slurm:90</span><span class="pp">]</span> Checking jobid 41622690 for hostname nid001237...</span>
<span id="cb16-260"><a href="#cb16-260"></a>        <span class="ex">[2025-08-14</span> 05:53:18,241792]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/slurm:92</span><span class="pp">]</span> Found nid001237 in nodelist for 41622690</span>
<span id="cb16-261"><a href="#cb16-261"></a>        <span class="ex">[2025-08-14</span> 05:53:18,328647]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/launch:253</span><span class="pp">]</span> Building command to execute by piecing together:</span>
<span id="cb16-262"><a href="#cb16-262"></a></span>
<span id="cb16-263"><a href="#cb16-263"></a>                <span class="kw">(</span><span class="ex">1.</span><span class="kw">)</span> <span class="ex">[</span><span class="st">'launch_cmd'</span><span class="ex">]</span> + <span class="er">(</span><span class="ex">2.</span><span class="kw">)</span> <span class="ex">[</span><span class="st">'python'</span><span class="ex">]</span> + <span class="er">(</span><span class="ex">3.</span><span class="kw">)</span> <span class="ex">[</span><span class="st">'cmd_to_launch'</span><span class="ex">]</span></span>
<span id="cb16-264"><a href="#cb16-264"></a></span>
<span id="cb16-265"><a href="#cb16-265"></a>        <span class="ex">[2025-08-14</span> 05:53:18,330096]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/launch:257</span><span class="pp">]</span> <span class="er">(</span><span class="ex">1.</span><span class="kw">)</span> <span class="ex">[</span><span class="st">'launch_cmd'</span><span class="ex">]:</span> srun <span class="at">-u</span> <span class="at">--verbose</span> <span class="at">-N2</span> <span class="at">-n8</span></span>
<span id="cb16-266"><a href="#cb16-266"></a>        <span class="ex">[2025-08-14</span> 05:53:18,330544]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/launch:258</span><span class="pp">]</span> <span class="er">(</span><span class="ex">2.</span><span class="kw">)</span> <span class="ex">[</span><span class="st">'python'</span><span class="ex">]:</span> /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/wordplay/venvs/perlmutter/pytorch2.6.0/bin/python3</span>
<span id="cb16-267"><a href="#cb16-267"></a>        <span class="ex">[2025-08-14</span> 05:53:18,330996]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/launch:259</span><span class="pp">]</span> <span class="er">(</span><span class="ex">3.</span><span class="kw">)</span> <span class="ex">[</span><span class="st">'cmd_to_launch'</span><span class="ex">]:</span>  <span class="at">-m</span> wordplay train.backend=DDP train.eval_interval=100 data=shakespeare train.dtype=bf16 model.batch_size=8 model.block_size=2048 train.max_iters=1000 train.log_interval=10 train.compile=true</span>
<span id="cb16-268"><a href="#cb16-268"></a>        <span class="ex">[2025-08-14</span> 05:53:18,331986]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/launch:264</span><span class="pp">]</span> Took: 1.05 seconds to build command.</span>
<span id="cb16-269"><a href="#cb16-269"></a>        <span class="ex">[2025-08-14</span> 05:53:18,332539]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/launch:268</span><span class="pp">]</span> Executing:</span>
<span id="cb16-270"><a href="#cb16-270"></a>                <span class="ex">srun</span></span>
<span id="cb16-271"><a href="#cb16-271"></a>                <span class="ex">-u</span></span>
<span id="cb16-272"><a href="#cb16-272"></a>                <span class="ex">--verbose</span></span>
<span id="cb16-273"><a href="#cb16-273"></a>                <span class="ex">-N2</span></span>
<span id="cb16-274"><a href="#cb16-274"></a>                <span class="ex">-n8</span></span>
<span id="cb16-275"><a href="#cb16-275"></a>                <span class="ex">/global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/wordplay/venvs/perlmutter/pytorch2.6.0/bin/python3</span></span>
<span id="cb16-276"><a href="#cb16-276"></a>                <span class="ex">-m</span></span>
<span id="cb16-277"><a href="#cb16-277"></a>                <span class="ex">wordplay</span></span>
<span id="cb16-278"><a href="#cb16-278"></a>                <span class="ex">train.backend=DDP</span></span>
<span id="cb16-279"><a href="#cb16-279"></a>                <span class="ex">train.eval_interval=100</span></span>
<span id="cb16-280"><a href="#cb16-280"></a>                <span class="va">data</span><span class="op">=</span>shakespeare</span>
<span id="cb16-281"><a href="#cb16-281"></a>                <span class="ex">train.dtype=bf16</span></span>
<span id="cb16-282"><a href="#cb16-282"></a>                <span class="ex">model.batch_size=8</span></span>
<span id="cb16-283"><a href="#cb16-283"></a>                <span class="ex">model.block_size=2048</span></span>
<span id="cb16-284"><a href="#cb16-284"></a>                <span class="ex">train.max_iters=1000</span></span>
<span id="cb16-285"><a href="#cb16-285"></a>                <span class="ex">train.log_interval=10</span></span>
<span id="cb16-286"><a href="#cb16-286"></a>                <span class="ex">train.compile=true</span></span>
<span id="cb16-287"><a href="#cb16-287"></a>        <span class="ex">[2025-08-14</span> 05:53:18,334155]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/launch:276</span><span class="pp">]</span> Execution started @ 2025-08-14-055318...</span>
<span id="cb16-288"><a href="#cb16-288"></a>        <span class="ex">[2025-08-14</span> 05:53:18,334619]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/launch:277</span><span class="pp">]</span> ======== [ezpz.launch: STOP] ========</span>
<span id="cb16-289"><a href="#cb16-289"></a></span>
<span id="cb16-290"><a href="#cb16-290"></a>        <span class="ex">srun:</span> defined options</span>
<span id="cb16-291"><a href="#cb16-291"></a>        <span class="ex">srun:</span> <span class="at">--------------------</span> <span class="at">--------------------</span></span>
<span id="cb16-292"><a href="#cb16-292"></a>        <span class="ex">srun:</span> <span class="er">(</span><span class="ex">null</span><span class="kw">)</span>              <span class="bu">:</span> nid<span class="pp">[</span><span class="ss">001237,001240</span><span class="pp">]</span></span>
<span id="cb16-293"><a href="#cb16-293"></a>        <span class="ex">srun:</span> gpus                : 8</span>
<span id="cb16-294"><a href="#cb16-294"></a>        <span class="ex">srun:</span> jobid               : 41622690</span>
<span id="cb16-295"><a href="#cb16-295"></a>        <span class="ex">srun:</span> job-name            : interactive</span>
<span id="cb16-296"><a href="#cb16-296"></a>        <span class="ex">srun:</span> mpi                 : cray_shasta</span>
<span id="cb16-297"><a href="#cb16-297"></a>        <span class="ex">srun:</span> nodes               : 2</span>
<span id="cb16-298"><a href="#cb16-298"></a>        <span class="ex">srun:</span> ntasks              : 8</span>
<span id="cb16-299"><a href="#cb16-299"></a>        <span class="ex">srun:</span> oom-kill-step       : 0</span>
<span id="cb16-300"><a href="#cb16-300"></a>        <span class="ex">srun:</span> slurmd-debug        : error</span>
<span id="cb16-301"><a href="#cb16-301"></a>        <span class="ex">srun:</span> unbuffered          : set</span>
<span id="cb16-302"><a href="#cb16-302"></a>        <span class="ex">srun:</span> verbose             : 1</span>
<span id="cb16-303"><a href="#cb16-303"></a>        <span class="ex">srun:</span> <span class="at">--------------------</span> <span class="at">--------------------</span></span>
<span id="cb16-304"><a href="#cb16-304"></a>        <span class="ex">srun:</span> end of defined options</span>
<span id="cb16-305"><a href="#cb16-305"></a>        <span class="ex">srun:</span> jobid 41622690: nodes<span class="er">(</span><span class="ex">2</span><span class="kw">)</span><span class="ex">:</span><span class="st">'nid[001237,001240]'</span><span class="ex">,</span> cpu counts: 128<span class="er">(</span><span class="ex">x2</span><span class="kw">)</span></span>
<span id="cb16-306"><a href="#cb16-306"></a>        <span class="ex">srun:</span> CpuBindType=<span class="er">(</span><span class="ex">null</span> type<span class="kw">)</span></span>
<span id="cb16-307"><a href="#cb16-307"></a>        <span class="ex">srun:</span> launching StepId=41622690.1 on host nid001237, 4 tasks: <span class="pp">[</span><span class="ss">0</span><span class="pp">-</span><span class="ss">3</span><span class="pp">]</span></span>
<span id="cb16-308"><a href="#cb16-308"></a>        <span class="ex">srun:</span> launching StepId=41622690.1 on host nid001240, 4 tasks: <span class="pp">[</span><span class="ss">4</span><span class="pp">-</span><span class="ss">7</span><span class="pp">]</span></span>
<span id="cb16-309"><a href="#cb16-309"></a>        <span class="ex">srun:</span> topology/default: init: topology Default plugin loaded</span>
<span id="cb16-310"><a href="#cb16-310"></a>        <span class="ex">srun:</span> Node nid001237, 4 tasks started</span>
<span id="cb16-311"><a href="#cb16-311"></a>        <span class="ex">srun:</span> Node nid001240, 4 tasks started</span>
<span id="cb16-312"><a href="#cb16-312"></a>        <span class="ex">[2025-08-14</span> 05:54:16,894992]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/__init__:265:ezpz</span><span class="pp">]</span> Setting logging level to <span class="st">'INFO'</span> on <span class="st">'RANK == 0'</span></span>
<span id="cb16-313"><a href="#cb16-313"></a>        <span class="ex">[2025-08-14</span> 05:54:16,897554]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/__init__:266:ezpz</span><span class="pp">]</span> Setting logging level to <span class="st">'CRITICAL'</span> on all others <span class="st">'RANK != 0'</span></span>
<span id="cb16-314"><a href="#cb16-314"></a>        <span class="ex">[2025-08-14</span> 05:54:17,040731]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/configs:81</span><span class="pp">]</span> Setting HF_DATASETS_CACHE to /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/wordplay/.cache/huggingface/datasets</span>
<span id="cb16-315"><a href="#cb16-315"></a>        <span class="ex">[2025-08-14</span> 05:54:18,062573]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1159</span><span class="pp">]</span> Using fw=<span class="st">'ddp'</span> with torch_<span class="dt">{device</span><span class="op">,</span><span class="dt">backend}</span>= {cuda, nccl}</span>
<span id="cb16-316"><a href="#cb16-316"></a>        <span class="ex">[2025-08-14</span> 05:54:18,063295]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1026</span><span class="pp">]</span> Caught MASTER_PORT=56513 from environment!</span>
<span id="cb16-317"><a href="#cb16-317"></a>        <span class="ex">[2025-08-14</span> 05:54:18,372603]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1042</span><span class="pp">]</span> Using torch.distributed.init_process_group with</span>
<span id="cb16-318"><a href="#cb16-318"></a>        <span class="ex">-</span> master_addr=<span class="st">'nid001237'</span></span>
<span id="cb16-319"><a href="#cb16-319"></a>        <span class="ex">-</span> master_port=<span class="st">'56513'</span></span>
<span id="cb16-320"><a href="#cb16-320"></a>        <span class="ex">-</span> world_size=8</span>
<span id="cb16-321"><a href="#cb16-321"></a>        <span class="ex">-</span> rank=0</span>
<span id="cb16-322"><a href="#cb16-322"></a>        <span class="ex">-</span> local_rank=0</span>
<span id="cb16-323"><a href="#cb16-323"></a>        <span class="ex">-</span> timeout=datetime.timedelta<span class="er">(</span><span class="va">seconds</span><span class="op">=</span>3600<span class="kw">)</span></span>
<span id="cb16-324"><a href="#cb16-324"></a>        <span class="ex">-</span> backend=<span class="st">'nccl'</span></span>
<span id="cb16-325"><a href="#cb16-325"></a>        <span class="ex">[2025-08-14</span> 05:54:18,373741]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:759</span><span class="pp">]</span> Calling torch.distributed.init_process_group_with: rank=0 world_size=8 backend=nccl</span>
<span id="cb16-326"><a href="#cb16-326"></a>        <span class="ex">[rank6]:[W814</span> 05:54:18.650817367 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 6]  using GPU 2 to perform barrier as devices usedby this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier<span class="er">(</span><span class="kw">)</span> <span class="ex">to</span> force use of a particular device, or call init_process_group<span class="er">(</span><span class="kw">)</span> <span class="ex">with</span> a device_id.</span>
<span id="cb16-327"><a href="#cb16-327"></a>        <span class="ex">[rank4]:[W814</span> 05:54:18.001713707 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 4]  using GPU 0 to perform barrier as devices usedby this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier<span class="er">(</span><span class="kw">)</span> <span class="ex">to</span> force use of a particular device, or call init_process_group<span class="er">(</span><span class="kw">)</span> <span class="ex">with</span> a device_id.</span>
<span id="cb16-328"><a href="#cb16-328"></a>        <span class="ex">[rank0]:[W814</span> 05:54:19.906551058 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices usedby this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier<span class="er">(</span><span class="kw">)</span> <span class="ex">to</span> force use of a particular device, or call init_process_group<span class="er">(</span><span class="kw">)</span> <span class="ex">with</span> a device_id.</span>
<span id="cb16-329"><a href="#cb16-329"></a>        <span class="ex">[rank5]:[W814</span> 05:54:19.231412634 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 5]  using GPU 1 to perform barrier as devices usedby this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier<span class="er">(</span><span class="kw">)</span> <span class="ex">to</span> force use of a particular device, or call init_process_group<span class="er">(</span><span class="kw">)</span> <span class="ex">with</span> a device_id.</span>
<span id="cb16-330"><a href="#cb16-330"></a>        <span class="ex">[rank7]:[W814</span> 05:54:19.394309045 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 7]  using GPU 3 to perform barrier as devices usedby this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier<span class="er">(</span><span class="kw">)</span> <span class="ex">to</span> force use of a particular device, or call init_process_group<span class="er">(</span><span class="kw">)</span> <span class="ex">with</span> a device_id.</span>
<span id="cb16-331"><a href="#cb16-331"></a>        <span class="ex">[rank3]:[W814</span> 05:54:19.232206867 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices usedby this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier<span class="er">(</span><span class="kw">)</span> <span class="ex">to</span> force use of a particular device, or call init_process_group<span class="er">(</span><span class="kw">)</span> <span class="ex">with</span> a device_id.</span>
<span id="cb16-332"><a href="#cb16-332"></a>        <span class="ex">[rank1]:[W814</span> 05:54:19.258096849 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices usedby this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier<span class="er">(</span><span class="kw">)</span> <span class="ex">to</span> force use of a particular device, or call init_process_group<span class="er">(</span><span class="kw">)</span> <span class="ex">with</span> a device_id.</span>
<span id="cb16-333"><a href="#cb16-333"></a>        <span class="ex">[rank2]:[W814</span> 05:54:19.258138279 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices usedby this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier<span class="er">(</span><span class="kw">)</span> <span class="ex">to</span> force use of a particular device, or call init_process_group<span class="er">(</span><span class="kw">)</span> <span class="ex">with</span> a device_id.</span>
<span id="cb16-334"><a href="#cb16-334"></a>        <span class="ex">[2025-08-14</span> 05:54:20,179821]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1377</span><span class="pp">]</span> Using device=<span class="st">'cuda'</span> with backend=<span class="st">'nccl'</span> + <span class="st">'nccl'</span> for distributed training.</span>
<span id="cb16-335"><a href="#cb16-335"></a>        <span class="ex">[2025-08-14</span> 05:54:20,181272]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1422</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'nid001237'</span><span class="pp">][</span><span class="ss">0/7</span><span class="pp">]</span></span>
<span id="cb16-336"><a href="#cb16-336"></a>        <span class="ex">[2025-08-14</span> 05:54:20,179635]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1422</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'nid001237'</span><span class="pp">][</span><span class="ss">1/7</span><span class="pp">]</span></span>
<span id="cb16-337"><a href="#cb16-337"></a>        <span class="ex">[2025-08-14</span> 05:54:20,179688]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1422</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'nid001240'</span><span class="pp">][</span><span class="ss">6/7</span><span class="pp">]</span></span>
<span id="cb16-338"><a href="#cb16-338"></a>        <span class="ex">[2025-08-14</span> 05:54:20,179683]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1422</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'nid001240'</span><span class="pp">][</span><span class="ss">7/7</span><span class="pp">]</span></span>
<span id="cb16-339"><a href="#cb16-339"></a>        <span class="ex">[2025-08-14</span> 05:54:20,179727]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1422</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'nid001237'</span><span class="pp">][</span><span class="ss">2/7</span><span class="pp">]</span></span>
<span id="cb16-340"><a href="#cb16-340"></a>        <span class="ex">[2025-08-14</span> 05:54:20,179700]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1422</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'nid001237'</span><span class="pp">][</span><span class="ss">3/7</span><span class="pp">]</span></span>
<span id="cb16-341"><a href="#cb16-341"></a>        <span class="ex">[2025-08-14</span> 05:54:20,179702]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1422</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'nid001240'</span><span class="pp">][</span><span class="ss">4/7</span><span class="pp">]</span></span>
<span id="cb16-342"><a href="#cb16-342"></a>        <span class="ex">[2025-08-14</span> 05:54:20,179691]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1422</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'nid001240'</span><span class="pp">][</span><span class="ss">5/7</span><span class="pp">]</span></span>
<span id="cb16-343"><a href="#cb16-343"></a>        <span class="ex">[2025-08-14</span> 05:54:20,213261]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/configs:317</span><span class="pp">]</span> Loading val from /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/wordplay/data/shakespeare_char/val.bin</span>
<span id="cb16-344"><a href="#cb16-344"></a>        <span class="ex">[2025-08-14</span> 05:54:20,215366]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/configs:317</span><span class="pp">]</span> Loading train from /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/wordplay/data/shakespeare_char/train.bin</span>
<span id="cb16-345"><a href="#cb16-345"></a>        <span class="ex">[2025-08-14</span> 05:54:20,221097]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/configs:442</span><span class="pp">]</span> Tokens per iteration: 131,072</span>
<span id="cb16-346"><a href="#cb16-346"></a>        <span class="ex">[2025-08-14</span> 05:54:20,221681]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/configs:465</span><span class="pp">]</span> Using self.ptdtype=torch.float16 on self.device_type=<span class="st">'cuda'</span></span>
<span id="cb16-347"><a href="#cb16-347"></a>        <span class="ex">[2025-08-14</span> 05:54:20,222155]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/configs:471</span><span class="pp">]</span> Initializing a new model from scratch</span>
<span id="cb16-348"><a href="#cb16-348"></a>        <span class="ex">[2025-08-14</span> 05:54:20,223622]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1648</span><span class="pp">]</span> Setting up wandb from rank=0</span>
<span id="cb16-349"><a href="#cb16-349"></a>        <span class="ex">[2025-08-14</span> 05:54:20,224043]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1649</span><span class="pp">]</span> Using WB_PROJECT=WordPlay</span>
<span id="cb16-350"><a href="#cb16-350"></a>        <span class="ex">wandb:</span> Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.</span>
<span id="cb16-351"><a href="#cb16-351"></a>        <span class="ex">wandb:</span> Currently logged in as: foremans <span class="er">(</span><span class="ex">aurora_gpt</span><span class="kw">)</span> <span class="ex">to</span> https://api.wandb.ai. Use <span class="kw">`</span><span class="ex">wandb</span> login <span class="at">--relogin</span><span class="kw">`</span> to force relogin</span>
<span id="cb16-352"><a href="#cb16-352"></a>        <span class="ex">wandb:</span> Tracking run with wandb version 0.19.7</span>
<span id="cb16-353"><a href="#cb16-353"></a>        <span class="ex">wandb:</span> Run data is saved locally in /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/outputs/runs/pytorch/DDP/2025-08-14/05-54-17/wandb/run-20250814_055421-qqpij4mt</span>
<span id="cb16-354"><a href="#cb16-354"></a>        <span class="ex">wandb:</span> Run <span class="kw">`</span><span class="ex">wandb</span> offline<span class="kw">`</span> to turn off syncing.</span>
<span id="cb16-355"><a href="#cb16-355"></a>        <span class="ex">wandb:</span> Syncing run helpful-sea-138</span>
<span id="cb16-356"><a href="#cb16-356"></a>        <span class="ex">wandb:</span> ⭐️ View project at https://wandb.ai/aurora_gpt/WordPlay</span>
<span id="cb16-357"><a href="#cb16-357"></a>        <span class="ex">wandb:</span> 🚀 View run at https://wandb.ai/aurora_gpt/WordPlay/runs/qqpij4mt</span>
<span id="cb16-358"><a href="#cb16-358"></a>        <span class="ex">[2025-08-14</span> 05:54:22,857365]<span class="pp">[</span><span class="ss">C</span><span class="pp">][</span><span class="ss">wordplay/trainer:322</span><span class="pp">]</span> RANK=1:devid=<span class="st">'cuda:1'</span></span>
<span id="cb16-359"><a href="#cb16-359"></a>        <span class="ex">[2025-08-14</span> 05:54:22,858391]<span class="pp">[</span><span class="ss">C</span><span class="pp">][</span><span class="ss">wordplay/trainer:322</span><span class="pp">]</span> RANK=3:devid=<span class="st">'cuda:3'</span></span>
<span id="cb16-360"><a href="#cb16-360"></a>        <span class="ex">[2025-08-14</span> 05:54:22,859157]<span class="pp">[</span><span class="ss">C</span><span class="pp">][</span><span class="ss">wordplay/trainer:322</span><span class="pp">]</span> RANK=2:devid=<span class="st">'cuda:2'</span></span>
<span id="cb16-361"><a href="#cb16-361"></a>        <span class="ex">[2025-08-14</span> 05:54:22,925017]<span class="pp">[</span><span class="ss">C</span><span class="pp">][</span><span class="ss">wordplay/trainer:322</span><span class="pp">]</span> RANK=7:devid=<span class="st">'cuda:3'</span></span>
<span id="cb16-362"><a href="#cb16-362"></a>        <span class="ex">[2025-08-14</span> 05:54:22,925164]<span class="pp">[</span><span class="ss">C</span><span class="pp">][</span><span class="ss">wordplay/trainer:322</span><span class="pp">]</span> RANK=6:devid=<span class="st">'cuda:2'</span></span>
<span id="cb16-363"><a href="#cb16-363"></a>        <span class="ex">[2025-08-14</span> 05:54:22,931160]<span class="pp">[</span><span class="ss">C</span><span class="pp">][</span><span class="ss">wordplay/trainer:322</span><span class="pp">]</span> RANK=4:devid=<span class="st">'cuda:0'</span></span>
<span id="cb16-364"><a href="#cb16-364"></a>        <span class="ex">[2025-08-14</span> 05:54:23,025155]<span class="pp">[</span><span class="ss">C</span><span class="pp">][</span><span class="ss">wordplay/trainer:322</span><span class="pp">]</span> RANK=5:devid=<span class="st">'cuda:1'</span></span>
<span id="cb16-365"><a href="#cb16-365"></a>        <span class="ex">[2025-08-14</span> 05:54:23,585980]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1678</span><span class="pp">]</span> wandb.run=<span class="pp">[</span><span class="ss">helpful</span><span class="pp">-</span><span class="ss">sea</span><span class="pp">-</span><span class="ss">138</span><span class="pp">]</span><span class="er">(</span><span class="ex">https://wandb.ai/aurora_gpt/WordPlay/runs/qqpij4mt</span><span class="kw">)</span></span>
<span id="cb16-366"><a href="#cb16-366"></a>        <span class="ex">[2025-08-14</span> 05:54:23,693859]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">ezpz/dist:1722</span><span class="pp">]</span> Running on machine=<span class="st">'Perlmutter'</span></span>
<span id="cb16-367"><a href="#cb16-367"></a>        <span class="ex">[2025-08-14</span> 05:54:23,695938]<span class="pp">[</span><span class="ss">W</span><span class="pp">][</span><span class="ss">wordplay/__main__:93:__main__</span><span class="pp">]</span> {</span>
<span id="cb16-368"><a href="#cb16-368"></a>            <span class="st">"train"</span><span class="ex">:</span> {</span>
<span id="cb16-369"><a href="#cb16-369"></a>                <span class="st">"framework"</span><span class="ex">:</span> <span class="st">"pytorch"</span>,</span>
<span id="cb16-370"><a href="#cb16-370"></a>                <span class="st">"backend"</span><span class="ex">:</span> <span class="st">"DDP"</span>,</span>
<span id="cb16-371"><a href="#cb16-371"></a>                <span class="st">"device"</span><span class="ex">:</span> null,</span>
<span id="cb16-372"><a href="#cb16-372"></a>                <span class="st">"seed"</span><span class="ex">:</span> null,</span>
<span id="cb16-373"><a href="#cb16-373"></a>                <span class="st">"port"</span><span class="ex">:</span> null,</span>
<span id="cb16-374"><a href="#cb16-374"></a>                <span class="st">"ds_config_path"</span><span class="ex">:</span> null,</span>
<span id="cb16-375"><a href="#cb16-375"></a>                <span class="st">"precision"</span><span class="ex">:</span> null,</span>
<span id="cb16-376"><a href="#cb16-376"></a>                <span class="st">"ngpus"</span><span class="ex">:</span> null,</span>
<span id="cb16-377"><a href="#cb16-377"></a>                <span class="st">"use_wandb"</span><span class="ex">:</span> true,</span>
<span id="cb16-378"><a href="#cb16-378"></a>                <span class="st">"eval_interval"</span><span class="ex">:</span> 100,</span>
<span id="cb16-379"><a href="#cb16-379"></a>                <span class="st">"log_interval"</span><span class="ex">:</span> 10,</span>
<span id="cb16-380"><a href="#cb16-380"></a>                <span class="st">"eval_iters"</span><span class="ex">:</span> 200,</span>
<span id="cb16-381"><a href="#cb16-381"></a>                <span class="st">"eval_only"</span><span class="ex">:</span> false,</span>
<span id="cb16-382"><a href="#cb16-382"></a>                <span class="st">"always_save_checkpoint"</span><span class="ex">:</span> false,</span>
<span id="cb16-383"><a href="#cb16-383"></a>                <span class="st">"init_from"</span><span class="ex">:</span> <span class="st">"scratch"</span>,</span>
<span id="cb16-384"><a href="#cb16-384"></a>                <span class="st">"wandb_project"</span><span class="ex">:</span> <span class="st">"WordPlay"</span>,</span>
<span id="cb16-385"><a href="#cb16-385"></a>                <span class="st">"max_iters"</span><span class="ex">:</span> 1000,</span>
<span id="cb16-386"><a href="#cb16-386"></a>                <span class="st">"warmup_iters"</span><span class="ex">:</span> 100,</span>
<span id="cb16-387"><a href="#cb16-387"></a>                <span class="st">"dtype"</span><span class="ex">:</span> <span class="st">"bf16"</span>,</span>
<span id="cb16-388"><a href="#cb16-388"></a>                <span class="st">"compile"</span><span class="ex">:</span> true</span>
<span id="cb16-389"><a href="#cb16-389"></a>            <span class="er">}</span><span class="ex">,</span></span>
<span id="cb16-390"><a href="#cb16-390"></a>            <span class="st">"model"</span><span class="ex">:</span> {</span>
<span id="cb16-391"><a href="#cb16-391"></a>                <span class="st">"n_layer"</span><span class="ex">:</span> 12,</span>
<span id="cb16-392"><a href="#cb16-392"></a>                <span class="st">"n_head"</span><span class="ex">:</span> 12,</span>
<span id="cb16-393"><a href="#cb16-393"></a>                <span class="st">"n_embd"</span><span class="ex">:</span> 768,</span>
<span id="cb16-394"><a href="#cb16-394"></a>                <span class="st">"batch_size"</span><span class="ex">:</span> 8,</span>
<span id="cb16-395"><a href="#cb16-395"></a>                <span class="st">"block_size"</span><span class="ex">:</span> 2048,</span>
<span id="cb16-396"><a href="#cb16-396"></a>                <span class="st">"activation"</span><span class="ex">:</span> <span class="st">"gelu"</span>,</span>
<span id="cb16-397"><a href="#cb16-397"></a>                <span class="st">"dropout"</span><span class="ex">:</span> 0.0,</span>
<span id="cb16-398"><a href="#cb16-398"></a>                <span class="st">"bias"</span><span class="ex">:</span> false,</span>
<span id="cb16-399"><a href="#cb16-399"></a>                <span class="st">"vocab_size"</span><span class="ex">:</span> 65</span>
<span id="cb16-400"><a href="#cb16-400"></a>            <span class="er">}</span><span class="ex">,</span></span>
<span id="cb16-401"><a href="#cb16-401"></a>            <span class="st">"data"</span><span class="ex">:</span> {</span>
<span id="cb16-402"><a href="#cb16-402"></a>                <span class="st">"dataset"</span><span class="ex">:</span> <span class="st">"shakespeare_char"</span>,</span>
<span id="cb16-403"><a href="#cb16-403"></a>                <span class="st">"out_dir"</span><span class="ex">:</span> <span class="st">"out-shakespeare-char"</span>,</span>
<span id="cb16-404"><a href="#cb16-404"></a>                <span class="st">"root_path"</span><span class="ex">:</span> null</span>
<span id="cb16-405"><a href="#cb16-405"></a>            <span class="er">}</span><span class="ex">,</span></span>
<span id="cb16-406"><a href="#cb16-406"></a>            <span class="st">"optimizer"</span><span class="ex">:</span> {</span>
<span id="cb16-407"><a href="#cb16-407"></a>                <span class="st">"gas"</span><span class="ex">:</span> 1,</span>
<span id="cb16-408"><a href="#cb16-408"></a>                <span class="st">"name"</span><span class="ex">:</span> <span class="st">"AdamW"</span>,</span>
<span id="cb16-409"><a href="#cb16-409"></a>                <span class="st">"learning_rate"</span><span class="ex">:</span> 0.0006,</span>
<span id="cb16-410"><a href="#cb16-410"></a>                <span class="st">"weight_decay"</span><span class="ex">:</span> 0.1,</span>
<span id="cb16-411"><a href="#cb16-411"></a>                <span class="st">"beta1"</span><span class="ex">:</span> 0.9,</span>
<span id="cb16-412"><a href="#cb16-412"></a>                <span class="st">"beta2"</span><span class="ex">:</span> 0.95,</span>
<span id="cb16-413"><a href="#cb16-413"></a>                <span class="st">"grad_clip"</span><span class="ex">:</span> 1.0,</span>
<span id="cb16-414"><a href="#cb16-414"></a>                <span class="st">"decay_lr"</span><span class="ex">:</span> true,</span>
<span id="cb16-415"><a href="#cb16-415"></a>                <span class="st">"lr_decay_iters"</span><span class="ex">:</span> 600000,</span>
<span id="cb16-416"><a href="#cb16-416"></a>                <span class="st">"min_lr"</span><span class="ex">:</span> 6e-05</span>
<span id="cb16-417"><a href="#cb16-417"></a>            <span class="er">}</span></span>
<span id="cb16-418"><a href="#cb16-418"></a>        <span class="er">}</span></span>
<span id="cb16-419"><a href="#cb16-419"></a>        <span class="ex">[2025-08-14</span> 05:54:23,698890]<span class="pp">[</span><span class="ss">W</span><span class="pp">][</span><span class="ss">wordplay/__main__:94:__main__</span><span class="pp">]</span> Output dir: /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/outputs/runs/pytorch/DDP/2025-08-14/05-54-17</span>
<span id="cb16-420"><a href="#cb16-420"></a>        <span class="ex">[2025-08-14</span> 05:54:23,699444]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:234</span><span class="pp">]</span> Initializing a new model from scratch</span>
<span id="cb16-421"><a href="#cb16-421"></a>        <span class="ex">[2025-08-14</span> 05:54:24,575640]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/model:255</span><span class="pp">]</span> number of parameters: 85.00M</span>
<span id="cb16-422"><a href="#cb16-422"></a>        <span class="ex">[2025-08-14</span> 05:54:24,625918]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:251</span><span class="pp">]</span> Model size: num_params=85003776</span>
<span id="cb16-423"><a href="#cb16-423"></a>        <span class="ex">[2025-08-14</span> 05:54:24,637219]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/model:445</span><span class="pp">]</span> num decayed parameter tensors: 50, with 86,557,440 parameters</span>
<span id="cb16-424"><a href="#cb16-424"></a>        <span class="ex">[2025-08-14</span> 05:54:24,637872]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/model:449</span><span class="pp">]</span> num non-decayed parameter tensors: 25, with 19,200 parameters</span>
<span id="cb16-425"><a href="#cb16-425"></a>        <span class="ex">[2025-08-14</span> 05:54:24,638937]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/model:465</span><span class="pp">]</span> using fused AdamW: True</span>
<span id="cb16-426"><a href="#cb16-426"></a>        <span class="ex">[2025-08-14</span> 05:54:25,662969]<span class="pp">[</span><span class="ss">C</span><span class="pp">][</span><span class="ss">wordplay/trainer:322</span><span class="pp">]</span> RANK=0:devid=<span class="st">'cuda:0'</span></span>
<span id="cb16-427"><a href="#cb16-427"></a>        <span class="ex">[2025-08-14</span> 05:54:25,748890]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:361</span><span class="pp">]</span> • self.model=OptimizedModule<span class="er">(</span></span>
<span id="cb16-428"><a href="#cb16-428"></a>          <span class="kw">(</span><span class="ex">_orig_mod</span><span class="kw">)</span><span class="bu">:</span> GPT<span class="er">(</span></span>
<span id="cb16-429"><a href="#cb16-429"></a>            <span class="kw">(</span><span class="ex">transformer</span><span class="kw">)</span><span class="bu">:</span> ModuleDict<span class="er">(</span></span>
<span id="cb16-430"><a href="#cb16-430"></a>              <span class="kw">(</span><span class="ex">wte</span><span class="kw">)</span><span class="bu">:</span> Embedding<span class="er">(</span><span class="ex">65,</span> 768<span class="kw">)</span></span>
<span id="cb16-431"><a href="#cb16-431"></a>              <span class="kw">(</span><span class="ex">wpe</span><span class="kw">)</span><span class="bu">:</span> Embedding<span class="er">(</span><span class="ex">2048,</span> 768<span class="kw">)</span></span>
<span id="cb16-432"><a href="#cb16-432"></a>              <span class="kw">(</span><span class="ex">drop</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-433"><a href="#cb16-433"></a>              <span class="kw">(</span><span class="ex">h</span><span class="kw">)</span><span class="bu">:</span> ModuleList<span class="er">(</span></span>
<span id="cb16-434"><a href="#cb16-434"></a>                <span class="kw">(</span><span class="ex">0-11</span><span class="kw">)</span><span class="bu">:</span> 12 x Block<span class="er">(</span></span>
<span id="cb16-435"><a href="#cb16-435"></a>                  <span class="kw">(</span><span class="ex">ln_1</span><span class="kw">)</span><span class="bu">:</span> LayerNorm<span class="er">(</span><span class="kw">)</span></span>
<span id="cb16-436"><a href="#cb16-436"></a>                  <span class="kw">(</span><span class="ex">attn</span><span class="kw">)</span><span class="bu">:</span> CausalSelfAttention<span class="er">(</span></span>
<span id="cb16-437"><a href="#cb16-437"></a>                    <span class="kw">(</span><span class="ex">c_attn</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>2304, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-438"><a href="#cb16-438"></a>                    <span class="kw">(</span><span class="ex">c_proj</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>768, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-439"><a href="#cb16-439"></a>                    <span class="kw">(</span><span class="ex">attn_dropout</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-440"><a href="#cb16-440"></a>                    <span class="kw">(</span><span class="ex">resid_dropout</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-441"><a href="#cb16-441"></a>                  <span class="kw">)</span></span>
<span id="cb16-442"><a href="#cb16-442"></a>                  <span class="kw">(</span><span class="ex">ln_2</span><span class="kw">)</span><span class="bu">:</span> LayerNorm<span class="er">(</span><span class="kw">)</span></span>
<span id="cb16-443"><a href="#cb16-443"></a>                  <span class="kw">(</span><span class="ex">mlp</span><span class="kw">)</span><span class="bu">:</span> MLP<span class="er">(</span></span>
<span id="cb16-444"><a href="#cb16-444"></a>                    <span class="kw">(</span><span class="ex">c_fc</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>3072, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-445"><a href="#cb16-445"></a>                    <span class="kw">(</span><span class="ex">act_fn</span><span class="kw">)</span><span class="bu">:</span> GELU<span class="er">(</span><span class="va">approximate</span><span class="op">=</span><span class="st">'none'</span><span class="kw">)</span></span>
<span id="cb16-446"><a href="#cb16-446"></a>                    <span class="kw">(</span><span class="ex">c_proj</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>3072, <span class="va">out_features</span><span class="op">=</span>768, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-447"><a href="#cb16-447"></a>                    <span class="kw">(</span><span class="ex">dropout</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-448"><a href="#cb16-448"></a>                  <span class="kw">)</span></span>
<span id="cb16-449"><a href="#cb16-449"></a>                <span class="kw">)</span></span>
<span id="cb16-450"><a href="#cb16-450"></a>              <span class="kw">)</span></span>
<span id="cb16-451"><a href="#cb16-451"></a>              <span class="kw">(</span><span class="ex">ln_f</span><span class="kw">)</span><span class="bu">:</span> LayerNorm<span class="er">(</span><span class="kw">)</span></span>
<span id="cb16-452"><a href="#cb16-452"></a>            <span class="kw">)</span></span>
<span id="cb16-453"><a href="#cb16-453"></a>            <span class="kw">(</span><span class="ex">lm_head</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>65, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-454"><a href="#cb16-454"></a>          <span class="kw">)</span></span>
<span id="cb16-455"><a href="#cb16-455"></a>        <span class="kw">)</span></span>
<span id="cb16-456"><a href="#cb16-456"></a>        <span class="ex">[2025-08-14</span> 05:54:25,752694]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:362</span><span class="pp">]</span> • self.grad_scaler=<span class="op">&lt;</span>torch.cuda.amp.grad_scaler.GradScaler object at 0x14da15e752b0<span class="op">&gt;</span></span>
<span id="cb16-457"><a href="#cb16-457"></a>        <span class="ex">[2025-08-14</span> 05:54:25,753734]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:363</span><span class="pp">]</span> • self.model_engine=DistributedDataParallel<span class="er">(</span></span>
<span id="cb16-458"><a href="#cb16-458"></a>          <span class="kw">(</span><span class="ex">module</span><span class="kw">)</span><span class="bu">:</span> OptimizedModule<span class="er">(</span></span>
<span id="cb16-459"><a href="#cb16-459"></a>            <span class="kw">(</span><span class="ex">_orig_mod</span><span class="kw">)</span><span class="bu">:</span> GPT<span class="er">(</span></span>
<span id="cb16-460"><a href="#cb16-460"></a>              <span class="kw">(</span><span class="ex">transformer</span><span class="kw">)</span><span class="bu">:</span> ModuleDict<span class="er">(</span></span>
<span id="cb16-461"><a href="#cb16-461"></a>                <span class="kw">(</span><span class="ex">wte</span><span class="kw">)</span><span class="bu">:</span> Embedding<span class="er">(</span><span class="ex">65,</span> 768<span class="kw">)</span></span>
<span id="cb16-462"><a href="#cb16-462"></a>                <span class="kw">(</span><span class="ex">wpe</span><span class="kw">)</span><span class="bu">:</span> Embedding<span class="er">(</span><span class="ex">2048,</span> 768<span class="kw">)</span></span>
<span id="cb16-463"><a href="#cb16-463"></a>                <span class="kw">(</span><span class="ex">drop</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-464"><a href="#cb16-464"></a>                <span class="kw">(</span><span class="ex">h</span><span class="kw">)</span><span class="bu">:</span> ModuleList<span class="er">(</span></span>
<span id="cb16-465"><a href="#cb16-465"></a>                  <span class="kw">(</span><span class="ex">0-11</span><span class="kw">)</span><span class="bu">:</span> 12 x Block<span class="er">(</span></span>
<span id="cb16-466"><a href="#cb16-466"></a>                    <span class="kw">(</span><span class="ex">ln_1</span><span class="kw">)</span><span class="bu">:</span> LayerNorm<span class="er">(</span><span class="kw">)</span></span>
<span id="cb16-467"><a href="#cb16-467"></a>                    <span class="kw">(</span><span class="ex">attn</span><span class="kw">)</span><span class="bu">:</span> CausalSelfAttention<span class="er">(</span></span>
<span id="cb16-468"><a href="#cb16-468"></a>                      <span class="kw">(</span><span class="ex">c_attn</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>2304, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-469"><a href="#cb16-469"></a>                      <span class="kw">(</span><span class="ex">c_proj</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>768, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-470"><a href="#cb16-470"></a>                      <span class="kw">(</span><span class="ex">attn_dropout</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-471"><a href="#cb16-471"></a>                      <span class="kw">(</span><span class="ex">resid_dropout</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-472"><a href="#cb16-472"></a>                    <span class="kw">)</span></span>
<span id="cb16-473"><a href="#cb16-473"></a>                    <span class="kw">(</span><span class="ex">ln_2</span><span class="kw">)</span><span class="bu">:</span> LayerNorm<span class="er">(</span><span class="kw">)</span></span>
<span id="cb16-474"><a href="#cb16-474"></a>                    <span class="kw">(</span><span class="ex">mlp</span><span class="kw">)</span><span class="bu">:</span> MLP<span class="er">(</span></span>
<span id="cb16-475"><a href="#cb16-475"></a>                      <span class="kw">(</span><span class="ex">c_fc</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>3072, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-476"><a href="#cb16-476"></a>                      <span class="kw">(</span><span class="ex">act_fn</span><span class="kw">)</span><span class="bu">:</span> GELU<span class="er">(</span><span class="va">approximate</span><span class="op">=</span><span class="st">'none'</span><span class="kw">)</span></span>
<span id="cb16-477"><a href="#cb16-477"></a>                      <span class="kw">(</span><span class="ex">c_proj</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>3072, <span class="va">out_features</span><span class="op">=</span>768, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-478"><a href="#cb16-478"></a>                      <span class="kw">(</span><span class="ex">dropout</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-479"><a href="#cb16-479"></a>                    <span class="kw">)</span></span>
<span id="cb16-480"><a href="#cb16-480"></a>                  <span class="kw">)</span></span>
<span id="cb16-481"><a href="#cb16-481"></a>                <span class="kw">)</span></span>
<span id="cb16-482"><a href="#cb16-482"></a>                <span class="kw">(</span><span class="ex">ln_f</span><span class="kw">)</span><span class="bu">:</span> LayerNorm<span class="er">(</span><span class="kw">)</span></span>
<span id="cb16-483"><a href="#cb16-483"></a>              <span class="kw">)</span></span>
<span id="cb16-484"><a href="#cb16-484"></a>              <span class="kw">(</span><span class="ex">lm_head</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>65, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-485"><a href="#cb16-485"></a>            <span class="kw">)</span></span>
<span id="cb16-486"><a href="#cb16-486"></a>          <span class="kw">)</span></span>
<span id="cb16-487"><a href="#cb16-487"></a>        <span class="kw">)</span></span>
<span id="cb16-488"><a href="#cb16-488"></a>        <span class="ex">[2025-08-14</span> 05:54:25,757292]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:364</span><span class="pp">]</span> • self.optimizer=AdamW <span class="er">(</span></span>
<span id="cb16-489"><a href="#cb16-489"></a>        <span class="ex">Parameter</span> Group 0</span>
<span id="cb16-490"><a href="#cb16-490"></a>            <span class="ex">amsgrad:</span> False</span>
<span id="cb16-491"><a href="#cb16-491"></a>            <span class="ex">betas:</span> <span class="er">(</span><span class="ex">0.9,</span> 0.95<span class="kw">)</span></span>
<span id="cb16-492"><a href="#cb16-492"></a>            <span class="ex">capturable:</span> False</span>
<span id="cb16-493"><a href="#cb16-493"></a>            <span class="ex">differentiable:</span> False</span>
<span id="cb16-494"><a href="#cb16-494"></a>            <span class="ex">eps:</span> 1e-08</span>
<span id="cb16-495"><a href="#cb16-495"></a>            <span class="ex">foreach:</span> None</span>
<span id="cb16-496"><a href="#cb16-496"></a>            <span class="ex">fused:</span> True</span>
<span id="cb16-497"><a href="#cb16-497"></a>            <span class="ex">lr:</span> 0.0006</span>
<span id="cb16-498"><a href="#cb16-498"></a>            <span class="ex">maximize:</span> False</span>
<span id="cb16-499"><a href="#cb16-499"></a>            <span class="ex">weight_decay:</span> 0.1</span>
<span id="cb16-500"><a href="#cb16-500"></a></span>
<span id="cb16-501"><a href="#cb16-501"></a>        <span class="ex">Parameter</span> Group 1</span>
<span id="cb16-502"><a href="#cb16-502"></a>            <span class="ex">amsgrad:</span> False</span>
<span id="cb16-503"><a href="#cb16-503"></a>            <span class="ex">betas:</span> <span class="er">(</span><span class="ex">0.9,</span> 0.95<span class="kw">)</span></span>
<span id="cb16-504"><a href="#cb16-504"></a>            <span class="ex">capturable:</span> False</span>
<span id="cb16-505"><a href="#cb16-505"></a>            <span class="ex">differentiable:</span> False</span>
<span id="cb16-506"><a href="#cb16-506"></a>            <span class="ex">eps:</span> 1e-08</span>
<span id="cb16-507"><a href="#cb16-507"></a>            <span class="ex">foreach:</span> None</span>
<span id="cb16-508"><a href="#cb16-508"></a>            <span class="ex">fused:</span> True</span>
<span id="cb16-509"><a href="#cb16-509"></a>            <span class="ex">lr:</span> 0.0006</span>
<span id="cb16-510"><a href="#cb16-510"></a>            <span class="ex">maximize:</span> False</span>
<span id="cb16-511"><a href="#cb16-511"></a>            <span class="ex">weight_decay:</span> 0.0</span>
<span id="cb16-512"><a href="#cb16-512"></a>        <span class="kw">)</span></span>
<span id="cb16-513"><a href="#cb16-513"></a>        <span class="ex">[2025-08-14</span> 05:54:25,759725]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:796</span><span class="pp">]</span> Startup time: 8.6967</span>
<span id="cb16-514"><a href="#cb16-514"></a>                        <span class="ex">Training</span> Legend</span>
<span id="cb16-515"><a href="#cb16-515"></a>        <span class="ex">┏━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓</span></span>
<span id="cb16-516"><a href="#cb16-516"></a>        <span class="ex">┃</span>        abbr ┃ desc                           ┃</span>
<span id="cb16-517"><a href="#cb16-517"></a>        <span class="ex">┡━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩</span></span>
<span id="cb16-518"><a href="#cb16-518"></a>        <span class="ex">│</span>        step │ Current training iteration     │</span>
<span id="cb16-519"><a href="#cb16-519"></a>        <span class="ex">│</span>        loss │ Loss value                     │</span>
<span id="cb16-520"><a href="#cb16-520"></a>        <span class="ex">│</span>          dt │ Elapsed time per training step │</span>
<span id="cb16-521"><a href="#cb16-521"></a>        <span class="ex">│</span>         dtf │ Elapsed time per forward step  │</span>
<span id="cb16-522"><a href="#cb16-522"></a>        <span class="ex">│</span>         dtb │ Elapsed time per backward step │</span>
<span id="cb16-523"><a href="#cb16-523"></a>        <span class="ex">│</span>         sps │ Samples per second             │</span>
<span id="cb16-524"><a href="#cb16-524"></a>        <span class="ex">│</span> sps_per_gpu │ Samples per second <span class="er">(</span><span class="ex">per</span> GPU<span class="kw">)</span>   <span class="ex">│</span></span>
<span id="cb16-525"><a href="#cb16-525"></a>        <span class="ex">│</span>         tps │ Tokens per second              │</span>
<span id="cb16-526"><a href="#cb16-526"></a>        <span class="ex">│</span> tps_per_gpu │ Tokens per second <span class="er">(</span><span class="ex">per</span> GPU<span class="kw">)</span>    <span class="ex">│</span></span>
<span id="cb16-527"><a href="#cb16-527"></a>        <span class="ex">│</span>         mfu │ Model flops utilization        │</span>
<span id="cb16-528"><a href="#cb16-528"></a>        <span class="ex">└─────────────┴────────────────────────────────┘</span></span>
<span id="cb16-529"><a href="#cb16-529"></a>        <span class="ex">[2025-08-14</span> 05:54:27,146477]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:807</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'prompt'</span><span class="pp">]</span>: <span class="st">'What is an LLM?'</span></span>
<span id="cb16-530"><a href="#cb16-530"></a>        <span class="ex">[2025-08-14</span> 05:54:27,147296]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:810</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'response'</span><span class="pp">]</span>:</span>
<span id="cb16-531"><a href="#cb16-531"></a></span>
<span id="cb16-532"><a href="#cb16-532"></a>        <span class="ex">What</span> is an LLM<span class="pp">?</span> <span class="st">'hkk ''Evllll VWccm UzcW!W'':zlWk W  z! XXwltMMV!Qyyx'</span>y kDDvVX<span class="kw">;</span><span class="ex">WWlyy</span>  jKy<span class="kw">;</span><span class="ex">kkyyxxx</span><span class="va">$-</span><span class="ex">WDll</span>  l!<span class="kw">;</span><span class="ex">WWmmWW</span> eeJJzq.vv<span class="kw">;</span><span class="ot">! </span><span class="fu">w</span><span class="kw">;;</span><span class="ex">z</span><span class="st">'tlWDDDWklUJ ;yyNlccxQ-D V!MMG'</span><span class="ex">zt</span><span class="kw">;</span><span class="ex">WWk</span> lllUU D-kkXWUvvMy<span class="kw">;;</span><span class="ex">JrMCzl</span><span class="kw">;</span><span class="ex">Uve,z</span><span class="kw">;</span><span class="st">''</span><span class="ex">:VWQ-y</span><span class="va">$l</span><span class="ex">--o.cJD.yM</span><span class="st">'yyyZyyyVV$Qt!!kxuJeeD kll'</span><span class="ex">Uy-J</span><span class="st">'vV!tmkzJuM?!ppXXG;'</span></span>
<span id="cb16-533"><a href="#cb16-533"></a>        <span class="ex">[2025-08-14</span> 05:55:22,838950]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=10 loss=3.01934 dt=0.0778009 dtf=0.0055681 dtb=0.0124092 sps=102.827 sps_per_gpu=12.8533 tps=1.68471e+06 tps_per_gpu=210589 mfu=49.7121</span>
<span id="cb16-534"><a href="#cb16-534"></a>        <span class="ex">[2025-08-14</span> 05:55:23,622530]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=20 loss=2.73268 dt=0.0783059 dtf=0.00546336 dtb=0.0124693 sps=102.163 sps_per_gpu=12.7704 tps=1.67385e+06 tps_per_gpu=209231 mfu=49.6801</span>
<span id="cb16-535"><a href="#cb16-535"></a>        <span class="ex">[2025-08-14</span> 05:55:24,407385]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=30 loss=2.5634 dt=0.0784503 dtf=0.00536114 dtb=0.0125228 sps=101.975 sps_per_gpu=12.7469 tps=1.67076e+06 tps_per_gpu=208846 mfu=49.6421</span>
<span id="cb16-536"><a href="#cb16-536"></a>        <span class="ex">[2025-08-14</span> 05:55:25,192393]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=40 loss=2.51223 dt=0.0784606 dtf=0.00545081 dtb=0.012732 sps=101.962 sps_per_gpu=12.7452 tps=1.67054e+06 tps_per_gpu=208818 mfu=49.6073</span>
<span id="cb16-537"><a href="#cb16-537"></a>        <span class="ex">[2025-08-14</span> 05:55:25,977765]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=50 loss=2.49004 dt=0.079029 dtf=0.00523198 dtb=0.0125401 sps=101.229 sps_per_gpu=12.6536 tps=1.65853e+06 tps_per_gpu=207316 mfu=49.5406</span>
<span id="cb16-538"><a href="#cb16-538"></a>        <span class="ex">[2025-08-14</span> 05:55:26,761465]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=60 loss=2.45537 dt=0.07775 dtf=0.00518063 dtb=0.0127289 sps=102.894 sps_per_gpu=12.8617 tps=1.68581e+06 tps_per_gpu=210727 mfu=49.561</span>
<span id="cb16-539"><a href="#cb16-539"></a>        <span class="ex">[2025-08-14</span> 05:55:27,546584]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=70 loss=2.46909 dt=0.0782411 dtf=0.00528915 dtb=0.0125154 sps=102.248 sps_per_gpu=12.781 tps=1.67523e+06 tps_per_gpu=209404 mfu=49.5481</span>
<span id="cb16-540"><a href="#cb16-540"></a>        <span class="ex">[2025-08-14</span> 05:55:28,332687]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=80 loss=2.48264 dt=0.0792809 dtf=0.00552908 dtb=0.0130663 sps=100.907 sps_per_gpu=12.6134 tps=1.65326e+06 tps_per_gpu=206657 mfu=49.4717</span>
<span id="cb16-541"><a href="#cb16-541"></a>        <span class="ex">[2025-08-14</span> 05:55:29,118556]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=90 loss=2.51034 dt=0.0781782 dtf=0.00514289 dtb=0.0124665 sps=102.33 sps_per_gpu=12.7913 tps=1.67658e+06 tps_per_gpu=209573 mfu=49.4718</span>
<span id="cb16-542"><a href="#cb16-542"></a>        <span class="ex">[2025-08-14</span> 05:55:29,904022]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=100 loss=2.46516 dt=0.078483 dtf=0.00516737 dtb=0.0129046 sps=101.933 sps_per_gpu=12.7416 tps=1.67007e+06 tps_per_gpu=208758 mfu=49.4526</span>
<span id="cb16-543"><a href="#cb16-543"></a>        <span class="ex">[2025-08-14</span> 05:55:30,990755]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:807</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'prompt'</span><span class="pp">]</span>: <span class="st">'What is an LLM?'</span></span>
<span id="cb16-544"><a href="#cb16-544"></a>        <span class="ex">[2025-08-14</span> 05:55:30,991344]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:810</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'response'</span><span class="pp">]</span>:</span>
<span id="cb16-545"><a href="#cb16-545"></a></span>
<span id="cb16-546"><a href="#cb16-546"></a>        <span class="ex">What</span> is an LLM<span class="pp">?</span> denour sad is thot wind<span class="kw">;</span></span>
<span id="cb16-547"><a href="#cb16-547"></a>        <span class="ex">Ae</span> micome lofas t butowhatiom, ar thy mitheath anshthath o w gesurcingero w on</span>
<span id="cb16-548"><a href="#cb16-548"></a></span>
<span id="cb16-549"><a href="#cb16-549"></a>        <span class="ex">GArsitheath</span> the,</span>
<span id="cb16-550"><a href="#cb16-550"></a>        <span class="ex">Tordist</span> w nofout thoru ol t arthim he my,</span>
<span id="cb16-551"><a href="#cb16-551"></a>        <span class="ex">Thich</span> thingay</span>
<span id="cb16-552"><a href="#cb16-552"></a>        <span class="ex">Thot</span> we wiman hineisoule blt me s hat f aul the t,</span>
<span id="cb16-553"><a href="#cb16-553"></a>        <span class="ex">Tyoffove.</span></span>
<span id="cb16-554"><a href="#cb16-554"></a>        <span class="ex">Haicede</span> t tounon</span>
<span id="cb16-555"><a href="#cb16-555"></a>        <span class="ex">[2025-08-14</span> 05:55:40,218926]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:750</span><span class="pp">]</span> Saving checkpoint to: /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/outputs/runs/pytorch/DDP/2025-08-14/05-54-17</span>
<span id="cb16-556"><a href="#cb16-556"></a>        <span class="ex">[2025-08-14</span> 05:55:40,219705]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:751</span><span class="pp">]</span> Saving model to: /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/outputs/runs/pytorch/DDP/2025-08-14/05-54-17/model.pth</span>
<span id="cb16-557"><a href="#cb16-557"></a>        <span class="ex">[2025-08-14</span> 05:55:42,195499]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/configs:141</span><span class="pp">]</span> Appending /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/outputs/runs/pytorch/DDP/2025-08-14/05-54-17 to /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/wordplay/src/ckpts/checkpoints.log</span>
<span id="cb16-558"><a href="#cb16-558"></a>        <span class="ex">[2025-08-14</span> 05:55:42,999389]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=110 loss=2.43177 dt=0.0780071 dtf=0.00545025 dtb=0.0126532 sps=102.555 sps_per_gpu=12.8193 tps=1.68026e+06 tps_per_gpu=210032 mfu=49.4654</span>
<span id="cb16-559"><a href="#cb16-559"></a>        <span class="ex">[2025-08-14</span> 05:55:43,785978]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=120 loss=2.44182 dt=0.078106 dtf=0.00545009 dtb=0.0125079 sps=102.425 sps_per_gpu=12.8031 tps=1.67813e+06 tps_per_gpu=209766 mfu=49.4707</span>
<span id="cb16-560"><a href="#cb16-560"></a>        <span class="ex">[2025-08-14</span> 05:55:44,572009]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=130 loss=2.44907 dt=0.0785986 dtf=0.00526247 dtb=0.0123562 sps=101.783 sps_per_gpu=12.7229 tps=1.66761e+06 tps_per_gpu=208451 mfu=49.4444</span>
<span id="cb16-561"><a href="#cb16-561"></a>        <span class="ex">[2025-08-14</span> 05:55:45,358627]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=140 loss=2.39859 dt=0.0794152 dtf=0.00549359 dtb=0.0128465 sps=100.736 sps_per_gpu=12.592 tps=1.65047e+06 tps_per_gpu=206308 mfu=49.3701</span>
<span id="cb16-562"><a href="#cb16-562"></a>        <span class="ex">[2025-08-14</span> 05:55:46,146387]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=150 loss=2.42138 dt=0.079703 dtf=0.00618074 dtb=0.012967 sps=100.373 sps_per_gpu=12.5466 tps=1.6445e+06 tps_per_gpu=205563 mfu=49.2856</span>
<span id="cb16-563"><a href="#cb16-563"></a>        <span class="ex">[2025-08-14</span> 05:55:46,933663]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=160 loss=2.41715 dt=0.0793599 dtf=0.00549591 dtb=0.0130799 sps=100.807 sps_per_gpu=12.6008 tps=1.65161e+06 tps_per_gpu=206452 mfu=49.2306</span>
<span id="cb16-564"><a href="#cb16-564"></a>        <span class="ex">[2025-08-14</span> 05:55:47,721057]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=170 loss=2.44814 dt=0.0789742 dtf=0.00546218 dtb=0.012633 sps=101.299 sps_per_gpu=12.6624 tps=1.65968e+06 tps_per_gpu=207460 mfu=49.2049</span>
<span id="cb16-565"><a href="#cb16-565"></a>        <span class="ex">[2025-08-14</span> 05:55:48,507992]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=180 loss=2.41629 dt=0.0787978 dtf=0.00542163 dtb=0.0128453 sps=101.526 sps_per_gpu=12.6907 tps=1.6634e+06 tps_per_gpu=207925 mfu=49.1928</span>
<span id="cb16-566"><a href="#cb16-566"></a>        <span class="ex">[2025-08-14</span> 05:55:49,297076]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=190 loss=2.38078 dt=0.0781823 dtf=0.00540887 dtb=0.0122009 sps=102.325 sps_per_gpu=12.7906 tps=1.67649e+06 tps_per_gpu=209561 mfu=49.2204</span>
<span id="cb16-567"><a href="#cb16-567"></a>        <span class="ex">[2025-08-14</span> 05:55:50,085624]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=200 loss=2.38881 dt=0.0787827 dtf=0.00544194 dtb=0.012954 sps=101.545 sps_per_gpu=12.6931 tps=1.66372e+06 tps_per_gpu=207964 mfu=49.2077</span>
<span id="cb16-568"><a href="#cb16-568"></a>        <span class="ex">[2025-08-14</span> 05:55:51,182746]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:807</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'prompt'</span><span class="pp">]</span>: <span class="st">'What is an LLM?'</span></span>
<span id="cb16-569"><a href="#cb16-569"></a>        <span class="ex">[2025-08-14</span> 05:55:51,183345]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:810</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'response'</span><span class="pp">]</span>:</span>
<span id="cb16-570"><a href="#cb16-570"></a></span>
<span id="cb16-571"><a href="#cb16-571"></a>        <span class="ex">What</span> is an LLM<span class="pp">?</span></span>
<span id="cb16-572"><a href="#cb16-572"></a>        <span class="ex">TYMMurcomarl</span> he ffal ther the arisplit at in fil an arices tor<span class="dt">\'</span>se iom o foul yof forsthe,</span>
<span id="cb16-573"><a href="#cb16-573"></a>        <span class="ex">ADe</span> ce he the her slashe th ous ar me andone be the sorthe spof aris indllfll thir me ay the bldorom n de</span>
<span id="cb16-574"><a href="#cb16-574"></a>        <span class="ex">She</span> thit t,</span>
<span id="cb16-575"><a href="#cb16-575"></a>        <span class="ex">Clou</span> lllethe fourth wit thin, pr thee th bl hes</span>
<span id="cb16-576"><a href="#cb16-576"></a>        <span class="ex">[2025-08-14</span> 05:56:00,419222]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:750</span><span class="pp">]</span> Saving checkpoint to: /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/outputs/runs/pytorch/DDP/2025-08-14/05-54-17</span>
<span id="cb16-577"><a href="#cb16-577"></a>        <span class="ex">[2025-08-14</span> 05:56:00,420026]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:751</span><span class="pp">]</span> Saving model to: /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/outputs/runs/pytorch/DDP/2025-08-14/05-54-17/model.pth</span>
<span id="cb16-578"><a href="#cb16-578"></a>        <span class="ex">[2025-08-14</span> 05:56:03,473861]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/configs:141</span><span class="pp">]</span> Appending /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/outputs/runs/pytorch/DDP/2025-08-14/05-54-17 to /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/wordplay/src/ckpts/checkpoints.log</span>
<span id="cb16-579"><a href="#cb16-579"></a>        <span class="ex">[2025-08-14</span> 05:56:04,301502]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=210 loss=2.40137 dt=0.0777987 dtf=0.00521268 dtb=0.012754 sps=102.829 sps_per_gpu=12.8537 tps=1.68476e+06 tps_per_gpu=210595 mfu=49.2582</span>
<span id="cb16-580"><a href="#cb16-580"></a>        <span class="ex">[2025-08-14</span> 05:56:05,090312]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=220 loss=2.32615 dt=0.0785563 dtf=0.00518237 dtb=0.0124011 sps=101.838 sps_per_gpu=12.7297 tps=1.66851e+06 tps_per_gpu=208564 mfu=49.2558</span>
<span id="cb16-581"><a href="#cb16-581"></a>        <span class="ex">[2025-08-14</span> 05:56:05,875417]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=230 loss=2.28453 dt=0.0781005 dtf=0.00532893 dtb=0.0126092 sps=102.432 sps_per_gpu=12.804 tps=1.67825e+06 tps_per_gpu=209781 mfu=49.2824</span>
<span id="cb16-582"><a href="#cb16-582"></a>        <span class="ex">[2025-08-14</span> 05:56:06,662143]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=240 loss=2.32075 dt=0.0790562 dtf=0.0056354 dtb=0.0128831 sps=101.194 sps_per_gpu=12.6492 tps=1.65796e+06 tps_per_gpu=207245 mfu=49.2464</span>
<span id="cb16-583"><a href="#cb16-583"></a>        <span class="ex">[2025-08-14</span> 05:56:07,448907]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=250 loss=2.26398 dt=0.0782558 dtf=0.00549903 dtb=0.0123185 sps=102.229 sps_per_gpu=12.7786 tps=1.67492e+06 tps_per_gpu=209365 mfu=49.2641</span>
<span id="cb16-584"><a href="#cb16-584"></a>        <span class="ex">[2025-08-14</span> 05:56:08,237097]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=260 loss=2.20778 dt=0.0779999 dtf=0.00544577 dtb=0.0125349 sps=102.564 sps_per_gpu=12.8205 tps=1.68041e+06 tps_per_gpu=210052 mfu=49.2962</span>
<span id="cb16-585"><a href="#cb16-585"></a>        <span class="ex">[2025-08-14</span> 05:56:09,024535]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=270 loss=2.13115 dt=0.0790745 dtf=0.00544547 dtb=0.0127346 sps=101.17 sps_per_gpu=12.6463 tps=1.65758e+06 tps_per_gpu=207197 mfu=49.2577</span>
<span id="cb16-586"><a href="#cb16-586"></a>        <span class="ex">[2025-08-14</span> 05:56:09,812910]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=280 loss=2.1087 dt=0.078672 dtf=0.00547284 dtb=0.0126957 sps=101.688 sps_per_gpu=12.711 tps=1.66606e+06 tps_per_gpu=208257 mfu=49.2481</span>
<span id="cb16-587"><a href="#cb16-587"></a>        <span class="ex">[2025-08-14</span> 05:56:10,600338]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=290 loss=2.07268 dt=0.0785346 dtf=0.00520987 dtb=0.0126892 sps=101.866 sps_per_gpu=12.7332 tps=1.66897e+06 tps_per_gpu=208621 mfu=49.2481</span>
<span id="cb16-588"><a href="#cb16-588"></a>        <span class="ex">[2025-08-14</span> 05:56:11,388671]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=300 loss=1.94068 dt=0.0790002 dtf=0.00531021 dtb=0.0126261 sps=101.266 sps_per_gpu=12.6582 tps=1.65914e+06 tps_per_gpu=207392 mfu=49.219</span>
<span id="cb16-589"><a href="#cb16-589"></a>        <span class="ex">[2025-08-14</span> 05:56:12,465166]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:807</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'prompt'</span><span class="pp">]</span>: <span class="st">'What is an LLM?'</span></span>
<span id="cb16-590"><a href="#cb16-590"></a>        <span class="ex">[2025-08-14</span> 05:56:12,465770]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:810</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'response'</span><span class="pp">]</span>:</span>
<span id="cb16-591"><a href="#cb16-591"></a></span>
<span id="cb16-592"><a href="#cb16-592"></a>        <span class="ex">What</span> is an LLM<span class="pp">?</span></span>
<span id="cb16-593"><a href="#cb16-593"></a></span>
<span id="cb16-594"><a href="#cb16-594"></a>        <span class="ex">BHORLINUS:</span></span>
<span id="cb16-595"><a href="#cb16-595"></a>        <span class="ex">You</span> hes.</span>
<span id="cb16-596"><a href="#cb16-596"></a></span>
<span id="cb16-597"><a href="#cb16-597"></a>        <span class="ex">SORONE:</span></span>
<span id="cb16-598"><a href="#cb16-598"></a>        <span class="ex">What</span> the the he opteresint o of men sign ond the be, them wit ook hom sace win comend faren thy to the sate, the there my ford thim helinguss<span class="pp">?</span></span>
<span id="cb16-599"><a href="#cb16-599"></a></span>
<span id="cb16-600"><a href="#cb16-600"></a>        <span class="ex">Gest</span> will ningure lan friner thing fornce, his blout of dete to hee tweer he hou</span>
<span id="cb16-601"><a href="#cb16-601"></a>        <span class="ex">[2025-08-14</span> 05:56:21,695714]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:750</span><span class="pp">]</span> Saving checkpoint to: /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/outputs/runs/pytorch/DDP/2025-08-14/05-54-17</span>
<span id="cb16-602"><a href="#cb16-602"></a>        <span class="ex">[2025-08-14</span> 05:56:21,696469]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:751</span><span class="pp">]</span> Saving model to: /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/outputs/runs/pytorch/DDP/2025-08-14/05-54-17/model.pth</span>
<span id="cb16-603"><a href="#cb16-603"></a>        <span class="ex">[2025-08-14</span> 05:56:24,287565]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/configs:141</span><span class="pp">]</span> Appending /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/outputs/runs/pytorch/DDP/2025-08-14/05-54-17 to /global/cfs/cdirs/m4388/Project5/foremans/projects/saforem2/wordplay/src/ckpts/checkpoints.log</span>
<span id="cb16-604"><a href="#cb16-604"></a>        <span class="ex">[2025-08-14</span> 05:56:25,085517]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=310 loss=1.95217 dt=0.0780975 dtf=0.0054995 dtb=0.0122778 sps=102.436 sps_per_gpu=12.8045 tps=1.67831e+06 tps_per_gpu=209789 mfu=49.2495</span>
<span id="cb16-605"><a href="#cb16-605"></a>        <span class="ex">[2025-08-14</span> 05:56:25,870824]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=320 loss=1.82002 dt=0.0780001 dtf=0.00549541 dtb=0.012604 sps=102.564 sps_per_gpu=12.8205 tps=1.68041e+06 tps_per_gpu=210051 mfu=49.283</span>
<span id="cb16-606"><a href="#cb16-606"></a>        <span class="ex">[2025-08-14</span> 05:56:26,657320]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=330 loss=1.80354 dt=0.080137 dtf=0.00549193 dtb=0.0133185 sps=99.8291 sps_per_gpu=12.4786 tps=1.6356e+06 tps_per_gpu=204450 mfu=49.181</span>
<span id="cb16-607"><a href="#cb16-607"></a>        <span class="ex">[2025-08-14</span> 05:56:27,444509]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=340 loss=1.7014 dt=0.0786976 dtf=0.00530128 dtb=0.012458 sps=101.655 sps_per_gpu=12.7069 tps=1.66551e+06 tps_per_gpu=208189 mfu=49.1775</span>
<span id="cb16-608"><a href="#cb16-608"></a>        <span class="ex">[2025-08-14</span> 05:56:28,230760]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=350 loss=1.70333 dt=0.0786828 dtf=0.00523585 dtb=0.0120742 sps=101.674 sps_per_gpu=12.7093 tps=1.66583e+06 tps_per_gpu=208228 mfu=49.1752</span>
<span id="cb16-609"><a href="#cb16-609"></a>        <span class="ex">[2025-08-14</span> 05:56:29,017482]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=360 loss=1.63698 dt=0.078231 dtf=0.00522951 dtb=0.0119305 sps=102.261 sps_per_gpu=12.7827 tps=1.67545e+06 tps_per_gpu=209431 mfu=49.2016</span>
<span id="cb16-610"><a href="#cb16-610"></a>        <span class="ex">[2025-08-14</span> 05:56:29,804709]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=370 loss=1.6209 dt=0.078897 dtf=0.00537987 dtb=0.0121035 sps=101.398 sps_per_gpu=12.6748 tps=1.66131e+06 tps_per_gpu=207663 mfu=49.1836</span>
<span id="cb16-611"><a href="#cb16-611"></a>        <span class="ex">[2025-08-14</span> 05:56:30,590656]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=380 loss=1.62243 dt=0.0783268 dtf=0.00511256 dtb=0.0119576 sps=102.136 sps_per_gpu=12.767 tps=1.6734e+06 tps_per_gpu=209175 mfu=49.2031</span>
<span id="cb16-612"><a href="#cb16-612"></a>        <span class="ex">[2025-08-14</span> 05:56:31,378053]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=390 loss=1.46302 dt=0.0787818 dtf=0.00514412 dtb=0.0120985 sps=101.546 sps_per_gpu=12.6933 tps=1.66373e+06 tps_per_gpu=207967 mfu=49.1921</span>
<span id="cb16-613"><a href="#cb16-613"></a>        <span class="ex">[2025-08-14</span> 05:56:32,164231]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:868</span><span class="pp">]</span> step=400 loss=1.48415 dt=0.0786123 dtf=0.00519092 dtb=0.0120484 sps=101.765 sps_per_gpu=12.7206 tps=1.66732e+06 tps_per_gpu=208415 mfu=49.1928</span>
<span id="cb16-614"><a href="#cb16-614"></a>        <span class="ex">[2025-08-14</span> 05:56:33,253719]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:807</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'prompt'</span><span class="pp">]</span>: <span class="st">'What is an LLM?'</span></span>
<span id="cb16-615"><a href="#cb16-615"></a>        <span class="ex">[2025-08-14</span> 05:56:33,254320]<span class="pp">[</span><span class="ss">I</span><span class="pp">][</span><span class="ss">wordplay/trainer:810</span><span class="pp">]</span> <span class="pp">[</span><span class="st">'response'</span><span class="pp">]</span>:</span>
<span id="cb16-616"><a href="#cb16-616"></a></span>
<span id="cb16-617"><a href="#cb16-617"></a>        <span class="ex">What</span> is an LLM<span class="pp">?</span></span>
<span id="cb16-618"><a href="#cb16-618"></a></span>
<span id="cb16-619"><a href="#cb16-619"></a>        <span class="ex">EONTES:</span></span>
<span id="cb16-620"><a href="#cb16-620"></a>        <span class="ex">The</span> sir, or accution of him. Well oftiess a somet</span>
<span id="cb16-621"><a href="#cb16-621"></a>        <span class="ex">to</span> marry be of our livery: anst the nemble to tearture,</span>
<span id="cb16-622"><a href="#cb16-622"></a>        <span class="ex">to</span> prompt out sicibler out himself too suction.</span>
<span id="cb16-623"><a href="#cb16-623"></a>        <span class="ex">I</span> but stain time acfficiancel<span class="dt">\'</span>d cament, and all</span>
<span id="cb16-624"><a href="#cb16-624"></a>        <span class="ex">nom</span> officious laptimes famits of finge, have</span>
<span id="cb16-625"><a href="#cb16-625"></a>        <span class="kw">```</span></span>
<span id="cb16-626"><a href="#cb16-626"></a></span>
<span id="cb16-627"><a href="#cb16-627"></a></span>
<span id="cb16-630"><a href="#cb16-630"></a><span class="in">```{python}</span></span>
<span id="cb16-631"><a href="#cb16-631"></a><span class="co">#| output: asis</span></span>
<span id="cb16-632"><a href="#cb16-632"></a><span class="co">#| code-fold: true</span></span>
<span id="cb16-633"><a href="#cb16-633"></a><span class="co">#| code-summary: "👀"</span></span>
<span id="cb16-634"><a href="#cb16-634"></a><span class="ex">import</span> datetime</span>
<span id="cb16-635"><a href="#cb16-635"></a><span class="ex">from</span> rich import print</span>
<span id="cb16-636"><a href="#cb16-636"></a><span class="ex">now</span> = datetime.datetime.now<span class="er">(</span><span class="kw">)</span></span>
<span id="cb16-637"><a href="#cb16-637"></a><span class="ex">print</span><span class="er">(</span><span class="st">' '</span><span class="ex">.join</span><span class="er">(</span><span class="bu">[</span> <span class="st">"[#838383]Last Updated[/]:"</span>, f<span class="st">"[#E599F7]{now.strftime("</span>%Y-%m-%d<span class="st">")}[/]"</span>, <span class="st">"[#838383]@[/]"</span>, <span class="er">f"[#00CCFF]{now.strftime("%H:%M:%S")}[/]",</span> <span class="ex">]</span><span class="kw">))</span></span>
<span id="cb16-638"><a href="#cb16-638"></a><span class="kw">```</span></span>
</code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://saforem2.github.io/intro-hpc-bootcamp-2025/">
<p>saforem2.github.io/intro-hpc-bootcamp-2025</p>
</a>
  </li>  
</ul>
    </div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/saforem2/intro-hpc-bootcamp-2025/blob/main/index.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/saforem2/intro-hpc-bootcamp-2025/edit/main/index.qmd" class="toc-action"><i class="bi empty"></i>Edit this page</a></li><li><a href="https://github.com/saforem2/intro-hpc-bootcamp-2025/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/saforem2">
      <i class="bi bi-twitter" role="img" aria-label="Sam Foreman Twitter">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link active" href="https://github.com/saforem2/intro-hpc-bootcamp-2025" aria-current="page">
      <i class="bi bi-github" role="img" aria-label="Sam Foreman GitHub">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>